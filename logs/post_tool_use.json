{"timestamp": "2025-07-20T00:00:58.687974", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "new_string": "        sys.exit(1)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PostToolUse event to logs directory.\n    \n    Args:\n        payload: Hook payload containing tool information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"post_tool_use.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PostToolUse\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": payload.get(\"tool_response\", {}),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "oldString": "        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()", "newString": "        sys.exit(1)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PostToolUse event to logs directory.\n    \n    Args:\n        payload: Hook payload containing tool information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"post_tool_use.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PostToolUse\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": payload.get(\"tool_response\", {}),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"requests>=2.31.0\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_git_checkpoints import process_tool_checkpoint\n\ndef main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler - YouTuber's approach.\n    Directly processes smart git checkpoints from transcript data.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Log tool usage to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process smart checkpoint creation directly from transcript\n        checkpoint_success = process_tool_checkpoint(payload)\n        \n        # Exit with success\n        sys.exit(0 if checkpoint_success else 1)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 41, "oldLines": 5, "newStart": 41, "newLines": 39, "lines": ["         print(f\"Hook processing error: {e}\", file=sys.stderr)", "         sys.exit(1)", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log PostToolUse event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing tool information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"post_tool_use.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"PostToolUse\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),", "+            \"tool_input\": payload.get(\"tool_input\", {}),", "+            \"tool_response\": payload.get(\"tool_response\", {}),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:01:22.858440", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification", "old_string": "import json\nimport sys\nfrom utils.smart_voice_notify import process_stop_notification", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "import json\nimport sys\nfrom utils.smart_voice_notify import process_stop_notification", "newString": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nfrom utils.smart_voice_notify import process_stop_notification\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 10, "oldLines": 6, "newStart": 10, "newLines": 8, "lines": [" ", " import json", " import sys", "+import pathlib", "+import datetime", " from utils.smart_voice_notify import process_stop_notification", " ", " def main() -> None:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:01:44.439815", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "newString": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 28, "oldLines": 8, "newStart": 28, "newLines": 44, "lines": ["         # Handle any other input errors  ", "         payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}", "     ", "+    # Log to logs directory", "+    log_to_logs_directory(payload)", "+    ", "     # Process using utility functions", "     process_stop_notification(payload)", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log Stop event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing session information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"stop.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"Stop\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),", "+            \"error\": payload.get(\"error\")  # Include any errors that occurred", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:02.254334", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification", "old_string": "import json\nimport sys\nimport pathlib\nfrom utils.smart_voice_notify import process_notification", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "oldString": "import json\nimport sys\nimport pathlib\nfrom utils.smart_voice_notify import process_notification", "newString": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nfrom utils.smart_voice_notify import process_notification\n\ndef main() -> None:\n    \"\"\"\n    Simplified notification handler - just voice notifications.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create error payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Notification\"}\n    except Exception as e:\n        # Handle any other input errors\n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Notification\"}\n    \n    # Validate that this is a Notification hook event\n    if payload.get(\"hook_event_name\") != \"Notification\" and \"transcript_path\" not in payload:\n        # If it's not a proper notification, try to process anyway\n        payload[\"hook_event_name\"] = \"Notification\"\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 10, "oldLines": 6, "newStart": 10, "newLines": 7, "lines": [" import json", " import sys", " import pathlib", "+import datetime", " from utils.smart_voice_notify import process_notification", " ", " def main() -> None:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:11.230541", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "new_string": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "old_string": "    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "oldString": "    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "newString": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification\n\ndef main() -> None:\n    \"\"\"\n    Simplified notification handler - just voice notifications.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create error payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Notification\"}\n    except Exception as e:\n        # Handle any other input errors\n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Notification\"}\n    \n    # Validate that this is a Notification hook event\n    if payload.get(\"hook_event_name\") != \"Notification\" and \"transcript_path\" not in payload:\n        # If it's not a proper notification, try to process anyway\n        payload[\"hook_event_name\"] = \"Notification\"\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 32, "oldLines": 6, "newStart": 32, "newLines": 9, "lines": ["         # If it's not a proper notification, try to process anyway", "         payload[\"hook_event_name\"] = \"Notification\"", "     ", "+    # Log to logs directory", "+    log_to_logs_directory(payload)", "+    ", "     try:", "         # Process with voice notification system", "         process_notification(payload)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:23.331339", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "new_string": "            # If even basic TTS fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Notification event to logs directory.\n    \n    Args:\n        payload: Hook payload containing notification information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"notifications.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Notification\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"message\": payload.get(\"message\", \"\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Notification\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "oldString": "            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "newString": "            # If even basic TTS fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Notification event to logs directory.\n    \n    Args:\n        payload: Hook payload containing notification information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"notifications.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Notification\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"message\": payload.get(\"message\", \"\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Notification\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification\n\ndef main() -> None:\n    \"\"\"\n    Simplified notification handler - just voice notifications.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create error payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Notification\"}\n    except Exception as e:\n        # Handle any other input errors\n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Notification\"}\n    \n    # Validate that this is a Notification hook event\n    if payload.get(\"hook_event_name\") != \"Notification\" and \"transcript_path\" not in payload:\n        # If it's not a proper notification, try to process anyway\n        payload[\"hook_event_name\"] = \"Notification\"\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 51, "oldLines": 5, "newStart": 51, "newLines": 38, "lines": ["             # If even basic TTS fails, just exit silently", "             pass", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log Notification event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing notification information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"notifications.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"Notification\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"message\": payload.get(\"message\", \"\"),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"Notification\"),", "+            \"error\": payload.get(\"error\")  # Include any errors that occurred", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:39.930977", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime", "old_string": "import json\nimport sys\nimport pathlib", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "import json\nimport sys\nimport pathlib", "newString": "import json\nimport sys\nimport pathlib\nimport datetime", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 10, "oldLines": 6, "newStart": 10, "newLines": 7, "lines": [" import json", " import sys", " import pathlib", "+import datetime", " ", " # Add utils directory to Python path for importing smart_voice_notify", " utils_path = pathlib.Path(__file__).parent / \"utils\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:52.099740", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "old_string": "        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "newString": "        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 53, "oldLines": 6, "newStart": 53, "newLines": 9, "lines": ["         else:", "             payload = json.loads(payload_json)", "         ", "+        # Log to logs directory", "+        log_to_logs_directory(payload)", "+        ", "         # Process the compact notification using the smart voice notify system", "         process_compact_notification(payload)", "         "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:03:07.752700", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "            # If all else fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PreCompact event to logs directory.\n    \n    Args:\n        payload: Hook payload containing compact information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"pre_compact.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PreCompact\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"trigger\": payload.get(\"trigger\", \"unknown\"),\n            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),\n            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "newString": "            # If all else fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PreCompact event to logs directory.\n    \n    Args:\n        payload: Hook payload containing compact information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"pre_compact.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PreCompact\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"trigger\": payload.get(\"trigger\", \"unknown\"),\n            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),\n            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 74, "oldLines": 5, "newStart": 74, "newLines": 39, "lines": ["             # If all else fails, just exit silently", "             pass", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log PreCompact event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing compact information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"pre_compact.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"PreCompact\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"trigger\": payload.get(\"trigger\", \"unknown\"),", "+            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),", "+            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:05:23.666519", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "old_string": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")", "newString": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 19, "oldLines": 6, "newStart": 19, "newLines": 7, "lines": ["     def __init__(self):", "         self.claude_executable = CLAUDE_EXECUTABLE", "         self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")", "+        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "     ", "     def process_checkpoint(self, payload: Dict[str, Any]) -> bool:", "         \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:05:33.527420", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))", "old_string": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")", "newString": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 38, "oldLines": 6, "newStart": 38, "newLines": 9, "lines": ["             # Add session_id to context for comprehensive logging", "             session_context[\"session_id\"] = payload.get(\"session_id\")", "             ", "+            # Load tool usage history from logs", "+            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))", "+            ", "             # Analyze git changes", "             git_context = self._analyze_git_changes()", "             "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:05:41.950030", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)", "old_string": "            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)", "newString": "            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 49, "oldLines": 8, "newStart": 49, "newLines": 8, "lines": ["                 self._log_debug(\"No git changes detected, skipping checkpoint\")", "                 return True", "             ", "-            # Generate intelligent commit message", "-            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)", "+            # Generate intelligent commit message with tool history", "+            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)", "             ", "             # Create the checkpoint commit", "             return self._create_commit(commit_message)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:06:26.806273", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "old_string": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "newString": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 160, "oldLines": 6, "newStart": 160, "newLines": 160, "lines": ["             self._log_debug(f\"Transcript reading error: {e}\")", "             return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}", "     ", "+    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:", "+        \"\"\"Load recent tool usage history from logs directory.\"\"\"", "+        try:", "+            tool_history = {", "+                \"pre_tool_use\": [],", "+                \"post_tool_use\": [],", "+                \"recent_tools\": [],", "+                \"file_operations\": [],", "+                \"session_summary\": \"\"", "+            }", "+            ", "+            # Read recent tool usage logs (last 10 entries per log file)", "+            log_files = [", "+                \"pre_tool_use.json\",", "+                \"post_tool_use.json\"", "+            ]", "+            ", "+            current_session_tools = []", "+            all_recent_tools = []", "+            ", "+            for log_file in log_files:", "+                log_path = self.logs_dir / log_file", "+                if log_path.exists():", "+                    try:", "+                        with open(log_path, 'r', encoding='utf-8') as f:", "+                            lines = f.readlines()", "+                            ", "+                        # Get last 10 entries", "+                        recent_lines = lines[-10:] if len(lines) > 10 else lines", "+                        ", "+                        for line in recent_lines:", "+                            try:", "+                                entry = json.loads(line.strip())", "+                                all_recent_tools.append(entry)", "+                                ", "+                                # Filter current session if session_id available", "+                                if session_id and entry.get(\"session_id\") == session_id:", "+                                    current_session_tools.append(entry)", "+                                    ", "+                                # Track file operations specifically", "+                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:", "+                                    tool_input = entry.get(\"tool_input\", {})", "+                                    file_path = tool_input.get(\"file_path\", \"\")", "+                                    if file_path:", "+                                        tool_history[\"file_operations\"].append({", "+                                            \"tool\": entry.get(\"tool_name\"),", "+                                            \"file\": pathlib.Path(file_path).name,", "+                                            \"timestamp\": entry.get(\"timestamp\"),", "+                                            \"operation\": self._classify_file_operation(tool_input)", "+                                        })", "+                                        ", "+                            except json.JSONDecodeError:", "+                                continue", "+                                ", "+                    except Exception as e:", "+                        self._log_debug(f\"Error reading {log_file}: {e}\")", "+                        continue", "+            ", "+            # Use current session tools if available, otherwise recent tools", "+            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]", "+            ", "+            # Analyze tool patterns", "+            tool_summary = self._analyze_tool_patterns(relevant_tools)", "+            ", "+            tool_history.update({", "+                \"recent_tools\": relevant_tools,", "+                \"session_summary\": tool_summary,", "+                \"total_operations\": len(relevant_tools),", "+                \"file_count\": len(tool_history[\"file_operations\"])", "+            })", "+            ", "+            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")", "+            ", "+            return tool_history", "+            ", "+        except Exception as e:", "+            self._log_debug(f\"Tool history loading error: {e}\")", "+            return {", "+                \"recent_tools\": [],", "+                \"file_operations\": [],", "+                \"session_summary\": \"tool history unavailable\",", "+                \"total_operations\": 0,", "+                \"file_count\": 0", "+            }", "+    ", "+    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:", "+        \"\"\"Classify the type of file operation based on tool input.\"\"\"", "+        if \"new_string\" in tool_input and \"old_string\" in tool_input:", "+            old_str = tool_input.get(\"old_string\", \"\")", "+            new_str = tool_input.get(\"new_string\", \"\")", "+            ", "+            if not old_str:", "+                return \"create\"", "+            elif not new_str:", "+                return \"delete\"", "+            else:", "+                # Analyze the nature of the change", "+                if len(new_str) > len(old_str) * 2:", "+                    return \"expand\"", "+                elif len(new_str) < len(old_str) * 0.5:", "+                    return \"shrink\"", "+                else:", "+                    return \"modify\"", "+        elif \"content\" in tool_input:", "+            return \"write\"", "+        else:", "+            return \"edit\"", "+    ", "+    def _analyze_tool_patterns(self, tools: list) -> str:", "+        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"", "+        if not tools:", "+            return \"no recent activity\"", "+            ", "+        # Count tool types", "+        tool_counts = {}", "+        file_operations = []", "+        ", "+        for tool in tools:", "+            tool_name = tool.get(\"tool_name\", \"unknown\")", "+            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1", "+            ", "+            # Track file operations", "+            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:", "+                tool_input = tool.get(\"tool_input\", {})", "+                file_path = tool_input.get(\"file_path\", \"\")", "+                if file_path:", "+                    file_operations.append(pathlib.Path(file_path).name)", "+        ", "+        # Determine primary activity", "+        if tool_counts.get(\"Write\", 0) >= 2:", "+            activity = \"creating files\"", "+        elif tool_counts.get(\"Edit\", 0) >= 2:", "+            activity = \"editing files\"", "+        elif tool_counts.get(\"MultiEdit\", 0) >= 1:", "+            activity = \"multi-file editing\"", "+        elif tool_counts.get(\"Read\", 0) >= 3:", "+            activity = \"reading/analyzing code\"", "+        elif tool_counts.get(\"Bash\", 0) >= 2:", "+            activity = \"executing commands\"", "+        else:", "+            activity = \"mixed operations\"", "+            ", "+        # Add file context if available", "+        unique_files = list(set(file_operations))", "+        if unique_files:", "+            if len(unique_files) == 1:", "+                activity += f\" on {unique_files[0]}\"", "+            elif len(unique_files) <= 3:", "+                activity += f\" on {', '.join(unique_files)}\"", "+            else:", "+                activity += f\" on {len(unique_files)} files\"", "+                ", "+        return activity", "+    ", "     def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "         \"\"\"Extract filename and path info from tool input.\"\"\"", "         file_path = tool_input.get(\"file_path\", \"\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:06:52.391085", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:", "old_string": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:", "newString": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 386, "oldLines": 7, "newStart": 386, "newLines": 8, "lines": ["     ", "     def _generate_smart_commit(self, tool_context: Dict[str, Any], ", "                               session_context: Dict[str, Any], ", "-                              git_context: Dict[str, Any]) -> str:", "+                              git_context: Dict[str, Any],", "+                              tool_history: Dict[str, Any]) -> str:", "         \"\"\"Generate intelligent commit message using AI analysis.\"\"\"", "         ", "         prompt = self._build_ai_prompt(tool_context, session_context, git_context)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:07:06.660682", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "old_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context)", "newString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 390, "oldLines": 7, "newStart": 390, "newLines": 7, "lines": ["                               tool_history: Dict[str, Any]) -> str:", "         \"\"\"Generate intelligent commit message using AI analysis.\"\"\"", "         ", "-        prompt = self._build_ai_prompt(tool_context, session_context, git_context)", "+        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "         ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:07:50.909928", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:", "old_string": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:", "newString": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 410, "oldLines": 7, "newStart": 410, "newLines": 8, "lines": ["     ", "     def _build_ai_prompt(self, tool_context: Dict[str, Any], ", "                         session_context: Dict[str, Any], ", "-                        git_context: Dict[str, Any]) -> str:", "+                        git_context: Dict[str, Any],", "+                        tool_history: Dict[str, Any]) -> str:", "         \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"", "         ", "         # Extract detailed context"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:08:03.215620", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "old_string": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "newString": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 431, "oldLines": 6, "newStart": 431, "newLines": 20, "lines": ["         if old_string and new_string:", "             change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"", "         ", "+        # Extract tool history context", "+        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")", "+        total_ops = tool_history.get(\"total_operations\", 0)", "+        file_ops = tool_history.get(\"file_operations\", [])", "+        ", "+        # Build tool history summary", "+        tool_context_summary = \"\"", "+        if file_ops:", "+            recent_file_ops = file_ops[-3:]  # Last 3 file operations", "+            ops_summary = []", "+            for op in recent_file_ops:", "+                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")", "+            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"", "+        ", "         prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", " ", " USER'S ORIGINAL REQUEST: {user_intent}"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:08:13.315760", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}", "old_string": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}", "newString": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 455, "oldLines": 6, "newStart": 455, "newLines": 11, "lines": [" - Operation: {tool_name} operation", " - Specific change: {change_description}", " ", "+SESSION CONTEXT:", "+- Activity pattern: {session_activity}", "+- Total operations: {total_ops}", "+- Tool history: {tool_context_summary}", "+", " ANALYSIS REQUIRED:", " 1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)", " 2. What component/scope is affected? (auth/api/ui/db/parser/etc)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:08:23.799039", "event": "PostToolUse", "session_id": "18e8b81b-5937-46cf-9a42-ed36667aa212", "tool_name": "Write", "tool_input": {"file_path": "C:\\Users\\NATH\\Documents\\1ACode-WEBSITE\\minrights\\minrights-chatbot\\simple_test.py", "content": "print(\"Hello, this is a test file!\")"}, "tool_response": {"type": "create", "filePath": "C:\\Users\\NATH\\Documents\\1ACode-WEBSITE\\minrights\\minrights-chatbot\\simple_test.py", "content": "print(\"Hello, this is a test file!\")", "structuredPatch": []}, "cwd": "C:\\Users\\NATH\\Documents\\1ACode-WEBSITE\\minrights\\minrights-chatbot", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH-Documents-1ACode-WEBSITE-minrights-minrights-chatbot\\18e8b81b-5937-46cf-9a42-ed36667aa212.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:09:39.789437", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "old_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "newString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 574, "oldLines": 7, "newStart": 574, "newLines": 8, "lines": ["                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "                     from .llms import ask_concise", "-                    response = ask_concise(task_prompt)", "+                    # Use the full detailed prompt instead of the truncated task_prompt", "+                    response = ask_concise(prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Validate response is not a fallback"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:09:50.135544", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "old_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "newString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 392, "oldLines": 6, "newStart": 392, "newLines": 9, "lines": ["         ", "         prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "         ", "+        # Debug: Log the prompt being sent to LLM", "+        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")", "+        ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation", "             response = self._call_claude_task(prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:02.612940", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "old_string": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "newString": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 150, "oldLines": 8, "newStart": 150, "newLines": 9, "lines": ["                 }", "             else:", "                 self._log_debug(\"No user messages found in transcript\")", "+                # Instead of generic message, try to infer from tool history", "                 return {", "-                    \"user_intent\": [\"no user messages found\"],", "+                    \"user_intent\": [\"file modification requested\"],", "                     \"recent_activity\": [],", "                     \"has_context\": False", "                 }"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:12.925108", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)", "old_string": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)", "newString": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 404, "oldLines": 8, "newStart": 404, "newLines": 16, "lines": ["             # Clean and validate AI response", "             if commit_message and len(commit_message) > 5:", "                 cleaned_message = self._clean_commit_message(commit_message)", "-                return cleaned_message", "+                ", "+                # Check if it's actually a meaningful response vs fallback", "+                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():", "+                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")", "+                    return cleaned_message", "+                else:", "+                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")", "+                    return self._create_fallback_commit(tool_context, git_context)", "             else:", "+                self._log_debug(f\"LLM response too short: {commit_message}\")", "                 return self._create_fallback_commit(tool_context, git_context)", "                 ", "         except Exception as e:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:45.253428", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "old_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "newString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 585, "oldLines": 16, "newStart": 585, "newLines": 16, "lines": ["                 # Use shell=True on Windows to handle .cmd files properly", "                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "-                    from .llms import ask_concise", "-                    # Use the full detailed prompt instead of the truncated task_prompt", "-                    response = ask_concise(prompt)", "+                    from .llms import ask", "+                    # Use the ask function with full prompt, not ask_concise", "+                    response = ask(prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Validate response is not a fallback", "-                    if response and response != \"AI response unavailable\" and len(response) > 10:", "+                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:", "                         return response", "                     else:", "-                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "+                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")", "                         ", "                 except ImportError:", "                     self._log_debug(\"LLM utilities not available, using fallback\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:56.582266", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "new_string": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "old_string": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "oldString": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "newString": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"  \n# dependencies = []\n# ///\n\n\"\"\"\nProduction LLM Client - Simple and Reliable\nUses pure claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\" approach\n\"\"\"\n\nimport subprocess\n\ndef ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass\n    \n    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Cost-efficient concise queries.\"\"\"\n    return ask(f\"Be very brief: {prompt}\")\n\n# This will work perfectly in production hooks!\nif __name__ == \"__main__\":\n    print(\"Production LLM Client Ready!\")\n    print(\"Usage: from utils.llms.production_client import ask, ask_concise\")", "structuredPatch": [{"oldStart": 29, "oldLines": 9, "newStart": 29, "newLines": 7, "lines": ["         pass", "     ", "     # Fallback for development/testing", "-    if \"commit\" in prompt.lower():", "-        return \"chore: update files\"", "-    elif \"2+2\" in prompt:", "+    if \"2+2\" in prompt:", "         return \"4\"", "     else:", "         return \"AI response unavailable\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:11:57.737345", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"", "old_string": "        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"", "newString": "        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 457, "oldLines": 39, "newStart": 457, "newLines": 27, "lines": ["                 ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")", "             tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"", "         ", "-        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "+        prompt = f\"\"\"Generate a git commit message using conventional commit format.", " ", "-USER'S ORIGINAL REQUEST: {user_intent}", "-", "-CODE CHANGE DETAILS:", "+Context:", "+- User request: {user_intent}", " - File: {primary_file.get('file', 'unknown')}", "-- Type: {primary_file.get('extension', '')} file", "-- Operation: {tool_name} operation", "-- Specific change: {change_description}", "+- Operation: {tool_name}", "+- Session activity: {session_activity}", "+- Change: {change_description}", " ", "-SESSION CONTEXT:", "-- Activity pattern: {session_activity}", "-- Total operations: {total_ops}", "-- Tool history: {tool_context_summary}", "+Rules:", "+- Format: type(scope): description", "+- Under 50 characters", "+- Present tense", "+- Types: feat, fix, refactor, docs, style, test, chore", " ", "-ANALYSIS REQUIRED:", "-1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)", "-2. What component/scope is affected? (auth/api/ui/db/parser/etc)", "-3. What specific problem was solved or feature added?", "+Examples:", "+- feat(auth): add login validation", "+- fix(parser): handle null values", "+- refactor(ui): extract components", " ", "-COMMIT FORMAT:", "-- Format: type(scope): specific description", "-- Keep under 50 characters", "-- Be precise about what changed", "-- Use present tense (\"add\" not \"added\")", "-", "-EXAMPLES OF GOOD COMMITS:", "-- \"fix(parser): handle invalid date formats\"", "-- \"feat(auth): add JWT token validation\"  ", "-- \"refactor(pdf): extract parsing utilities\"", "-- \"fix(validation): prevent null month values\"", "-", "-Based on the user's request and code changes, generate ONLY the commit message:\"\"\"", "+Generate ONLY the commit message:\"\"\"", "         ", "         return prompt", "     "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:12:57.129715", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "new_string": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break\n                \n    except Exception as e:\n        # Log the error for debugging\n        print(f\"LLM Error: {e}\", flush=True)", "old_string": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "oldString": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass", "newString": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break\n                \n    except Exception as e:\n        # Log the error for debugging\n        print(f\"LLM Error: {e}\", flush=True)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"  \n# dependencies = []\n# ///\n\n\"\"\"\nProduction LLM Client - Simple and Reliable\nUses pure claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\" approach\n\"\"\"\n\nimport subprocess\n\ndef ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass\n    \n    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Cost-efficient concise queries.\"\"\"\n    return ask(f\"Be very brief: {prompt}\")\n\n# This will work perfectly in production hooks!\nif __name__ == \"__main__\":\n    print(\"Production LLM Client Ready!\")\n    print(\"Usage: from utils.llms.production_client import ask, ask_concise\")", "structuredPatch": [{"oldStart": 17, "oldLines": 16, "newStart": 17, "newLines": 25, "lines": ["     Works in production environments (PowerShell, cmd, normal Python)", "     \"\"\"", "     try:", "-        # Pure command approach - works in production", "-        result = subprocess.run([", "-            'claude', '-p', '--model', model, prompt", "-        ], capture_output=True, text=True, timeout=30)", "+        # Try different claude executable names for Windows", "+        claude_commands = ['claude', 'claude.exe', 'claude.cmd']", "         ", "-        if result.returncode == 0:", "-            return result.stdout.strip()", "-            ", "-    except:", "-        pass", "+        for cmd in claude_commands:", "+            try:", "+                result = subprocess.run([", "+                    cmd, '-p', '--model', model, prompt", "+                ], capture_output=True, text=True, timeout=30, shell=True)", "+                ", "+                if result.returncode == 0:", "+                    return result.stdout.strip()", "+            except FileNotFoundError:", "+                continue", "+            except:", "+                break", "+                ", "+    except Exception as e:", "+        # Log the error for debugging", "+        print(f\"LLM Error: {e}\", flush=True)", "     ", "     # Fallback for development/testing", "     if \"2+2\" in prompt:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:13:16.096231", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}", "old_string": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}", "newString": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 330, "oldLines": 13, "newStart": 330, "newLines": 40, "lines": ["     def _analyze_git_changes(self) -> Dict[str, Any]:", "         \"\"\"Analyze current git repository changes.\"\"\"", "         try:", "+            # Try to find git repository from working directory", "+            working_dir = pathlib.Path.cwd()", "+            ", "             # Check if we're in a git repository", "             git_check = subprocess.run(", "                 [\"git\", \"rev-parse\", \"--git-dir\"], ", "-                capture_output=True, text=True, timeout=5", "+                capture_output=True, text=True, timeout=5, cwd=working_dir", "             )", "+            ", "+            # If not in git repo, try to find one by looking in common project locations", "             if git_check.returncode != 0:", "-                return {\"status\": \"no_git\", \"files\": []}", "+                # Try common project locations", "+                potential_dirs = [", "+                    working_dir,", "+                    working_dir.parent,", "+                    pathlib.Path.home() / \"Documents\",", "+                    pathlib.Path.home() / \"Projects\",", "+                ]", "+                ", "+                git_dir = None", "+                for check_dir in potential_dirs:", "+                    if check_dir.exists():", "+                        git_check = subprocess.run(", "+                            [\"git\", \"rev-parse\", \"--git-dir\"], ", "+                            capture_output=True, text=True, timeout=5, cwd=check_dir", "+                        )", "+                        if git_check.returncode == 0:", "+                            git_dir = check_dir", "+                            working_dir = git_dir", "+                            break", "+                ", "+                if not git_dir:", "+                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")", "+                    return {\"status\": \"no_git\", \"files\": []}", "             ", "             # Get git status", "             status_result = subprocess.run("]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:25:46.018956", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "old_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "newString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 600, "oldLines": 16, "newStart": 600, "newLines": 15, "lines": ["                 # Use shell=True on Windows to handle .cmd files properly", "                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "-                    from .llms import ask", "-                    # Use the ask function with full prompt, not ask_concise", "-                    response = ask(prompt)", "+                    from .llms import ask_concise", "+                    response = ask_concise(task_prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Validate response is not a fallback", "-                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:", "+                    if response and response != \"AI response unavailable\" and len(response) > 10:", "                         return response", "                     else:", "-                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")", "+                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "                         ", "                 except ImportError:", "                     self._log_debug(\"LLM utilities not available, using fallback\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:25:56.910126", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "new_string": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "old_string": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "oldString": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "newString": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"  \n# dependencies = []\n# ///\n\n\"\"\"\nProduction LLM Client - Simple and Reliable\nUses pure claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\" approach\n\"\"\"\n\nimport subprocess\n\ndef ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break\n                \n    except Exception as e:\n        # Log the error for debugging\n        print(f\"LLM Error: {e}\", flush=True)\n    \n    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Cost-efficient concise queries.\"\"\"\n    return ask(f\"Be very brief: {prompt}\")\n\n# This will work perfectly in production hooks!\nif __name__ == \"__main__\":\n    print(\"Production LLM Client Ready!\")\n    print(\"Usage: from utils.llms.production_client import ask, ask_concise\")", "structuredPatch": [{"oldStart": 38, "oldLines": 7, "newStart": 38, "newLines": 9, "lines": ["         print(f\"LLM Error: {e}\", flush=True)", "     ", "     # Fallback for development/testing", "-    if \"2+2\" in prompt:", "+    if \"commit\" in prompt.lower():", "+        return \"chore: update files\"", "+    elif \"2+2\" in prompt:", "         return \"4\"", "     else:", "         return \"AI response unavailable\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:26:09.494415", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "old_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "newString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 420, "oldLines": 9, "newStart": 420, "newLines": 6, "lines": ["         ", "         prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "         ", "-        # Debug: Log the prompt being sent to LLM", "-        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")", "-        ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation", "             response = self._call_claude_task(prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:26:25.234923", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)", "old_string": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)", "newString": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 428, "oldLines": 16, "newStart": 428, "newLines": 8, "lines": ["             # Clean and validate AI response", "             if commit_message and len(commit_message) > 5:", "                 cleaned_message = self._clean_commit_message(commit_message)", "-                ", "-                # Check if it's actually a meaningful response vs fallback", "-                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():", "-                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")", "-                    return cleaned_message", "-                else:", "-                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")", "-                    return self._create_fallback_commit(tool_context, git_context)", "+                return cleaned_message", "             else:", "-                self._log_debug(f\"LLM response too short: {commit_message}\")", "                 return self._create_fallback_commit(tool_context, git_context)", "                 ", "         except Exception as e:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:34:08.793908", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:", "old_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "newString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 420, "oldLines": 6, "newStart": 420, "newLines": 9, "lines": ["         ", "         prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "         ", "+        # Debug: Log the actual prompt being sent", "+        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")", "+        ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation", "             response = self._call_claude_task(prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:34:35.705029", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                try:\n                    from .llms import ask_concise\n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "old_string": "                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "newString": "                try:\n                    from .llms import ask_concise\n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 593, "oldLines": 11, "newStart": 593, "newLines": 16, "lines": ["                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "                     from .llms import ask_concise", "+                    # Debug: Log what we're sending to LLM utility", "+                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")", "                     response = ask_concise(task_prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "-                    # Validate response is not a fallback", "-                    if response and response != \"AI response unavailable\" and len(response) > 10:", "+                    # Check if this is the hardcoded fallback", "+                    if response == \"chore: update files\":", "+                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")", "+                    elif response and response != \"AI response unavailable\" and len(response) > 10:", "+                        self._log_debug(f\"LLM gave meaningful response: {response}\")", "                         return response", "                     else:", "                         self._log_debug(\"LLM response appears to be fallback, trying original method\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:34:55.093940", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")", "old_string": "                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows", "newString": "                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 614, "oldLines": 20, "newStart": 614, "newLines": 39, "lines": ["                 ", "                 # Fallback to original claude command with Haiku for cost efficiency", "                 ", "-                result = subprocess.run([", "-                    self.claude_executable, ", "-                    \"--print\",  # Print response and exit (non-interactive)", "-                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency", "-                    \"--output-format\", \"text\",  # Plain text output only", "-                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",", "-                    f\"@{temp_file_path}\"  # Read prompt from file", "-                ], ", "-                capture_output=True, ", "-                text=True, ", "-                timeout=30,  # Reduced timeout for simple task", "-                cwd=pathlib.Path.cwd(),", "-                shell=True)  # Required for .cmd files on Windows", "+                # Try different claude command variations for Windows", "+                claude_commands = [", "+                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],", "+                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],", "+                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],", "+                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]", "+                ]", "                 ", "+                result = None", "+                for cmd in claude_commands:", "+                    try:", "+                        self._log_debug(f\"Trying claude command: {cmd[0]}\")", "+                        result = subprocess.run(", "+                            cmd,", "+                            capture_output=True, ", "+                            text=True, ", "+                            timeout=30,", "+                            cwd=pathlib.Path.cwd(),", "+                            shell=True", "+                        )", "+                        if result.returncode == 0:", "+                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")", "+                            break", "+                        else:", "+                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")", "+                    except Exception as e:", "+                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")", "+                        continue", "+                ", "+                if not result or result.returncode != 0:", "+                    self._log_debug(\"All claude commands failed\")", "+                    raise Exception(\"All claude command variations failed\")", "+                ", "                 if result.returncode == 0:", "                     raw_response = result.stdout.strip()", "                     self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:37:11.553935", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\config.py", "new_string": "    # Claude Executable Settings\n    claude_executable: str = \"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\"  # Full path for reliability", "old_string": "    # Claude Executable Settings\n    claude_executable: str = \"/c/Users/NATH/AppData/Local/pnpm/claude\"  # Full path for reliability", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\config.py", "oldString": "    # Claude Executable Settings\n    claude_executable: str = \"/c/Users/NATH/AppData/Local/pnpm/claude\"  # Full path for reliability", "newString": "    # Claude Executable Settings\n    claude_executable: str = \"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\"  # Full path for reliability", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\n\"\"\"\nLLM Configuration Management for Claude Code Hooks\nCentralized configuration for cost-efficient AI integration using Claude 3.5 Haiku\n\"\"\"\n\nimport os\nimport json\nimport pathlib\nfrom typing import Dict, Any, Optional\nfrom dataclasses import dataclass, asdict\n\n@dataclass\nclass LLMConfig:\n    \"\"\"Configuration for LLM client with cost-efficiency defaults.\"\"\"\n    \n    # Model Configuration\n    default_model: str = \"claude-3-5-haiku-20241022\"\n    fallback_models: list = None\n    \n    # Cost & Performance\n    default_timeout: int = 30\n    max_tokens: Optional[int] = None\n    temperature: float = 0.1\n    \n    # Claude Executable Settings\n    claude_executable: str = \"/c/Users/NATH/AppData/Local/pnpm/claude\"  # Full path for reliability\n    output_format: str = \"text\"\n    print_mode: bool = True\n    \n    # Cost Monitoring\n    enable_cost_tracking: bool = True\n    daily_token_budget: Optional[int] = None\n    warn_at_percentage: float = 0.8\n    \n    # Caching\n    enable_caching: bool = True\n    cache_ttl_minutes: int = 60\n    \n    # Logging\n    debug_logging: bool = True\n    log_path: str = \"C:/Users/NATH/.claude/hooks/debug.log\"\n    \n    def __post_init__(self):\n        \"\"\"Initialize default values after dataclass creation.\"\"\"\n        if self.fallback_models is None:\n            self.fallback_models = [\n                \"claude-3-5-haiku-20241022\",\n                \"claude-3-5-sonnet-20241022\", \n                \"manual_fallback\"\n            ]\n\nclass LLMConfigManager:\n    \"\"\"Manages LLM configuration with file persistence and environment overrides.\"\"\"\n    \n    def __init__(self, config_path: Optional[str] = None):\n        self.config_path = pathlib.Path(config_path or \"C:/Users/NATH/.claude/hooks/utils/llms/llm_config.json\")\n        self.config_path.parent.mkdir(parents=True, exist_ok=True)\n        self._config = None\n    \n    def load_config(self) -> LLMConfig:\n        \"\"\"Load configuration from file, environment, and defaults.\"\"\"\n        if self._config is not None:\n            return self._config\n            \n        # Start with defaults\n        config_dict = asdict(LLMConfig())\n        \n        # Override with file config if exists\n        if self.config_path.exists():\n            try:\n                with open(self.config_path, 'r') as f:\n                    file_config = json.load(f)\n                    config_dict.update(file_config)\n            except Exception:\n                pass  # Use defaults if file read fails\n        \n        # Override with environment variables\n        env_overrides = self._get_env_overrides()\n        config_dict.update(env_overrides)\n        \n        # Create config object\n        self._config = LLMConfig(**config_dict)\n        return self._config\n    \n    def save_config(self, config: LLMConfig) -> bool:\n        \"\"\"Save configuration to file.\"\"\"\n        try:\n            config_dict = asdict(config)\n            with open(self.config_path, 'w') as f:\n                json.dump(config_dict, f, indent=2)\n            self._config = config\n            return True\n        except Exception:\n            return False\n    \n    def _get_env_overrides(self) -> Dict[str, Any]:\n        \"\"\"Get configuration overrides from environment variables.\"\"\"\n        overrides = {}\n        \n        # Model settings\n        if os.getenv(\"CLAUDE_LLM_MODEL\"):\n            overrides[\"default_model\"] = os.getenv(\"CLAUDE_LLM_MODEL\")\n        \n        if os.getenv(\"CLAUDE_LLM_TIMEOUT\"):\n            try:\n                overrides[\"default_timeout\"] = int(os.getenv(\"CLAUDE_LLM_TIMEOUT\"))\n            except ValueError:\n                pass\n        \n        # Cost monitoring\n        if os.getenv(\"CLAUDE_LLM_BUDGET\"):\n            try:\n                overrides[\"daily_token_budget\"] = int(os.getenv(\"CLAUDE_LLM_BUDGET\"))\n            except ValueError:\n                pass\n        \n        # Executable path\n        if os.getenv(\"CLAUDE_EXECUTABLE\"):\n            overrides[\"claude_executable\"] = os.getenv(\"CLAUDE_EXECUTABLE\")\n        \n        # Debug mode\n        if os.getenv(\"CLAUDE_LLM_DEBUG\"):\n            overrides[\"debug_logging\"] = os.getenv(\"CLAUDE_LLM_DEBUG\").lower() in (\"true\", \"1\", \"yes\")\n        \n        return overrides\n    \n    def get_model_config(self, model_override: Optional[str] = None) -> Dict[str, str]:\n        \"\"\"Get model configuration for claude command.\"\"\"\n        config = self.load_config()\n        model = model_override or config.default_model\n        \n        return {\n            \"model\": model,\n            \"timeout\": str(config.default_timeout),\n            \"executable\": config.claude_executable,\n            \"output_format\": config.output_format\n        }\n    \n    def get_claude_args(self, model_override: Optional[str] = None, \n                       custom_system_prompt: Optional[str] = None) -> list:\n        \"\"\"Generate claude command arguments.\"\"\"\n        config = self.load_config()\n        model = model_override or config.default_model\n        \n        args = [\n            config.claude_executable,\n            \"--model\", model,\n            \"--output-format\", config.output_format\n        ]\n        \n        if config.print_mode:\n            args.append(\"--print\")\n        \n        if custom_system_prompt:\n            args.extend([\"--append-system-prompt\", custom_system_prompt])\n        \n        # Add temperature if not default\n        if config.temperature != 0.1:\n            args.extend([\"--temperature\", str(config.temperature)])\n        \n        return args\n\n# Global configuration instance\n_config_manager = None\n\ndef get_config_manager() -> LLMConfigManager:\n    \"\"\"Get global configuration manager instance.\"\"\"\n    global _config_manager\n    if _config_manager is None:\n        _config_manager = LLMConfigManager()\n    return _config_manager\n\ndef get_config() -> LLMConfig:\n    \"\"\"Get current LLM configuration.\"\"\"\n    return get_config_manager().load_config()\n\ndef update_config(**kwargs) -> bool:\n    \"\"\"Update configuration with new values.\"\"\"\n    manager = get_config_manager()\n    config = manager.load_config()\n    \n    # Update only provided fields\n    config_dict = asdict(config)\n    config_dict.update(kwargs)\n    \n    new_config = LLMConfig(**config_dict)\n    return manager.save_config(new_config)\n\n# Cost-efficient presets\nCOST_PRESETS = {\n    \"ultra_efficient\": {\n        \"default_model\": \"claude-3-5-haiku-20241022\",\n        \"temperature\": 0.0,\n        \"default_timeout\": 15,\n        \"enable_caching\": True\n    },\n    \"balanced\": {\n        \"default_model\": \"claude-3-5-haiku-20241022\", \n        \"temperature\": 0.1,\n        \"default_timeout\": 30,\n        \"enable_caching\": True\n    },\n    \"quality_focused\": {\n        \"default_model\": \"claude-3-5-sonnet-20241022\",\n        \"temperature\": 0.2,\n        \"default_timeout\": 45,\n        \"enable_caching\": False\n    }\n}\n\ndef apply_preset(preset_name: str) -> bool:\n    \"\"\"Apply a cost/quality preset configuration.\"\"\"\n    if preset_name not in COST_PRESETS:\n        return False\n    \n    preset_config = COST_PRESETS[preset_name]\n    return update_config(**preset_config)\n\nif __name__ == \"__main__\":\n    # Test configuration system\n    print(\"\u00f0\u0178\u201d\u00a7 Testing LLM Configuration System...\")\n    \n    manager = get_config_manager()\n    config = manager.load_config()\n    \n    print(f\"\u00e2\u0153\u2026 Default Model: {config.default_model}\")\n    print(f\"\u00e2\u0153\u2026 Fallback Models: {config.fallback_models}\")\n    print(f\"\u00e2\u0153\u2026 Cost Tracking: {config.enable_cost_tracking}\")\n    print(f\"\u00e2\u0153\u2026 Claude Args: {manager.get_claude_args()}\")\n    \n    print(\"\u00f0\u0178\u201d\u00a7 Configuration system ready!\")", "structuredPatch": [{"oldStart": 29, "oldLines": 7, "newStart": 29, "newLines": 7, "lines": ["     temperature: float = 0.1", "     ", "     # Claude Executable Settings", "-    claude_executable: str = \"/c/Users/NATH/AppData/Local/pnpm/claude\"  # Full path for reliability", "+    claude_executable: str = \"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\"  # Full path for reliability", "     output_format: str = \"text\"", "     print_mode: bool = True", "     "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:39:15.580158", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "new_string": "    try:\n        # Try specific claude paths for Windows (from 'where claude' command)\n        claude_paths = [\n            r'C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD',\n            r'C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd',\n            'claude.cmd',\n            'claude'\n        ]\n        \n        for cmd in claude_paths:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n                else:\n                    print(f\"Claude {cmd} failed: {result.stderr}\", flush=True)\n            except FileNotFoundError:\n                print(f\"Claude path not found: {cmd}\", flush=True)\n                continue\n            except Exception as e:\n                print(f\"Claude {cmd} error: {e}\", flush=True)\n                break", "old_string": "    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "oldString": "    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break", "newString": "    try:\n        # Try specific claude paths for Windows (from 'where claude' command)\n        claude_paths = [\n            r'C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD',\n            r'C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd',\n            'claude.cmd',\n            'claude'\n        ]\n        \n        for cmd in claude_paths:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n                else:\n                    print(f\"Claude {cmd} failed: {result.stderr}\", flush=True)\n            except FileNotFoundError:\n                print(f\"Claude path not found: {cmd}\", flush=True)\n                continue\n            except Exception as e:\n                print(f\"Claude {cmd} error: {e}\", flush=True)\n                break", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"  \n# dependencies = []\n# ///\n\n\"\"\"\nProduction LLM Client - Simple and Reliable\nUses pure claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\" approach\n\"\"\"\n\nimport subprocess\n\ndef ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break\n                \n    except Exception as e:\n        # Log the error for debugging\n        print(f\"LLM Error: {e}\", flush=True)\n    \n    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Cost-efficient concise queries.\"\"\"\n    return ask(f\"Be very brief: {prompt}\")\n\n# This will work perfectly in production hooks!\nif __name__ == \"__main__\":\n    print(\"Production LLM Client Ready!\")\n    print(\"Usage: from utils.llms.production_client import ask, ask_concise\")", "structuredPatch": [{"oldStart": 17, "oldLines": 10, "newStart": 17, "newLines": 15, "lines": ["     Works in production environments (PowerShell, cmd, normal Python)", "     \"\"\"", "     try:", "-        # Try different claude executable names for Windows", "-        claude_commands = ['claude', 'claude.exe', 'claude.cmd']", "+        # Try specific claude paths for Windows (from 'where claude' command)", "+        claude_paths = [", "+            r'C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD',", "+            r'C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd',", "+            'claude.cmd',", "+            'claude'", "+        ]", "         ", "-        for cmd in claude_commands:", "+        for cmd in claude_paths:", "             try:", "                 result = subprocess.run([", "                     cmd, '-p', '--model', model, prompt"]}, {"oldStart": 28, "oldLines": 9, "newStart": 33, "newLines": 13, "lines": ["                 ", "                 if result.returncode == 0:", "                     return result.stdout.strip()", "+                else:", "+                    print(f\"Claude {cmd} failed: {result.stderr}\", flush=True)", "             except FileNotFoundError:", "+                print(f\"Claude path not found: {cmd}\", flush=True)", "                 continue", "-            except:", "+            except Exception as e:", "+                print(f\"Claude {cmd} error: {e}\", flush=True)", "                 break", "                 ", "     except Exception as e:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:45:04.561771", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "new_string": "                # Ensure proper environment with pnpm path\n                import os\n                env = os.environ.copy()\n                \n                # Add pnpm path if not already there\n                pnpm_path = r'C:\\Users\\NATH\\AppData\\Local\\pnpm'\n                if 'PATH' in env and pnpm_path not in env['PATH']:\n                    env['PATH'] = pnpm_path + ';' + env['PATH']\n                elif 'PATH' not in env:\n                    env['PATH'] = pnpm_path\n                \n                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env  # Use Windows shell, not bash\n                )", "old_string": "                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    executable='/usr/bin/bash'  # Use the bash we know works\n                )", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "oldString": "                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    executable='/usr/bin/bash'  # Use the bash we know works\n                )", "newString": "                # Ensure proper environment with pnpm path\n                import os\n                env = os.environ.copy()\n                \n                # Add pnpm path if not already there\n                pnpm_path = r'C:\\Users\\NATH\\AppData\\Local\\pnpm'\n                if 'PATH' in env and pnpm_path not in env['PATH']:\n                    env['PATH'] = pnpm_path + ';' + env['PATH']\n                elif 'PATH' not in env:\n                    env['PATH'] = pnpm_path\n                \n                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env  # Use Windows shell, not bash\n                )", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\n\"\"\"\nLLM Client for Claude Code Hooks\nReusable, cost-efficient AI client using Claude 3.5 Haiku by default\nSupports the command structure: claude -p --model claude-3-5-haiku-20241022 \"<PROMPT>\"\n\"\"\"\n\nimport subprocess\nimport tempfile\nimport pathlib\nimport datetime\nimport json\nfrom typing import Dict, Any, Optional, List, Union\ntry:\n    from .config import get_config, get_config_manager, LLMConfig\nexcept ImportError:\n    from config import get_config, get_config_manager, LLMConfig\n\nclass LLMClient:\n    \"\"\"\n    Reusable LLM client for cost-efficient AI integration across Claude Code hooks.\n    \n    Features:\n    - Claude 3.5 Haiku by default for cost efficiency\n    - Automatic fallbacks: Haiku \u00e2\u2020\u2019 Sonnet \u00e2\u2020\u2019 Manual\n    - Response caching and token tracking\n    - Simple API: llm.ask(\"prompt\")\n    \"\"\"\n    \n    def __init__(self, config: Optional[LLMConfig] = None):\n        self.config = config or get_config()\n        self.config_manager = get_config_manager()\n        self.debug_log = pathlib.Path(self.config.log_path)\n        self._response_cache = {}\n    \n    def ask(self, prompt: str, model: Optional[str] = None, \n            max_tokens: Optional[int] = None, \n            system_prompt: Optional[str] = None) -> str:\n        \"\"\"\n        Ask the LLM a question with automatic fallbacks and caching.\n        \n        Args:\n            prompt: The question/task for the LLM\n            model: Override default model (optional)\n            max_tokens: Token limit override (optional)\n            system_prompt: Additional system instructions (optional)\n            \n        Returns:\n            str: The LLM's response, cleaned and validated\n        \"\"\"\n        try:\n            # Check cache first\n            cache_key = self._generate_cache_key(prompt, model, system_prompt)\n            if self.config.enable_caching and cache_key in self._response_cache:\n                cached_response = self._response_cache[cache_key]\n                if self._is_cache_valid(cached_response):\n                    self._log_debug(f\"Cache hit for prompt: {prompt[:50]}...\")\n                    return cached_response[\"response\"]\n            \n            # Try primary model\n            target_model = model or self.config.default_model\n            response = self._call_claude(prompt, target_model, system_prompt)\n            \n            if response and len(response.strip()) > 0:\n                # Cache successful response\n                if self.config.enable_caching:\n                    self._cache_response(cache_key, response)\n                \n                self._log_debug(f\"\u00e2\u0153\u2026 LLM success with {target_model}: {len(response)} chars\")\n                return response\n            \n            # Fallback to next model\n            return self._try_fallbacks(prompt, target_model, system_prompt)\n            \n        except Exception as e:\n            self._log_debug(f\"\u00e2\udc9d\u0152 LLM error: {e}\")\n            return self._try_fallbacks(prompt, model, system_prompt)\n    \n    def ask_concise(self, prompt: str, model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask for an ultra-concise response optimized for cost efficiency.\n        Uses aggressive compression and minimal tokens.\n        \"\"\"\n        concise_system = (\n            \"Be extremely concise. Use minimal tokens. \"\n            \"No explanations, examples, or elaboration. \"\n            \"Output only the essential answer.\"\n        )\n        \n        # Force haiku for maximum cost efficiency\n        efficient_model = model or \"claude-3-5-haiku-20241022\"\n        \n        return self.ask(prompt, efficient_model, max_tokens=100, system_prompt=concise_system)\n    \n    def ask_with_context(self, prompt: str, context_files: List[str] = None, \n                        model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask with additional context from files.\n        Automatically includes relevant file contents in the prompt.\n        \"\"\"\n        enhanced_prompt = prompt\n        \n        if context_files:\n            context_content = self._read_context_files(context_files)\n            enhanced_prompt = f\"Context:\\n{context_content}\\n\\nQuestion: {prompt}\"\n        \n        return self.ask(enhanced_prompt, model)\n    \n    def ask_structured(self, prompt: str, format_type: str = \"json\", \n                      model: Optional[str] = None) -> Union[Dict, List, str]:\n        \"\"\"\n        Ask for a structured response (JSON, list, etc.).\n        \n        Args:\n            prompt: The question/task\n            format_type: \"json\", \"list\", \"yaml\", or \"text\"\n            model: Model override\n            \n        Returns:\n            Parsed structured data or raw text\n        \"\"\"\n        format_instructions = {\n            \"json\": \"Respond with valid JSON only. No explanations.\",\n            \"list\": \"Respond with a numbered list only. No explanations.\",\n            \"yaml\": \"Respond with valid YAML only. No explanations.\",\n            \"text\": \"Respond with plain text only. No formatting.\"\n        }\n        \n        system_prompt = format_instructions.get(format_type, format_instructions[\"text\"])\n        response = self.ask(prompt, model, system_prompt=system_prompt)\n        \n        # Try to parse structured formats\n        if format_type == \"json\":\n            try:\n                return json.loads(response)\n            except json.JSONDecodeError:\n                return {\"error\": \"Invalid JSON\", \"raw_response\": response}\n        elif format_type == \"list\":\n            return [line.strip() for line in response.split('\\n') if line.strip()]\n        \n        return response\n    \n    def _call_claude(self, prompt: str, model: str, system_prompt: Optional[str] = None) -> str:\n        \"\"\"Call Claude executable with the specified model and prompt.\"\"\"\n        try:\n            # Create temporary file for prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                temp_file.write(prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Build command arguments\n                args = self.config_manager.get_claude_args(model, system_prompt)\n                args.append(f\"@{temp_file_path}\")\n                \n                self._log_debug(f\"Calling: {' '.join(args[:4])} @prompt ({len(prompt)} chars)\")\n                \n                # Execute command - build command string for shell execution\n                command_str = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in args)\n                \n                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    executable='/usr/bin/bash'  # Use the bash we know works\n                )\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    cleaned_response = self._clean_response(raw_response)\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude failed: {result.stderr}\")\n                    raise Exception(f\"Claude failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(f\"Claude timeout ({self.config.default_timeout}s)\")\n            raise Exception(\"Claude timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude call error: {e}\")\n            raise\n    \n    def _try_fallbacks(self, prompt: str, failed_model: Optional[str], \n                      system_prompt: Optional[str]) -> str:\n        \"\"\"Try fallback models when primary model fails.\"\"\"\n        fallback_models = [m for m in self.config.fallback_models if m != failed_model]\n        \n        for fallback_model in fallback_models:\n            if fallback_model == \"manual_fallback\":\n                return self._manual_fallback(prompt)\n            \n            try:\n                self._log_debug(f\"Trying fallback: {fallback_model}\")\n                response = self._call_claude(prompt, fallback_model, system_prompt)\n                if response and len(response.strip()) > 0:\n                    self._log_debug(f\"\u00e2\u0153\u2026 Fallback success: {fallback_model}\")\n                    return response\n            except Exception as e:\n                self._log_debug(f\"Fallback {fallback_model} failed: {e}\")\n                continue\n        \n        # All fallbacks failed\n        return self._manual_fallback(prompt)\n    \n    def _manual_fallback(self, prompt: str) -> str:\n        \"\"\"Generate a manual fallback response when all AI models fail.\"\"\"\n        self._log_debug(\"All AI models failed, using manual fallback\")\n        \n        # Simple keyword-based responses for common tasks\n        prompt_lower = prompt.lower()\n        \n        if any(word in prompt_lower for word in [\"commit\", \"git\", \"message\"]):\n            return \"chore: update files\"\n        elif any(word in prompt_lower for word in [\"explain\", \"what\", \"how\"]):\n            return \"Unable to generate explanation - AI models unavailable\"\n        elif any(word in prompt_lower for word in [\"error\", \"debug\", \"fix\"]):\n            return \"Error analysis unavailable - check logs and documentation\"\n        elif any(word in prompt_lower for word in [\"summary\", \"summarize\"]):\n            return \"Summary unavailable - AI models unavailable\"\n        else:\n            return \"AI response unavailable - please try again later\"\n    \n    def _clean_response(self, response: str) -> str:\n        \"\"\"Clean and validate AI response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and suffixes\n        cleaned = response.strip()\n        \n        # Remove quotes if response is entirely quoted\n        if cleaned.startswith('\"') and cleaned.endswith('\"'):\n            cleaned = cleaned[1:-1]\n        elif cleaned.startswith(\"'\") and cleaned.endswith(\"'\"):\n            cleaned = cleaned[1:-1]\n        \n        # Remove markdown code blocks\n        if cleaned.startswith(\"```\") and cleaned.endswith(\"```\"):\n            lines = cleaned.split('\\n')\n            if len(lines) > 2:\n                cleaned = '\\n'.join(lines[1:-1])\n        \n        return cleaned.strip()\n    \n    def _read_context_files(self, file_paths: List[str]) -> str:\n        \"\"\"Read content from context files.\"\"\"\n        context_parts = []\n        \n        for file_path in file_paths:\n            try:\n                path_obj = pathlib.Path(file_path)\n                if path_obj.exists() and path_obj.is_file():\n                    with open(path_obj, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n                        if len(content) > 2000:  # Limit context size\n                            content = content[:2000] + \"...\"\n                        context_parts.append(f\"File: {file_path}\\n{content}\\n\")\n            except Exception:\n                context_parts.append(f\"File: {file_path}\\n[Unable to read file]\\n\")\n        \n        return '\\n'.join(context_parts)\n    \n    def _generate_cache_key(self, prompt: str, model: Optional[str], \n                           system_prompt: Optional[str]) -> str:\n        \"\"\"Generate cache key for response caching.\"\"\"\n        key_parts = [\n            prompt[:100],  # First 100 chars of prompt\n            model or self.config.default_model,\n            system_prompt or \"\"\n        ]\n        return str(hash(tuple(key_parts)))\n    \n    def _cache_response(self, cache_key: str, response: str):\n        \"\"\"Cache a response with timestamp.\"\"\"\n        self._response_cache[cache_key] = {\n            \"response\": response,\n            \"timestamp\": datetime.datetime.now(),\n            \"ttl_minutes\": self.config.cache_ttl_minutes\n        }\n        \n        # Simple cache cleanup - remove old entries\n        if len(self._response_cache) > 100:\n            old_keys = list(self._response_cache.keys())[:20]\n            for old_key in old_keys:\n                del self._response_cache[old_key]\n    \n    def _is_cache_valid(self, cached_item: Dict) -> bool:\n        \"\"\"Check if cached response is still valid.\"\"\"\n        if not self.config.enable_caching:\n            return False\n        \n        elapsed = datetime.datetime.now() - cached_item[\"timestamp\"]\n        ttl_minutes = cached_item.get(\"ttl_minutes\", self.config.cache_ttl_minutes)\n        \n        return elapsed.total_seconds() < (ttl_minutes * 60)\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information.\"\"\"\n        if not self.config.debug_logging:\n            return\n        \n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - LLMClient: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n    \n    def get_usage_stats(self) -> Dict[str, Any]:\n        \"\"\"Get basic usage statistics.\"\"\"\n        return {\n            \"cache_size\": len(self._response_cache),\n            \"default_model\": self.config.default_model,\n            \"caching_enabled\": self.config.enable_caching,\n            \"cost_tracking_enabled\": self.config.enable_cost_tracking\n        }\n\n# Convenience functions for simple usage\ndef ask(prompt: str, model: Optional[str] = None) -> str:\n    \"\"\"Quick ask function for simple queries.\"\"\"\n    client = LLMClient()\n    return client.ask(prompt, model)\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Quick concise ask for cost-efficient queries.\"\"\"\n    client = LLMClient()\n    return client.ask_concise(prompt)\n\ndef ask_json(prompt: str) -> Dict:\n    \"\"\"Quick ask for JSON responses.\"\"\"\n    client = LLMClient()\n    return client.ask_structured(prompt, \"json\")\n\n# Test function\ndef test_llm_client():\n    \"\"\"Test LLM client functionality.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing LLM Client...\")\n    \n    client = LLMClient()\n    \n    # Test basic ask\n    try:\n        response = client.ask(\"What is 2+2? Answer with just the number.\")\n        print(f\"\u00e2\u0153\u2026 Basic ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Basic ask failed: {e}\")\n    \n    # Test concise ask\n    try:\n        response = client.ask_concise(\"Current year\")\n        print(f\"\u00e2\u0153\u2026 Concise ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Concise ask failed: {e}\")\n    \n    # Test usage stats\n    stats = client.get_usage_stats()\n    print(f\"\u00e2\u0153\u2026 Usage stats: {stats}\")\n    \n    print(\"\u00f0\u0178\u00a7\u00aa LLM Client test completed!\")\n\nif __name__ == \"__main__\":\n    test_llm_client()", "structuredPatch": [{"oldStart": 163, "oldLines": 6, "newStart": 163, "newLines": 17, "lines": ["                 # Execute command - build command string for shell execution", "                 command_str = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in args)", "                 ", "+                # Ensure proper environment with pnpm path", "+                import os", "+                env = os.environ.copy()", "+                ", "+                # Add pnpm path if not already there", "+                pnpm_path = r'C:\\Users\\NATH\\AppData\\Local\\pnpm'", "+                if 'PATH' in env and pnpm_path not in env['PATH']:", "+                    env['PATH'] = pnpm_path + ';' + env['PATH']", "+                elif 'PATH' not in env:", "+                    env['PATH'] = pnpm_path", "+                ", "                 result = subprocess.run(", "                     command_str,", "                     capture_output=True,"]}, {"oldStart": 170, "oldLines": 7, "newStart": 181, "newLines": 7, "lines": ["                     timeout=self.config.default_timeout,", "                     cwd=pathlib.Path.cwd(),", "                     shell=True,", "-                    executable='/usr/bin/bash'  # Use the bash we know works", "+                    env=env  # Use Windows shell, not bash", "                 )", "                 ", "                 if result.returncode == 0:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:48:12.308246", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "new_string": "                # Try direct execution without shell for better Windows compatibility\n                import os\n                env = os.environ.copy()\n                \n                # Try to find the actual Claude executable\n                claude_exe = None\n                potential_paths = [\n                    r\"C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD\",\n                    r\"C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd\",\n                    \"claude.cmd\",\n                    \"claude\"\n                ]\n                \n                for path in potential_paths:\n                    if pathlib.Path(path).exists() or path in [\"claude.cmd\", \"claude\"]:\n                        claude_exe = path\n                        break\n                \n                if not claude_exe:\n                    raise FileNotFoundError(\"Claude executable not found in any expected location\")\n                \n                # Build direct command arguments\n                cmd_args = [claude_exe] + args[1:]  # Skip the first arg which is the executable path\n                \n                self._log_debug(f\"Executing: {cmd_args[0]} with {len(cmd_args)-1} args\")\n                \n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,  # Use shell for .cmd files on Windows\n                    env=env\n                )", "old_string": "                # Execute command - build command string for shell execution\n                command_str = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in args)\n                \n                # Ensure proper environment with pnpm path\n                import os\n                env = os.environ.copy()\n                \n                # Add pnpm path if not already there\n                pnpm_path = r'C:\\Users\\NATH\\AppData\\Local\\pnpm'\n                if 'PATH' in env and pnpm_path not in env['PATH']:\n                    env['PATH'] = pnpm_path + ';' + env['PATH']\n                elif 'PATH' not in env:\n                    env['PATH'] = pnpm_path\n                \n                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env  # Use Windows shell, not bash\n                )", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "oldString": "                # Execute command - build command string for shell execution\n                command_str = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in args)\n                \n                # Ensure proper environment with pnpm path\n                import os\n                env = os.environ.copy()\n                \n                # Add pnpm path if not already there\n                pnpm_path = r'C:\\Users\\NATH\\AppData\\Local\\pnpm'\n                if 'PATH' in env and pnpm_path not in env['PATH']:\n                    env['PATH'] = pnpm_path + ';' + env['PATH']\n                elif 'PATH' not in env:\n                    env['PATH'] = pnpm_path\n                \n                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env  # Use Windows shell, not bash\n                )", "newString": "                # Try direct execution without shell for better Windows compatibility\n                import os\n                env = os.environ.copy()\n                \n                # Try to find the actual Claude executable\n                claude_exe = None\n                potential_paths = [\n                    r\"C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD\",\n                    r\"C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd\",\n                    \"claude.cmd\",\n                    \"claude\"\n                ]\n                \n                for path in potential_paths:\n                    if pathlib.Path(path).exists() or path in [\"claude.cmd\", \"claude\"]:\n                        claude_exe = path\n                        break\n                \n                if not claude_exe:\n                    raise FileNotFoundError(\"Claude executable not found in any expected location\")\n                \n                # Build direct command arguments\n                cmd_args = [claude_exe] + args[1:]  # Skip the first arg which is the executable path\n                \n                self._log_debug(f\"Executing: {cmd_args[0]} with {len(cmd_args)-1} args\")\n                \n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,  # Use shell for .cmd files on Windows\n                    env=env\n                )", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\n\"\"\"\nLLM Client for Claude Code Hooks\nReusable, cost-efficient AI client using Claude 3.5 Haiku by default\nSupports the command structure: claude -p --model claude-3-5-haiku-20241022 \"<PROMPT>\"\n\"\"\"\n\nimport subprocess\nimport tempfile\nimport pathlib\nimport datetime\nimport json\nfrom typing import Dict, Any, Optional, List, Union\ntry:\n    from .config import get_config, get_config_manager, LLMConfig\nexcept ImportError:\n    from config import get_config, get_config_manager, LLMConfig\n\nclass LLMClient:\n    \"\"\"\n    Reusable LLM client for cost-efficient AI integration across Claude Code hooks.\n    \n    Features:\n    - Claude 3.5 Haiku by default for cost efficiency\n    - Automatic fallbacks: Haiku \u00e2\u2020\u2019 Sonnet \u00e2\u2020\u2019 Manual\n    - Response caching and token tracking\n    - Simple API: llm.ask(\"prompt\")\n    \"\"\"\n    \n    def __init__(self, config: Optional[LLMConfig] = None):\n        self.config = config or get_config()\n        self.config_manager = get_config_manager()\n        self.debug_log = pathlib.Path(self.config.log_path)\n        self._response_cache = {}\n    \n    def ask(self, prompt: str, model: Optional[str] = None, \n            max_tokens: Optional[int] = None, \n            system_prompt: Optional[str] = None) -> str:\n        \"\"\"\n        Ask the LLM a question with automatic fallbacks and caching.\n        \n        Args:\n            prompt: The question/task for the LLM\n            model: Override default model (optional)\n            max_tokens: Token limit override (optional)\n            system_prompt: Additional system instructions (optional)\n            \n        Returns:\n            str: The LLM's response, cleaned and validated\n        \"\"\"\n        try:\n            # Check cache first\n            cache_key = self._generate_cache_key(prompt, model, system_prompt)\n            if self.config.enable_caching and cache_key in self._response_cache:\n                cached_response = self._response_cache[cache_key]\n                if self._is_cache_valid(cached_response):\n                    self._log_debug(f\"Cache hit for prompt: {prompt[:50]}...\")\n                    return cached_response[\"response\"]\n            \n            # Try primary model\n            target_model = model or self.config.default_model\n            response = self._call_claude(prompt, target_model, system_prompt)\n            \n            if response and len(response.strip()) > 0:\n                # Cache successful response\n                if self.config.enable_caching:\n                    self._cache_response(cache_key, response)\n                \n                self._log_debug(f\"\u00e2\u0153\u2026 LLM success with {target_model}: {len(response)} chars\")\n                return response\n            \n            # Fallback to next model\n            return self._try_fallbacks(prompt, target_model, system_prompt)\n            \n        except Exception as e:\n            self._log_debug(f\"\u00e2\udc9d\u0152 LLM error: {e}\")\n            return self._try_fallbacks(prompt, model, system_prompt)\n    \n    def ask_concise(self, prompt: str, model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask for an ultra-concise response optimized for cost efficiency.\n        Uses aggressive compression and minimal tokens.\n        \"\"\"\n        concise_system = (\n            \"Be extremely concise. Use minimal tokens. \"\n            \"No explanations, examples, or elaboration. \"\n            \"Output only the essential answer.\"\n        )\n        \n        # Force haiku for maximum cost efficiency\n        efficient_model = model or \"claude-3-5-haiku-20241022\"\n        \n        return self.ask(prompt, efficient_model, max_tokens=100, system_prompt=concise_system)\n    \n    def ask_with_context(self, prompt: str, context_files: List[str] = None, \n                        model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask with additional context from files.\n        Automatically includes relevant file contents in the prompt.\n        \"\"\"\n        enhanced_prompt = prompt\n        \n        if context_files:\n            context_content = self._read_context_files(context_files)\n            enhanced_prompt = f\"Context:\\n{context_content}\\n\\nQuestion: {prompt}\"\n        \n        return self.ask(enhanced_prompt, model)\n    \n    def ask_structured(self, prompt: str, format_type: str = \"json\", \n                      model: Optional[str] = None) -> Union[Dict, List, str]:\n        \"\"\"\n        Ask for a structured response (JSON, list, etc.).\n        \n        Args:\n            prompt: The question/task\n            format_type: \"json\", \"list\", \"yaml\", or \"text\"\n            model: Model override\n            \n        Returns:\n            Parsed structured data or raw text\n        \"\"\"\n        format_instructions = {\n            \"json\": \"Respond with valid JSON only. No explanations.\",\n            \"list\": \"Respond with a numbered list only. No explanations.\",\n            \"yaml\": \"Respond with valid YAML only. No explanations.\",\n            \"text\": \"Respond with plain text only. No formatting.\"\n        }\n        \n        system_prompt = format_instructions.get(format_type, format_instructions[\"text\"])\n        response = self.ask(prompt, model, system_prompt=system_prompt)\n        \n        # Try to parse structured formats\n        if format_type == \"json\":\n            try:\n                return json.loads(response)\n            except json.JSONDecodeError:\n                return {\"error\": \"Invalid JSON\", \"raw_response\": response}\n        elif format_type == \"list\":\n            return [line.strip() for line in response.split('\\n') if line.strip()]\n        \n        return response\n    \n    def _call_claude(self, prompt: str, model: str, system_prompt: Optional[str] = None) -> str:\n        \"\"\"Call Claude executable with the specified model and prompt.\"\"\"\n        try:\n            # Create temporary file for prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                temp_file.write(prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Build command arguments\n                args = self.config_manager.get_claude_args(model, system_prompt)\n                args.append(f\"@{temp_file_path}\")\n                \n                self._log_debug(f\"Calling: {' '.join(args[:4])} @prompt ({len(prompt)} chars)\")\n                \n                # Execute command - build command string for shell execution\n                command_str = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in args)\n                \n                # Ensure proper environment with pnpm path\n                import os\n                env = os.environ.copy()\n                \n                # Add pnpm path if not already there\n                pnpm_path = r'C:\\Users\\NATH\\AppData\\Local\\pnpm'\n                if 'PATH' in env and pnpm_path not in env['PATH']:\n                    env['PATH'] = pnpm_path + ';' + env['PATH']\n                elif 'PATH' not in env:\n                    env['PATH'] = pnpm_path\n                \n                result = subprocess.run(\n                    command_str,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env  # Use Windows shell, not bash\n                )\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    cleaned_response = self._clean_response(raw_response)\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude failed: {result.stderr}\")\n                    raise Exception(f\"Claude failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(f\"Claude timeout ({self.config.default_timeout}s)\")\n            raise Exception(\"Claude timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude call error: {e}\")\n            raise\n    \n    def _try_fallbacks(self, prompt: str, failed_model: Optional[str], \n                      system_prompt: Optional[str]) -> str:\n        \"\"\"Try fallback models when primary model fails.\"\"\"\n        fallback_models = [m for m in self.config.fallback_models if m != failed_model]\n        \n        for fallback_model in fallback_models:\n            if fallback_model == \"manual_fallback\":\n                return self._manual_fallback(prompt)\n            \n            try:\n                self._log_debug(f\"Trying fallback: {fallback_model}\")\n                response = self._call_claude(prompt, fallback_model, system_prompt)\n                if response and len(response.strip()) > 0:\n                    self._log_debug(f\"\u00e2\u0153\u2026 Fallback success: {fallback_model}\")\n                    return response\n            except Exception as e:\n                self._log_debug(f\"Fallback {fallback_model} failed: {e}\")\n                continue\n        \n        # All fallbacks failed\n        return self._manual_fallback(prompt)\n    \n    def _manual_fallback(self, prompt: str) -> str:\n        \"\"\"Generate a manual fallback response when all AI models fail.\"\"\"\n        self._log_debug(\"All AI models failed, using manual fallback\")\n        \n        # Simple keyword-based responses for common tasks\n        prompt_lower = prompt.lower()\n        \n        if any(word in prompt_lower for word in [\"commit\", \"git\", \"message\"]):\n            return \"chore: update files\"\n        elif any(word in prompt_lower for word in [\"explain\", \"what\", \"how\"]):\n            return \"Unable to generate explanation - AI models unavailable\"\n        elif any(word in prompt_lower for word in [\"error\", \"debug\", \"fix\"]):\n            return \"Error analysis unavailable - check logs and documentation\"\n        elif any(word in prompt_lower for word in [\"summary\", \"summarize\"]):\n            return \"Summary unavailable - AI models unavailable\"\n        else:\n            return \"AI response unavailable - please try again later\"\n    \n    def _clean_response(self, response: str) -> str:\n        \"\"\"Clean and validate AI response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and suffixes\n        cleaned = response.strip()\n        \n        # Remove quotes if response is entirely quoted\n        if cleaned.startswith('\"') and cleaned.endswith('\"'):\n            cleaned = cleaned[1:-1]\n        elif cleaned.startswith(\"'\") and cleaned.endswith(\"'\"):\n            cleaned = cleaned[1:-1]\n        \n        # Remove markdown code blocks\n        if cleaned.startswith(\"```\") and cleaned.endswith(\"```\"):\n            lines = cleaned.split('\\n')\n            if len(lines) > 2:\n                cleaned = '\\n'.join(lines[1:-1])\n        \n        return cleaned.strip()\n    \n    def _read_context_files(self, file_paths: List[str]) -> str:\n        \"\"\"Read content from context files.\"\"\"\n        context_parts = []\n        \n        for file_path in file_paths:\n            try:\n                path_obj = pathlib.Path(file_path)\n                if path_obj.exists() and path_obj.is_file():\n                    with open(path_obj, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n                        if len(content) > 2000:  # Limit context size\n                            content = content[:2000] + \"...\"\n                        context_parts.append(f\"File: {file_path}\\n{content}\\n\")\n            except Exception:\n                context_parts.append(f\"File: {file_path}\\n[Unable to read file]\\n\")\n        \n        return '\\n'.join(context_parts)\n    \n    def _generate_cache_key(self, prompt: str, model: Optional[str], \n                           system_prompt: Optional[str]) -> str:\n        \"\"\"Generate cache key for response caching.\"\"\"\n        key_parts = [\n            prompt[:100],  # First 100 chars of prompt\n            model or self.config.default_model,\n            system_prompt or \"\"\n        ]\n        return str(hash(tuple(key_parts)))\n    \n    def _cache_response(self, cache_key: str, response: str):\n        \"\"\"Cache a response with timestamp.\"\"\"\n        self._response_cache[cache_key] = {\n            \"response\": response,\n            \"timestamp\": datetime.datetime.now(),\n            \"ttl_minutes\": self.config.cache_ttl_minutes\n        }\n        \n        # Simple cache cleanup - remove old entries\n        if len(self._response_cache) > 100:\n            old_keys = list(self._response_cache.keys())[:20]\n            for old_key in old_keys:\n                del self._response_cache[old_key]\n    \n    def _is_cache_valid(self, cached_item: Dict) -> bool:\n        \"\"\"Check if cached response is still valid.\"\"\"\n        if not self.config.enable_caching:\n            return False\n        \n        elapsed = datetime.datetime.now() - cached_item[\"timestamp\"]\n        ttl_minutes = cached_item.get(\"ttl_minutes\", self.config.cache_ttl_minutes)\n        \n        return elapsed.total_seconds() < (ttl_minutes * 60)\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information.\"\"\"\n        if not self.config.debug_logging:\n            return\n        \n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - LLMClient: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n    \n    def get_usage_stats(self) -> Dict[str, Any]:\n        \"\"\"Get basic usage statistics.\"\"\"\n        return {\n            \"cache_size\": len(self._response_cache),\n            \"default_model\": self.config.default_model,\n            \"caching_enabled\": self.config.enable_caching,\n            \"cost_tracking_enabled\": self.config.enable_cost_tracking\n        }\n\n# Convenience functions for simple usage\ndef ask(prompt: str, model: Optional[str] = None) -> str:\n    \"\"\"Quick ask function for simple queries.\"\"\"\n    client = LLMClient()\n    return client.ask(prompt, model)\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Quick concise ask for cost-efficient queries.\"\"\"\n    client = LLMClient()\n    return client.ask_concise(prompt)\n\ndef ask_json(prompt: str) -> Dict:\n    \"\"\"Quick ask for JSON responses.\"\"\"\n    client = LLMClient()\n    return client.ask_structured(prompt, \"json\")\n\n# Test function\ndef test_llm_client():\n    \"\"\"Test LLM client functionality.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing LLM Client...\")\n    \n    client = LLMClient()\n    \n    # Test basic ask\n    try:\n        response = client.ask(\"What is 2+2? Answer with just the number.\")\n        print(f\"\u00e2\u0153\u2026 Basic ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Basic ask failed: {e}\")\n    \n    # Test concise ask\n    try:\n        response = client.ask_concise(\"Current year\")\n        print(f\"\u00e2\u0153\u2026 Concise ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Concise ask failed: {e}\")\n    \n    # Test usage stats\n    stats = client.get_usage_stats()\n    print(f\"\u00e2\u0153\u2026 Usage stats: {stats}\")\n    \n    print(\"\u00f0\u0178\u00a7\u00aa LLM Client test completed!\")\n\nif __name__ == \"__main__\":\n    test_llm_client()", "structuredPatch": [{"oldStart": 160, "oldLines": 28, "newStart": 160, "newLines": 40, "lines": ["                 ", "                 self._log_debug(f\"Calling: {' '.join(args[:4])} @prompt ({len(prompt)} chars)\")", "                 ", "-                # Execute command - build command string for shell execution", "-                command_str = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in args)", "-                ", "-                # Ensure proper environment with pnpm path", "+                # Try direct execution without shell for better Windows compatibility", "                 import os", "                 env = os.environ.copy()", "                 ", "-                # Add pnpm path if not already there", "-                pnpm_path = r'C:\\Users\\NATH\\AppData\\Local\\pnpm'", "-                if 'PATH' in env and pnpm_path not in env['PATH']:", "-                    env['PATH'] = pnpm_path + ';' + env['PATH']", "-                elif 'PATH' not in env:", "-                    env['PATH'] = pnpm_path", "+                # Try to find the actual Claude executable", "+                claude_exe = None", "+                potential_paths = [", "+                    r\"C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD\",", "+                    r\"C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd\",", "+                    \"claude.cmd\",", "+                    \"claude\"", "+                ]", "                 ", "+                for path in potential_paths:", "+                    if pathlib.Path(path).exists() or path in [\"claude.cmd\", \"claude\"]:", "+                        claude_exe = path", "+                        break", "+                ", "+                if not claude_exe:", "+                    raise FileNotFoundError(\"Claude executable not found in any expected location\")", "+                ", "+                # Build direct command arguments", "+                cmd_args = [claude_exe] + args[1:]  # Skip the first arg which is the executable path", "+                ", "+                self._log_debug(f\"Executing: {cmd_args[0]} with {len(cmd_args)-1} args\")", "+                ", "                 result = subprocess.run(", "-                    command_str,", "+                    cmd_args,", "                     capture_output=True,", "                     text=True,", "                     timeout=self.config.default_timeout,", "                     cwd=pathlib.Path.cwd(),", "-                    shell=True,", "-                    env=env  # Use Windows shell, not bash", "+                    shell=True,  # Use shell for .cmd files on Windows", "+                    env=env", "                 )", "                 ", "                 if result.returncode == 0:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:48:48.276058", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "new_string": "                # Force Windows CMD shell instead of bash\n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env,\n                    executable=None  # Let Windows choose the shell\n                )", "old_string": "                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,  # Use shell for .cmd files on Windows\n                    env=env\n                )", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "oldString": "                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,  # Use shell for .cmd files on Windows\n                    env=env\n                )", "newString": "                # Force Windows CMD shell instead of bash\n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env,\n                    executable=None  # Let Windows choose the shell\n                )", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\n\"\"\"\nLLM Client for Claude Code Hooks\nReusable, cost-efficient AI client using Claude 3.5 Haiku by default\nSupports the command structure: claude -p --model claude-3-5-haiku-20241022 \"<PROMPT>\"\n\"\"\"\n\nimport subprocess\nimport tempfile\nimport pathlib\nimport datetime\nimport json\nfrom typing import Dict, Any, Optional, List, Union\ntry:\n    from .config import get_config, get_config_manager, LLMConfig\nexcept ImportError:\n    from config import get_config, get_config_manager, LLMConfig\n\nclass LLMClient:\n    \"\"\"\n    Reusable LLM client for cost-efficient AI integration across Claude Code hooks.\n    \n    Features:\n    - Claude 3.5 Haiku by default for cost efficiency\n    - Automatic fallbacks: Haiku \u00e2\u2020\u2019 Sonnet \u00e2\u2020\u2019 Manual\n    - Response caching and token tracking\n    - Simple API: llm.ask(\"prompt\")\n    \"\"\"\n    \n    def __init__(self, config: Optional[LLMConfig] = None):\n        self.config = config or get_config()\n        self.config_manager = get_config_manager()\n        self.debug_log = pathlib.Path(self.config.log_path)\n        self._response_cache = {}\n    \n    def ask(self, prompt: str, model: Optional[str] = None, \n            max_tokens: Optional[int] = None, \n            system_prompt: Optional[str] = None) -> str:\n        \"\"\"\n        Ask the LLM a question with automatic fallbacks and caching.\n        \n        Args:\n            prompt: The question/task for the LLM\n            model: Override default model (optional)\n            max_tokens: Token limit override (optional)\n            system_prompt: Additional system instructions (optional)\n            \n        Returns:\n            str: The LLM's response, cleaned and validated\n        \"\"\"\n        try:\n            # Check cache first\n            cache_key = self._generate_cache_key(prompt, model, system_prompt)\n            if self.config.enable_caching and cache_key in self._response_cache:\n                cached_response = self._response_cache[cache_key]\n                if self._is_cache_valid(cached_response):\n                    self._log_debug(f\"Cache hit for prompt: {prompt[:50]}...\")\n                    return cached_response[\"response\"]\n            \n            # Try primary model\n            target_model = model or self.config.default_model\n            response = self._call_claude(prompt, target_model, system_prompt)\n            \n            if response and len(response.strip()) > 0:\n                # Cache successful response\n                if self.config.enable_caching:\n                    self._cache_response(cache_key, response)\n                \n                self._log_debug(f\"\u00e2\u0153\u2026 LLM success with {target_model}: {len(response)} chars\")\n                return response\n            \n            # Fallback to next model\n            return self._try_fallbacks(prompt, target_model, system_prompt)\n            \n        except Exception as e:\n            self._log_debug(f\"\u00e2\udc9d\u0152 LLM error: {e}\")\n            return self._try_fallbacks(prompt, model, system_prompt)\n    \n    def ask_concise(self, prompt: str, model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask for an ultra-concise response optimized for cost efficiency.\n        Uses aggressive compression and minimal tokens.\n        \"\"\"\n        concise_system = (\n            \"Be extremely concise. Use minimal tokens. \"\n            \"No explanations, examples, or elaboration. \"\n            \"Output only the essential answer.\"\n        )\n        \n        # Force haiku for maximum cost efficiency\n        efficient_model = model or \"claude-3-5-haiku-20241022\"\n        \n        return self.ask(prompt, efficient_model, max_tokens=100, system_prompt=concise_system)\n    \n    def ask_with_context(self, prompt: str, context_files: List[str] = None, \n                        model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask with additional context from files.\n        Automatically includes relevant file contents in the prompt.\n        \"\"\"\n        enhanced_prompt = prompt\n        \n        if context_files:\n            context_content = self._read_context_files(context_files)\n            enhanced_prompt = f\"Context:\\n{context_content}\\n\\nQuestion: {prompt}\"\n        \n        return self.ask(enhanced_prompt, model)\n    \n    def ask_structured(self, prompt: str, format_type: str = \"json\", \n                      model: Optional[str] = None) -> Union[Dict, List, str]:\n        \"\"\"\n        Ask for a structured response (JSON, list, etc.).\n        \n        Args:\n            prompt: The question/task\n            format_type: \"json\", \"list\", \"yaml\", or \"text\"\n            model: Model override\n            \n        Returns:\n            Parsed structured data or raw text\n        \"\"\"\n        format_instructions = {\n            \"json\": \"Respond with valid JSON only. No explanations.\",\n            \"list\": \"Respond with a numbered list only. No explanations.\",\n            \"yaml\": \"Respond with valid YAML only. No explanations.\",\n            \"text\": \"Respond with plain text only. No formatting.\"\n        }\n        \n        system_prompt = format_instructions.get(format_type, format_instructions[\"text\"])\n        response = self.ask(prompt, model, system_prompt=system_prompt)\n        \n        # Try to parse structured formats\n        if format_type == \"json\":\n            try:\n                return json.loads(response)\n            except json.JSONDecodeError:\n                return {\"error\": \"Invalid JSON\", \"raw_response\": response}\n        elif format_type == \"list\":\n            return [line.strip() for line in response.split('\\n') if line.strip()]\n        \n        return response\n    \n    def _call_claude(self, prompt: str, model: str, system_prompt: Optional[str] = None) -> str:\n        \"\"\"Call Claude executable with the specified model and prompt.\"\"\"\n        try:\n            # Create temporary file for prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                temp_file.write(prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Build command arguments\n                args = self.config_manager.get_claude_args(model, system_prompt)\n                args.append(f\"@{temp_file_path}\")\n                \n                self._log_debug(f\"Calling: {' '.join(args[:4])} @prompt ({len(prompt)} chars)\")\n                \n                # Try direct execution without shell for better Windows compatibility\n                import os\n                env = os.environ.copy()\n                \n                # Try to find the actual Claude executable\n                claude_exe = None\n                potential_paths = [\n                    r\"C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD\",\n                    r\"C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd\",\n                    \"claude.cmd\",\n                    \"claude\"\n                ]\n                \n                for path in potential_paths:\n                    if pathlib.Path(path).exists() or path in [\"claude.cmd\", \"claude\"]:\n                        claude_exe = path\n                        break\n                \n                if not claude_exe:\n                    raise FileNotFoundError(\"Claude executable not found in any expected location\")\n                \n                # Build direct command arguments\n                cmd_args = [claude_exe] + args[1:]  # Skip the first arg which is the executable path\n                \n                self._log_debug(f\"Executing: {cmd_args[0]} with {len(cmd_args)-1} args\")\n                \n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,  # Use shell for .cmd files on Windows\n                    env=env\n                )\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    cleaned_response = self._clean_response(raw_response)\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude failed: {result.stderr}\")\n                    raise Exception(f\"Claude failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(f\"Claude timeout ({self.config.default_timeout}s)\")\n            raise Exception(\"Claude timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude call error: {e}\")\n            raise\n    \n    def _try_fallbacks(self, prompt: str, failed_model: Optional[str], \n                      system_prompt: Optional[str]) -> str:\n        \"\"\"Try fallback models when primary model fails.\"\"\"\n        fallback_models = [m for m in self.config.fallback_models if m != failed_model]\n        \n        for fallback_model in fallback_models:\n            if fallback_model == \"manual_fallback\":\n                return self._manual_fallback(prompt)\n            \n            try:\n                self._log_debug(f\"Trying fallback: {fallback_model}\")\n                response = self._call_claude(prompt, fallback_model, system_prompt)\n                if response and len(response.strip()) > 0:\n                    self._log_debug(f\"\u00e2\u0153\u2026 Fallback success: {fallback_model}\")\n                    return response\n            except Exception as e:\n                self._log_debug(f\"Fallback {fallback_model} failed: {e}\")\n                continue\n        \n        # All fallbacks failed\n        return self._manual_fallback(prompt)\n    \n    def _manual_fallback(self, prompt: str) -> str:\n        \"\"\"Generate a manual fallback response when all AI models fail.\"\"\"\n        self._log_debug(\"All AI models failed, using manual fallback\")\n        \n        # Simple keyword-based responses for common tasks\n        prompt_lower = prompt.lower()\n        \n        if any(word in prompt_lower for word in [\"commit\", \"git\", \"message\"]):\n            return \"chore: update files\"\n        elif any(word in prompt_lower for word in [\"explain\", \"what\", \"how\"]):\n            return \"Unable to generate explanation - AI models unavailable\"\n        elif any(word in prompt_lower for word in [\"error\", \"debug\", \"fix\"]):\n            return \"Error analysis unavailable - check logs and documentation\"\n        elif any(word in prompt_lower for word in [\"summary\", \"summarize\"]):\n            return \"Summary unavailable - AI models unavailable\"\n        else:\n            return \"AI response unavailable - please try again later\"\n    \n    def _clean_response(self, response: str) -> str:\n        \"\"\"Clean and validate AI response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and suffixes\n        cleaned = response.strip()\n        \n        # Remove quotes if response is entirely quoted\n        if cleaned.startswith('\"') and cleaned.endswith('\"'):\n            cleaned = cleaned[1:-1]\n        elif cleaned.startswith(\"'\") and cleaned.endswith(\"'\"):\n            cleaned = cleaned[1:-1]\n        \n        # Remove markdown code blocks\n        if cleaned.startswith(\"```\") and cleaned.endswith(\"```\"):\n            lines = cleaned.split('\\n')\n            if len(lines) > 2:\n                cleaned = '\\n'.join(lines[1:-1])\n        \n        return cleaned.strip()\n    \n    def _read_context_files(self, file_paths: List[str]) -> str:\n        \"\"\"Read content from context files.\"\"\"\n        context_parts = []\n        \n        for file_path in file_paths:\n            try:\n                path_obj = pathlib.Path(file_path)\n                if path_obj.exists() and path_obj.is_file():\n                    with open(path_obj, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n                        if len(content) > 2000:  # Limit context size\n                            content = content[:2000] + \"...\"\n                        context_parts.append(f\"File: {file_path}\\n{content}\\n\")\n            except Exception:\n                context_parts.append(f\"File: {file_path}\\n[Unable to read file]\\n\")\n        \n        return '\\n'.join(context_parts)\n    \n    def _generate_cache_key(self, prompt: str, model: Optional[str], \n                           system_prompt: Optional[str]) -> str:\n        \"\"\"Generate cache key for response caching.\"\"\"\n        key_parts = [\n            prompt[:100],  # First 100 chars of prompt\n            model or self.config.default_model,\n            system_prompt or \"\"\n        ]\n        return str(hash(tuple(key_parts)))\n    \n    def _cache_response(self, cache_key: str, response: str):\n        \"\"\"Cache a response with timestamp.\"\"\"\n        self._response_cache[cache_key] = {\n            \"response\": response,\n            \"timestamp\": datetime.datetime.now(),\n            \"ttl_minutes\": self.config.cache_ttl_minutes\n        }\n        \n        # Simple cache cleanup - remove old entries\n        if len(self._response_cache) > 100:\n            old_keys = list(self._response_cache.keys())[:20]\n            for old_key in old_keys:\n                del self._response_cache[old_key]\n    \n    def _is_cache_valid(self, cached_item: Dict) -> bool:\n        \"\"\"Check if cached response is still valid.\"\"\"\n        if not self.config.enable_caching:\n            return False\n        \n        elapsed = datetime.datetime.now() - cached_item[\"timestamp\"]\n        ttl_minutes = cached_item.get(\"ttl_minutes\", self.config.cache_ttl_minutes)\n        \n        return elapsed.total_seconds() < (ttl_minutes * 60)\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information.\"\"\"\n        if not self.config.debug_logging:\n            return\n        \n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - LLMClient: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n    \n    def get_usage_stats(self) -> Dict[str, Any]:\n        \"\"\"Get basic usage statistics.\"\"\"\n        return {\n            \"cache_size\": len(self._response_cache),\n            \"default_model\": self.config.default_model,\n            \"caching_enabled\": self.config.enable_caching,\n            \"cost_tracking_enabled\": self.config.enable_cost_tracking\n        }\n\n# Convenience functions for simple usage\ndef ask(prompt: str, model: Optional[str] = None) -> str:\n    \"\"\"Quick ask function for simple queries.\"\"\"\n    client = LLMClient()\n    return client.ask(prompt, model)\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Quick concise ask for cost-efficient queries.\"\"\"\n    client = LLMClient()\n    return client.ask_concise(prompt)\n\ndef ask_json(prompt: str) -> Dict:\n    \"\"\"Quick ask for JSON responses.\"\"\"\n    client = LLMClient()\n    return client.ask_structured(prompt, \"json\")\n\n# Test function\ndef test_llm_client():\n    \"\"\"Test LLM client functionality.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing LLM Client...\")\n    \n    client = LLMClient()\n    \n    # Test basic ask\n    try:\n        response = client.ask(\"What is 2+2? Answer with just the number.\")\n        print(f\"\u00e2\u0153\u2026 Basic ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Basic ask failed: {e}\")\n    \n    # Test concise ask\n    try:\n        response = client.ask_concise(\"Current year\")\n        print(f\"\u00e2\u0153\u2026 Concise ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Concise ask failed: {e}\")\n    \n    # Test usage stats\n    stats = client.get_usage_stats()\n    print(f\"\u00e2\u0153\u2026 Usage stats: {stats}\")\n    \n    print(\"\u00f0\u0178\u00a7\u00aa LLM Client test completed!\")\n\nif __name__ == \"__main__\":\n    test_llm_client()", "structuredPatch": [{"oldStart": 186, "oldLines": 14, "newStart": 186, "newLines": 16, "lines": ["                 ", "                 self._log_debug(f\"Executing: {cmd_args[0]} with {len(cmd_args)-1} args\")", "                 ", "+                # Force Windows CMD shell instead of bash", "                 result = subprocess.run(", "                     cmd_args,", "                     capture_output=True,", "                     text=True,", "                     timeout=self.config.default_timeout,", "                     cwd=pathlib.Path.cwd(),", "-                    shell=True,  # Use shell for .cmd files on Windows", "-                    env=env", "+                    shell=True,", "+                    env=env,", "+                    executable=None  # Let Windows choose the shell", "                 )", "                 ", "                 if result.returncode == 0:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:49:04.794665", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "new_string": "                # Use cmd.exe explicitly to avoid bash issues\n                cmd_command = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in cmd_args)\n                \n                result = subprocess.run(\n                    [\"cmd.exe\", \"/c\", cmd_command],\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    env=env\n                )", "old_string": "                # Force Windows CMD shell instead of bash\n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env,\n                    executable=None  # Let Windows choose the shell\n                )", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\client.py", "oldString": "                # Force Windows CMD shell instead of bash\n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env,\n                    executable=None  # Let Windows choose the shell\n                )", "newString": "                # Use cmd.exe explicitly to avoid bash issues\n                cmd_command = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in cmd_args)\n                \n                result = subprocess.run(\n                    [\"cmd.exe\", \"/c\", cmd_command],\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    env=env\n                )", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\n\"\"\"\nLLM Client for Claude Code Hooks\nReusable, cost-efficient AI client using Claude 3.5 Haiku by default\nSupports the command structure: claude -p --model claude-3-5-haiku-20241022 \"<PROMPT>\"\n\"\"\"\n\nimport subprocess\nimport tempfile\nimport pathlib\nimport datetime\nimport json\nfrom typing import Dict, Any, Optional, List, Union\ntry:\n    from .config import get_config, get_config_manager, LLMConfig\nexcept ImportError:\n    from config import get_config, get_config_manager, LLMConfig\n\nclass LLMClient:\n    \"\"\"\n    Reusable LLM client for cost-efficient AI integration across Claude Code hooks.\n    \n    Features:\n    - Claude 3.5 Haiku by default for cost efficiency\n    - Automatic fallbacks: Haiku \u00e2\u2020\u2019 Sonnet \u00e2\u2020\u2019 Manual\n    - Response caching and token tracking\n    - Simple API: llm.ask(\"prompt\")\n    \"\"\"\n    \n    def __init__(self, config: Optional[LLMConfig] = None):\n        self.config = config or get_config()\n        self.config_manager = get_config_manager()\n        self.debug_log = pathlib.Path(self.config.log_path)\n        self._response_cache = {}\n    \n    def ask(self, prompt: str, model: Optional[str] = None, \n            max_tokens: Optional[int] = None, \n            system_prompt: Optional[str] = None) -> str:\n        \"\"\"\n        Ask the LLM a question with automatic fallbacks and caching.\n        \n        Args:\n            prompt: The question/task for the LLM\n            model: Override default model (optional)\n            max_tokens: Token limit override (optional)\n            system_prompt: Additional system instructions (optional)\n            \n        Returns:\n            str: The LLM's response, cleaned and validated\n        \"\"\"\n        try:\n            # Check cache first\n            cache_key = self._generate_cache_key(prompt, model, system_prompt)\n            if self.config.enable_caching and cache_key in self._response_cache:\n                cached_response = self._response_cache[cache_key]\n                if self._is_cache_valid(cached_response):\n                    self._log_debug(f\"Cache hit for prompt: {prompt[:50]}...\")\n                    return cached_response[\"response\"]\n            \n            # Try primary model\n            target_model = model or self.config.default_model\n            response = self._call_claude(prompt, target_model, system_prompt)\n            \n            if response and len(response.strip()) > 0:\n                # Cache successful response\n                if self.config.enable_caching:\n                    self._cache_response(cache_key, response)\n                \n                self._log_debug(f\"\u00e2\u0153\u2026 LLM success with {target_model}: {len(response)} chars\")\n                return response\n            \n            # Fallback to next model\n            return self._try_fallbacks(prompt, target_model, system_prompt)\n            \n        except Exception as e:\n            self._log_debug(f\"\u00e2\udc9d\u0152 LLM error: {e}\")\n            return self._try_fallbacks(prompt, model, system_prompt)\n    \n    def ask_concise(self, prompt: str, model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask for an ultra-concise response optimized for cost efficiency.\n        Uses aggressive compression and minimal tokens.\n        \"\"\"\n        concise_system = (\n            \"Be extremely concise. Use minimal tokens. \"\n            \"No explanations, examples, or elaboration. \"\n            \"Output only the essential answer.\"\n        )\n        \n        # Force haiku for maximum cost efficiency\n        efficient_model = model or \"claude-3-5-haiku-20241022\"\n        \n        return self.ask(prompt, efficient_model, max_tokens=100, system_prompt=concise_system)\n    \n    def ask_with_context(self, prompt: str, context_files: List[str] = None, \n                        model: Optional[str] = None) -> str:\n        \"\"\"\n        Ask with additional context from files.\n        Automatically includes relevant file contents in the prompt.\n        \"\"\"\n        enhanced_prompt = prompt\n        \n        if context_files:\n            context_content = self._read_context_files(context_files)\n            enhanced_prompt = f\"Context:\\n{context_content}\\n\\nQuestion: {prompt}\"\n        \n        return self.ask(enhanced_prompt, model)\n    \n    def ask_structured(self, prompt: str, format_type: str = \"json\", \n                      model: Optional[str] = None) -> Union[Dict, List, str]:\n        \"\"\"\n        Ask for a structured response (JSON, list, etc.).\n        \n        Args:\n            prompt: The question/task\n            format_type: \"json\", \"list\", \"yaml\", or \"text\"\n            model: Model override\n            \n        Returns:\n            Parsed structured data or raw text\n        \"\"\"\n        format_instructions = {\n            \"json\": \"Respond with valid JSON only. No explanations.\",\n            \"list\": \"Respond with a numbered list only. No explanations.\",\n            \"yaml\": \"Respond with valid YAML only. No explanations.\",\n            \"text\": \"Respond with plain text only. No formatting.\"\n        }\n        \n        system_prompt = format_instructions.get(format_type, format_instructions[\"text\"])\n        response = self.ask(prompt, model, system_prompt=system_prompt)\n        \n        # Try to parse structured formats\n        if format_type == \"json\":\n            try:\n                return json.loads(response)\n            except json.JSONDecodeError:\n                return {\"error\": \"Invalid JSON\", \"raw_response\": response}\n        elif format_type == \"list\":\n            return [line.strip() for line in response.split('\\n') if line.strip()]\n        \n        return response\n    \n    def _call_claude(self, prompt: str, model: str, system_prompt: Optional[str] = None) -> str:\n        \"\"\"Call Claude executable with the specified model and prompt.\"\"\"\n        try:\n            # Create temporary file for prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                temp_file.write(prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Build command arguments\n                args = self.config_manager.get_claude_args(model, system_prompt)\n                args.append(f\"@{temp_file_path}\")\n                \n                self._log_debug(f\"Calling: {' '.join(args[:4])} @prompt ({len(prompt)} chars)\")\n                \n                # Try direct execution without shell for better Windows compatibility\n                import os\n                env = os.environ.copy()\n                \n                # Try to find the actual Claude executable\n                claude_exe = None\n                potential_paths = [\n                    r\"C:\\Users\\NATH\\AppData\\Local\\pnpm\\claude.CMD\",\n                    r\"C:\\Users\\NATH\\AppData\\Roaming\\npm\\claude.cmd\",\n                    \"claude.cmd\",\n                    \"claude\"\n                ]\n                \n                for path in potential_paths:\n                    if pathlib.Path(path).exists() or path in [\"claude.cmd\", \"claude\"]:\n                        claude_exe = path\n                        break\n                \n                if not claude_exe:\n                    raise FileNotFoundError(\"Claude executable not found in any expected location\")\n                \n                # Build direct command arguments\n                cmd_args = [claude_exe] + args[1:]  # Skip the first arg which is the executable path\n                \n                self._log_debug(f\"Executing: {cmd_args[0]} with {len(cmd_args)-1} args\")\n                \n                # Force Windows CMD shell instead of bash\n                result = subprocess.run(\n                    cmd_args,\n                    capture_output=True,\n                    text=True,\n                    timeout=self.config.default_timeout,\n                    cwd=pathlib.Path.cwd(),\n                    shell=True,\n                    env=env,\n                    executable=None  # Let Windows choose the shell\n                )\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    cleaned_response = self._clean_response(raw_response)\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude failed: {result.stderr}\")\n                    raise Exception(f\"Claude failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(f\"Claude timeout ({self.config.default_timeout}s)\")\n            raise Exception(\"Claude timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude call error: {e}\")\n            raise\n    \n    def _try_fallbacks(self, prompt: str, failed_model: Optional[str], \n                      system_prompt: Optional[str]) -> str:\n        \"\"\"Try fallback models when primary model fails.\"\"\"\n        fallback_models = [m for m in self.config.fallback_models if m != failed_model]\n        \n        for fallback_model in fallback_models:\n            if fallback_model == \"manual_fallback\":\n                return self._manual_fallback(prompt)\n            \n            try:\n                self._log_debug(f\"Trying fallback: {fallback_model}\")\n                response = self._call_claude(prompt, fallback_model, system_prompt)\n                if response and len(response.strip()) > 0:\n                    self._log_debug(f\"\u00e2\u0153\u2026 Fallback success: {fallback_model}\")\n                    return response\n            except Exception as e:\n                self._log_debug(f\"Fallback {fallback_model} failed: {e}\")\n                continue\n        \n        # All fallbacks failed\n        return self._manual_fallback(prompt)\n    \n    def _manual_fallback(self, prompt: str) -> str:\n        \"\"\"Generate a manual fallback response when all AI models fail.\"\"\"\n        self._log_debug(\"All AI models failed, using manual fallback\")\n        \n        # Simple keyword-based responses for common tasks\n        prompt_lower = prompt.lower()\n        \n        if any(word in prompt_lower for word in [\"commit\", \"git\", \"message\"]):\n            return \"chore: update files\"\n        elif any(word in prompt_lower for word in [\"explain\", \"what\", \"how\"]):\n            return \"Unable to generate explanation - AI models unavailable\"\n        elif any(word in prompt_lower for word in [\"error\", \"debug\", \"fix\"]):\n            return \"Error analysis unavailable - check logs and documentation\"\n        elif any(word in prompt_lower for word in [\"summary\", \"summarize\"]):\n            return \"Summary unavailable - AI models unavailable\"\n        else:\n            return \"AI response unavailable - please try again later\"\n    \n    def _clean_response(self, response: str) -> str:\n        \"\"\"Clean and validate AI response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and suffixes\n        cleaned = response.strip()\n        \n        # Remove quotes if response is entirely quoted\n        if cleaned.startswith('\"') and cleaned.endswith('\"'):\n            cleaned = cleaned[1:-1]\n        elif cleaned.startswith(\"'\") and cleaned.endswith(\"'\"):\n            cleaned = cleaned[1:-1]\n        \n        # Remove markdown code blocks\n        if cleaned.startswith(\"```\") and cleaned.endswith(\"```\"):\n            lines = cleaned.split('\\n')\n            if len(lines) > 2:\n                cleaned = '\\n'.join(lines[1:-1])\n        \n        return cleaned.strip()\n    \n    def _read_context_files(self, file_paths: List[str]) -> str:\n        \"\"\"Read content from context files.\"\"\"\n        context_parts = []\n        \n        for file_path in file_paths:\n            try:\n                path_obj = pathlib.Path(file_path)\n                if path_obj.exists() and path_obj.is_file():\n                    with open(path_obj, 'r', encoding='utf-8', errors='ignore') as f:\n                        content = f.read()\n                        if len(content) > 2000:  # Limit context size\n                            content = content[:2000] + \"...\"\n                        context_parts.append(f\"File: {file_path}\\n{content}\\n\")\n            except Exception:\n                context_parts.append(f\"File: {file_path}\\n[Unable to read file]\\n\")\n        \n        return '\\n'.join(context_parts)\n    \n    def _generate_cache_key(self, prompt: str, model: Optional[str], \n                           system_prompt: Optional[str]) -> str:\n        \"\"\"Generate cache key for response caching.\"\"\"\n        key_parts = [\n            prompt[:100],  # First 100 chars of prompt\n            model or self.config.default_model,\n            system_prompt or \"\"\n        ]\n        return str(hash(tuple(key_parts)))\n    \n    def _cache_response(self, cache_key: str, response: str):\n        \"\"\"Cache a response with timestamp.\"\"\"\n        self._response_cache[cache_key] = {\n            \"response\": response,\n            \"timestamp\": datetime.datetime.now(),\n            \"ttl_minutes\": self.config.cache_ttl_minutes\n        }\n        \n        # Simple cache cleanup - remove old entries\n        if len(self._response_cache) > 100:\n            old_keys = list(self._response_cache.keys())[:20]\n            for old_key in old_keys:\n                del self._response_cache[old_key]\n    \n    def _is_cache_valid(self, cached_item: Dict) -> bool:\n        \"\"\"Check if cached response is still valid.\"\"\"\n        if not self.config.enable_caching:\n            return False\n        \n        elapsed = datetime.datetime.now() - cached_item[\"timestamp\"]\n        ttl_minutes = cached_item.get(\"ttl_minutes\", self.config.cache_ttl_minutes)\n        \n        return elapsed.total_seconds() < (ttl_minutes * 60)\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information.\"\"\"\n        if not self.config.debug_logging:\n            return\n        \n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - LLMClient: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n    \n    def get_usage_stats(self) -> Dict[str, Any]:\n        \"\"\"Get basic usage statistics.\"\"\"\n        return {\n            \"cache_size\": len(self._response_cache),\n            \"default_model\": self.config.default_model,\n            \"caching_enabled\": self.config.enable_caching,\n            \"cost_tracking_enabled\": self.config.enable_cost_tracking\n        }\n\n# Convenience functions for simple usage\ndef ask(prompt: str, model: Optional[str] = None) -> str:\n    \"\"\"Quick ask function for simple queries.\"\"\"\n    client = LLMClient()\n    return client.ask(prompt, model)\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Quick concise ask for cost-efficient queries.\"\"\"\n    client = LLMClient()\n    return client.ask_concise(prompt)\n\ndef ask_json(prompt: str) -> Dict:\n    \"\"\"Quick ask for JSON responses.\"\"\"\n    client = LLMClient()\n    return client.ask_structured(prompt, \"json\")\n\n# Test function\ndef test_llm_client():\n    \"\"\"Test LLM client functionality.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing LLM Client...\")\n    \n    client = LLMClient()\n    \n    # Test basic ask\n    try:\n        response = client.ask(\"What is 2+2? Answer with just the number.\")\n        print(f\"\u00e2\u0153\u2026 Basic ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Basic ask failed: {e}\")\n    \n    # Test concise ask\n    try:\n        response = client.ask_concise(\"Current year\")\n        print(f\"\u00e2\u0153\u2026 Concise ask: {response}\")\n    except Exception as e:\n        print(f\"\u00e2\udc9d\u0152 Concise ask failed: {e}\")\n    \n    # Test usage stats\n    stats = client.get_usage_stats()\n    print(f\"\u00e2\u0153\u2026 Usage stats: {stats}\")\n    \n    print(\"\u00f0\u0178\u00a7\u00aa LLM Client test completed!\")\n\nif __name__ == \"__main__\":\n    test_llm_client()", "structuredPatch": [{"oldStart": 186, "oldLines": 16, "newStart": 186, "newLines": 16, "lines": ["                 ", "                 self._log_debug(f\"Executing: {cmd_args[0]} with {len(cmd_args)-1} args\")", "                 ", "-                # Force Windows CMD shell instead of bash", "+                # Use cmd.exe explicitly to avoid bash issues", "+                cmd_command = \" \".join(f'\"{arg}\"' if \" \" in arg else arg for arg in cmd_args)", "+                ", "                 result = subprocess.run(", "-                    cmd_args,", "+                    [\"cmd.exe\", \"/c\", cmd_command],", "                     capture_output=True,", "                     text=True,", "                     timeout=self.config.default_timeout,", "                     cwd=pathlib.Path.cwd(),", "-                    shell=True,", "-                    env=env,", "-                    executable=None  # Let Windows choose the shell", "+                    env=env", "                 )", "                 ", "                 if result.returncode == 0:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:52:09.264744", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with specific system prompt for commit messages\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a git commit message generator. \"\n                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"\n                        \"No explanations, no conversation, no questions. \"\n                        \"Just output the commit message directly.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "old_string": "                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "newString": "                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with specific system prompt for commit messages\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a git commit message generator. \"\n                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"\n                        \"No explanations, no conversation, no questions. \"\n                        \"Just output the commit message directly.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 592, "oldLines": 10, "newStart": 592, "newLines": 20, "lines": ["                 # Use shell=True on Windows to handle .cmd files properly", "                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "-                    from .llms import ask_concise", "+                    from .llms import LLMClient", "+                    ", "+                    # Create LLM client with specific system prompt for commit messages", "+                    llm = LLMClient()", "+                    commit_system_prompt = (", "+                        \"You are a git commit message generator. \"", "+                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"", "+                        \"No explanations, no conversation, no questions. \"", "+                        \"Just output the commit message directly.\"", "+                    )", "+                    ", "                     # Debug: Log what we're sending to LLM utility", "                     self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")", "-                    response = ask_concise(task_prompt)", "+                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Check if this is the hardcoded fallback"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:52:47.358899", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"", "old_string": "                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"", "newString": "                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with specific system prompt for commit messages\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a git commit message generator. \"\n                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"\n                        \"No explanations, no conversation, no questions. \"\n                        \"Just output the commit message directly.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 572, "oldLines": 17, "newStart": 572, "newLines": 25, "lines": ["             with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:", "                 # Ultra-compact prompt for minimal token usage", "                 # Extract key info from the original detailed prompt", "-                task_prompt = f\"\"\"Generate git commit message from this context:", "+                task_prompt = f\"\"\"TASK: Generate a git commit message.", " ", "-{prompt[:200]}", "+CONTEXT:", "+{prompt[:300]}", " ", "-Format: type(scope): description", "-Max 50 chars. Examples:", "-feat(auth): add login", "-fix(api): handle errors", "-chore: update config", "+REQUIREMENTS:", "+- Use conventional commit format: type(scope): description  ", "+- Maximum 50 characters", "+- Use present tense verbs", "+- Do NOT provide explanations or conversation", "+- Output ONLY the commit message", " ", "-Output only the commit message:\"\"\"", "+EXAMPLES:", "+feat(auth): add login validation", "+fix(parser): handle null values  ", "+refactor(ui): extract components", "+chore(deps): update packages", "+", "+COMMIT MESSAGE:\"\"\"", "                 ", "                 temp_file.write(task_prompt)", "                 temp_file_path = temp_file.name"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:53:22.973730", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)", "old_string": "                    # Create LLM client with specific system prompt for commit messages\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a git commit message generator. \"\n                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"\n                        \"No explanations, no conversation, no questions. \"\n                        \"Just output the commit message directly.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                    # Create LLM client with specific system prompt for commit messages\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a git commit message generator. \"\n                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"\n                        \"No explanations, no conversation, no questions. \"\n                        \"Just output the commit message directly.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)", "newString": "                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with specific system prompt for commit messages\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a git commit message generator. \"\n                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"\n                        \"No explanations, no conversation, no questions. \"\n                        \"Just output the commit message directly.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 602, "oldLines": 18, "newStart": 602, "newLines": 18, "lines": ["                 try:", "                     from .llms import LLMClient", "                     ", "-                    # Create LLM client with specific system prompt for commit messages", "+                    # Create LLM client with more specific system prompt", "                     llm = LLMClient()", "                     commit_system_prompt = (", "-                        \"You are a git commit message generator. \"", "-                        \"Generate ONLY a conventional commit message in the format: type(scope): description. \"", "-                        \"No explanations, no conversation, no questions. \"", "-                        \"Just output the commit message directly.\"", "+                        \"You are a commit message generator. Output only the commit message in this exact format: \"", "+                        \"type(scope): description. No conversation, no explanations, no questions. \"", "+                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"", "+                        \"Output ONLY the commit message.\"", "                     )", "                     ", "                     # Debug: Log what we're sending to LLM utility", "                     self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")", "-                    response = llm.ask(task_prompt, max_tokens=50, system_prompt=commit_system_prompt)", "+                    response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Check if this is the hardcoded fallback"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:56:16.982421", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 5\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout", "old_string": "                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)", "newString": "                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 5\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 613, "oldLines": 7, "newStart": 613, "newLines": 22, "lines": ["                     ", "                     # Debug: Log what we're sending to LLM utility", "                     self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")", "-                    response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)", "+                    ", "+                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)", "+                    import time", "+                    start_time = time.time()", "+                    ", "+                    # Override LLM client timeout for this call", "+                    original_timeout = llm.config.default_timeout", "+                    llm.config.default_timeout = 5", "+                    ", "+                    try:", "+                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)", "+                        elapsed = time.time() - start_time", "+                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")", "+                    finally:", "+                        # Restore original timeout", "+                        llm.config.default_timeout = original_timeout", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Check if this is the hardcoded fallback"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:57:31.398230", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "old_string": "                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "newString": "                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 5\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif response and response != \"AI response unavailable\" and len(response) > 10:\n                        self._log_debug(f\"LLM gave meaningful response: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 631, "oldLines": 11, "newStart": 631, "newLines": 15, "lines": ["                         llm.config.default_timeout = original_timeout", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "-                    # Check if this is the hardcoded fallback", "+                    # Check if this is the hardcoded fallback or conversational response", "                     if response == \"chore: update files\":", "                         self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")", "-                    elif response and response != \"AI response unavailable\" and len(response) > 10:", "-                        self._log_debug(f\"LLM gave meaningful response: {response}\")", "+                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():", "+                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")", "+                        # Use fallback immediately since the prompt was interrupted", "+                        return self._create_fallback_commit(tool_context, git_context)", "+                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:", "+                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")", "                         return response", "                     else:", "                         self._log_debug(\"LLM response appears to be fallback, trying original method\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:58:23.671833", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"", "old_string": "    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"", "newString": "    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 5\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 565, "oldLines": 7, "newStart": 565, "newLines": 7, "lines": ["             self._log_debug(f\"Commit creation error: {e}\")", "             return False", "     ", "-    def _call_claude_task(self, prompt: str) -> str:", "+    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:", "         \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"", "         try:", "             # Create a temporary file with the prompt"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:59:52.830265", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6", "old_string": "                    # Override LLM client timeout for this call\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 5", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                    # Override LLM client timeout for this call\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 5", "newString": "                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 5\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 618, "oldLines": 9, "newStart": 618, "newLines": 9, "lines": ["                     import time", "                     start_time = time.time()", "                     ", "-                    # Override LLM client timeout for this call", "+                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)", "                     original_timeout = llm.config.default_timeout", "-                    llm.config.default_timeout = 5", "+                    llm.config.default_timeout = 6", "                     ", "                     try:", "                         response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:01:25.508446", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )", "old_string": "                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )", "newString": "                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        result = subprocess.run(\n                            cmd,\n                            capture_output=True, \n                            text=True, \n                            timeout=30,\n                            cwd=pathlib.Path.cwd(),\n                            shell=True\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 663, "oldLines": 13, "newStart": 663, "newLines": 15, "lines": ["                 for cmd in claude_commands:", "                     try:", "                         self._log_debug(f\"Trying claude command: {cmd[0]}\")", "+                        # Use cmd.exe explicitly to avoid bash issues on Windows", "+                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)", "+                        ", "                         result = subprocess.run(", "-                            cmd,", "+                            [\"cmd.exe\", \"/c\", cmd_command],", "                             capture_output=True, ", "                             text=True, ", "-                            timeout=30,", "-                            cwd=pathlib.Path.cwd(),", "-                            shell=True", "+                            timeout=10,  # Shorter timeout since this is fallback", "+                            cwd=pathlib.Path.cwd()", "                         )", "                         if result.returncode == 0:", "                             self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:02:37.868958", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)", "old_string": "            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)", "newString": "            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 425, "oldLines": 7, "newStart": 425, "newLines": 7, "lines": ["         ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation", "-            response = self._call_claude_task(prompt)", "+            response = self._call_claude_task(prompt, tool_context, git_context)", "             commit_message = response.strip()", "             ", "             # Clean and validate AI response"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:03:50.556022", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"", "old_string": "                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)", "newString": "                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        return self._create_fallback_commit(tool_context, git_context)\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 637, "oldLines": 7, "newStart": 637, "newLines": 10, "lines": ["                     elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():", "                         self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")", "                         # Use fallback immediately since the prompt was interrupted", "-                        return self._create_fallback_commit(tool_context, git_context)", "+                        if tool_context and git_context:", "+                            return self._create_fallback_commit(tool_context, git_context)", "+                        else:", "+                            return \"chore: interrupted LLM operation\"", "                     elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:", "                         self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")", "                         return response"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:09:06.032964", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                    # Override LLM client timeout for this call (8s to allow completion before Stop hook)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 8", "old_string": "                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6", "newString": "                    # Override LLM client timeout for this call (8s to allow completion before Stop hook)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 8", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 6\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 618, "oldLines": 9, "newStart": 618, "newLines": 9, "lines": ["                     import time", "                     start_time = time.time()", "                     ", "-                    # Override LLM client timeout for this call (6s max to avoid Stop hook at ~7s)", "+                    # Override LLM client timeout for this call (8s to allow completion before Stop hook)", "                     original_timeout = llm.config.default_timeout", "-                    llm.config.default_timeout = 6", "+                    llm.config.default_timeout = 8", "                     ", "                     try:", "                         response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:12:56.209382", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20", "old_string": "                    # Override LLM client timeout for this call (14s to allow completion before Stop hook)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 14", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                    # Override LLM client timeout for this call (14s to allow completion before Stop hook)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 14", "newString": "                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (14s to allow completion before Stop hook)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 14\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 618, "oldLines": 9, "newStart": 618, "newLines": 9, "lines": ["                     import time", "                     start_time = time.time()", "                     ", "-                    # Override LLM client timeout for this call (14s to allow completion before Stop hook)", "+                    # Override LLM client timeout for this call (20s for ample completion time)", "                     original_timeout = llm.config.default_timeout", "-                    llm.config.default_timeout = 14", "+                    llm.config.default_timeout = 20", "                     ", "                     try:", "                         response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:13:44.755552", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]", "old_string": "                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]", "newString": "                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows\n                claude_commands = [\n                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],\n                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 654, "oldLines": 12, "newStart": 654, "newLines": 13, "lines": ["                 ", "                 # Fallback to original claude command with Haiku for cost efficiency", "                 ", "-                # Try different claude command variations for Windows", "+                # Try different claude command variations for Windows (most reliable first)", "                 claude_commands = [", "-                    [self.claude_executable, \"--print\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\", f\"@{temp_file_path}\"],", "-                    [\"claude\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],", "-                    [\"claude.exe\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"],", "-                    [\"claude.cmd\", \"-p\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]", "+                    # Use the exact path that worked before", "+                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],", "+                    # Fallback to generic commands", "+                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],", "+                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]", "                 ]", "                 ", "                 result = None"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:14:31.952747", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )", "old_string": "                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )", "newString": "                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=10,  # Shorter timeout since this is fallback\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 674, "oldLines": 7, "newStart": 674, "newLines": 7, "lines": ["                             [\"cmd.exe\", \"/c\", cmd_command],", "                             capture_output=True, ", "                             text=True, ", "-                            timeout=10,  # Shorter timeout since this is fallback", "+                            timeout=15,  # Give fallback commands reasonable time", "                             cwd=pathlib.Path.cwd()", "                         )", "                         if result.returncode == 0:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:21:00.351995", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\nfrom utils.smart_git_checkpoints import SmartGitCheckpoint", "old_string": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification", "newString": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\nfrom utils.smart_git_checkpoints import SmartGitCheckpoint", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 13, "oldLines": 6, "newStart": 13, "newLines": 7, "lines": [" import pathlib", " import datetime", " from utils.smart_voice_notify import process_stop_notification", "+from utils.smart_git_checkpoints import SmartGitCheckpoint", " ", " def main() -> None:", "     \"\"\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:21:21.370332", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process smart git checkpoints for the entire session\n    process_session_git_checkpoint(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)", "old_string": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)", "newString": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process smart git checkpoints for the entire session\n    process_session_git_checkpoint(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\nfrom utils.smart_git_checkpoints import SmartGitCheckpoint\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 32, "oldLines": 6, "newStart": 32, "newLines": 9, "lines": ["     # Log to logs directory", "     log_to_logs_directory(payload)", "     ", "+    # Process smart git checkpoints for the entire session", "+    process_session_git_checkpoint(payload)", "+    ", "     # Process using utility functions", "     process_stop_notification(payload)", " "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:21:45.943474", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "def process_session_git_checkpoint(payload) -> None:\n    \"\"\"\n    Process smart git checkpoints for the entire session.\n    This runs after session ends, so no timing issues with LLM calls.\n    \n    Args:\n        payload: Stop hook payload containing session information\n    \"\"\"\n    try:\n        session_id = payload.get(\"session_id\")\n        if not session_id:\n            return\n            \n        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoint()\n        \n        # Process the entire session at once\n        # This is much better than processing individual tools\n        checkpoint.process_session_checkpoint(session_id, payload)\n        \n    except Exception as e:\n        # Don't fail the hook if git processing fails\n        print(f\"Git checkpoint error: {e}\", file=sys.stderr)\n\ndef log_to_logs_directory(payload) -> None:", "old_string": "def log_to_logs_directory(payload) -> None:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "def log_to_logs_directory(payload) -> None:", "newString": "def process_session_git_checkpoint(payload) -> None:\n    \"\"\"\n    Process smart git checkpoints for the entire session.\n    This runs after session ends, so no timing issues with LLM calls.\n    \n    Args:\n        payload: Stop hook payload containing session information\n    \"\"\"\n    try:\n        session_id = payload.get(\"session_id\")\n        if not session_id:\n            return\n            \n        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoint()\n        \n        # Process the entire session at once\n        # This is much better than processing individual tools\n        checkpoint.process_session_checkpoint(session_id, payload)\n        \n    except Exception as e:\n        # Don't fail the hook if git processing fails\n        print(f\"Git checkpoint error: {e}\", file=sys.stderr)\n\ndef log_to_logs_directory(payload) -> None:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\nfrom utils.smart_git_checkpoints import SmartGitCheckpoint\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process smart git checkpoints for the entire session\n    process_session_git_checkpoint(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 38, "oldLines": 6, "newStart": 38, "newLines": 30, "lines": ["     # Process using utility functions", "     process_stop_notification(payload)", " ", "+def process_session_git_checkpoint(payload) -> None:", "+    \"\"\"", "+    Process smart git checkpoints for the entire session.", "+    This runs after session ends, so no timing issues with LLM calls.", "+    ", "+    Args:", "+        payload: Stop hook payload containing session information", "+    \"\"\"", "+    try:", "+        session_id = payload.get(\"session_id\")", "+        if not session_id:", "+            return", "+            ", "+        # Create smart checkpoint processor", "+        checkpoint = SmartGitCheckpoint()", "+        ", "+        # Process the entire session at once", "+        # This is much better than processing individual tools", "+        checkpoint.process_session_checkpoint(session_id, payload)", "+        ", "+    except Exception as e:", "+        # Don't fail the hook if git processing fails", "+        print(f\"Git checkpoint error: {e}\", file=sys.stderr)", "+", " def log_to_logs_directory(payload) -> None:", "     \"\"\"", "     Log Stop event to logs directory."]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:22:33.752036", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:\n        \"\"\"\n        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.\n        \n        Args:\n            session_id: Session identifier\n            stop_payload: Stop hook payload with session information\n        \"\"\"\n        try:\n            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")\n            \n            # Load all tool usage from the entire session\n            tool_history = self._load_tool_usage_history(session_id)\n            \n            # Check if there were any meaningful file operations\n            file_operations = tool_history.get(\"file_operations\", [])\n            if not file_operations:\n                self._log_debug(\"No file operations found, skipping checkpoint\")\n                return\n                \n            # Analyze git repository state\n            git_context = self._analyze_git_changes()\n            if not git_context.get(\"files\"):\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return\n                \n            # Build session context\n            session_context = {\n                \"session_id\": session_id,\n                \"total_operations\": len(file_operations),\n                \"file_count\": len(git_context.get(\"files\", [])),\n                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")\n            }\n            \n            # Generate commit for entire session (with unlimited time!)\n            commit_message = self._generate_session_commit(session_context, git_context, tool_history)\n            \n            # Create the commit\n            if self._create_commit(commit_message):\n                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")\n            else:\n                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")\n                \n        except Exception as e:\n            self._log_debug(f\"Session checkpoint error: {e}\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:", "old_string": "        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:", "newString": "        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:\n        \"\"\"\n        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.\n        \n        Args:\n            session_id: Session identifier\n            stop_payload: Stop hook payload with session information\n        \"\"\"\n        try:\n            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")\n            \n            # Load all tool usage from the entire session\n            tool_history = self._load_tool_usage_history(session_id)\n            \n            # Check if there were any meaningful file operations\n            file_operations = tool_history.get(\"file_operations\", [])\n            if not file_operations:\n                self._log_debug(\"No file operations found, skipping checkpoint\")\n                return\n                \n            # Analyze git repository state\n            git_context = self._analyze_git_changes()\n            if not git_context.get(\"files\"):\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return\n                \n            # Build session context\n            session_context = {\n                \"session_id\": session_id,\n                \"total_operations\": len(file_operations),\n                \"file_count\": len(git_context.get(\"files\", [])),\n                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")\n            }\n            \n            # Generate commit for entire session (with unlimited time!)\n            commit_message = self._generate_session_commit(session_context, git_context, tool_history)\n            \n            # Create the commit\n            if self._create_commit(commit_message):\n                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")\n            else:\n                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")\n                \n        except Exception as e:\n            self._log_debug(f\"Session checkpoint error: {e}\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 21, "oldLines": 6, "newStart": 21, "newLines": 52, "lines": ["         self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")", "         self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "     ", "+    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:", "+        \"\"\"", "+        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.", "+        ", "+        Args:", "+            session_id: Session identifier", "+            stop_payload: Stop hook payload with session information", "+        \"\"\"", "+        try:", "+            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")", "+            ", "+            # Load all tool usage from the entire session", "+            tool_history = self._load_tool_usage_history(session_id)", "+            ", "+            # Check if there were any meaningful file operations", "+            file_operations = tool_history.get(\"file_operations\", [])", "+            if not file_operations:", "+                self._log_debug(\"No file operations found, skipping checkpoint\")", "+                return", "+                ", "+            # Analyze git repository state", "+            git_context = self._analyze_git_changes()", "+            if not git_context.get(\"files\"):", "+                self._log_debug(\"No git changes detected, skipping checkpoint\")", "+                return", "+                ", "+            # Build session context", "+            session_context = {", "+                \"session_id\": session_id,", "+                \"total_operations\": len(file_operations),", "+                \"file_count\": len(git_context.get(\"files\", [])),", "+                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")", "+            }", "+            ", "+            # Generate commit for entire session (with unlimited time!)", "+            commit_message = self._generate_session_commit(session_context, git_context, tool_history)", "+            ", "+            # Create the commit", "+            if self._create_commit(commit_message):", "+                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")", "+            else:", "+                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")", "+                ", "+        except Exception as e:", "+            self._log_debug(f\"Session checkpoint error: {e}\")", "+    ", "     def process_checkpoint(self, payload: Dict[str, Any]) -> bool:", "         \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"", "         "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:23:33.954789", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _generate_session_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate commit message for entire session - much simpler and more reliable.\n        Since this runs in Stop hook, we have unlimited time for LLM calls.\n        \"\"\"\n        try:\n            # Build session-level prompt\n            file_operations = tool_history.get(\"file_operations\", [])\n            total_ops = session_context.get(\"total_operations\", 0)\n            file_count = session_context.get(\"file_count\", 0)\n            \n            # Create simple but effective prompt\n            session_prompt = f\"\"\"Generate a git commit message for this session.\n\nSESSION SUMMARY:\n- Total operations: {total_ops}\n- Files changed: {file_count}\n- Activity: {tool_history.get('session_summary', 'code changes')}\n\nFILES CHANGED:\n{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nFORMAT: type(scope): description\nEXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure\n\nCOMMIT MESSAGE:\"\"\"\n\n            # Since we're in Stop hook, we can take time for LLM\n            self._log_debug(\"\u00f0\u0178\u0161\u20ac Session commit generation (unlimited time)\")\n            \n            # Try simple pattern matching first (instant)\n            pattern_commit = self._generate_pattern_commit(session_context, git_context, tool_history)\n            if pattern_commit and pattern_commit != \"chore: update files\":\n                self._log_debug(f\"\u00e2\u0153\u2026 Using pattern-based commit: {pattern_commit}\")\n                return pattern_commit\n            \n            # If pattern matching fails, use LLM (with time to complete)\n            self._log_debug(\"\u00f0\u0178\u201c\udc9d Trying LLM generation for session commit\")\n            llm_commit = self._call_claude_task(session_prompt)\n            if llm_commit and \":\" in llm_commit and len(llm_commit) > 10:\n                cleaned = self._clean_commit_message(llm_commit)\n                self._log_debug(f\"\u00e2\u0153\u2026 LLM generated session commit: {cleaned}\")\n                return cleaned\n            \n            # Final fallback\n            return self._create_session_fallback_commit(session_context, git_context)\n            \n        except Exception as e:\n            self._log_debug(f\"Session commit generation error: {e}\")\n            return self._create_session_fallback_commit(session_context, git_context)\n    \n    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        \n        if not file_operations:\n            return \"chore: session updates\"\n            \n        # Count operation types\n        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")\n        \n        # Analyze file types\n        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]\n        \n        # Smart pattern matching\n        if len(files_changed) == 1:\n            file_name = files_changed[0].get(\"file\", \"\")\n            if \"test\" in file_name.lower():\n                return \"test: update test files\"\n            elif \"config\" in file_name.lower():\n                return \"chore(config): update settings\"\n            elif file_name.endswith(\".py\"):\n                return \"refactor: update Python code\"\n            elif file_name.endswith((\".js\", \".ts\")):\n                return \"refactor: update JavaScript code\"\n            else:\n                return f\"chore: update {file_name}\"\n        \n        elif len(py_files) > 0 and len(js_files) == 0:\n            return f\"refactor: update {len(py_files)} Python files\"\n        elif len(js_files) > 0 and len(py_files) == 0:\n            return f\"refactor: update {len(js_files)} JavaScript files\"\n        elif len(config_files) > 0:\n            return \"chore(config): update configuration\"\n        else:\n            return f\"chore: update {len(files_changed)} files\"\n    \n    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any],", "old_string": "            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any],", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any],", "newString": "            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _generate_session_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate commit message for entire session - much simpler and more reliable.\n        Since this runs in Stop hook, we have unlimited time for LLM calls.\n        \"\"\"\n        try:\n            # Build session-level prompt\n            file_operations = tool_history.get(\"file_operations\", [])\n            total_ops = session_context.get(\"total_operations\", 0)\n            file_count = session_context.get(\"file_count\", 0)\n            \n            # Create simple but effective prompt\n            session_prompt = f\"\"\"Generate a git commit message for this session.\n\nSESSION SUMMARY:\n- Total operations: {total_ops}\n- Files changed: {file_count}\n- Activity: {tool_history.get('session_summary', 'code changes')}\n\nFILES CHANGED:\n{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nFORMAT: type(scope): description\nEXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure\n\nCOMMIT MESSAGE:\"\"\"\n\n            # Since we're in Stop hook, we can take time for LLM\n            self._log_debug(\"\u00f0\u0178\u0161\u20ac Session commit generation (unlimited time)\")\n            \n            # Try simple pattern matching first (instant)\n            pattern_commit = self._generate_pattern_commit(session_context, git_context, tool_history)\n            if pattern_commit and pattern_commit != \"chore: update files\":\n                self._log_debug(f\"\u00e2\u0153\u2026 Using pattern-based commit: {pattern_commit}\")\n                return pattern_commit\n            \n            # If pattern matching fails, use LLM (with time to complete)\n            self._log_debug(\"\u00f0\u0178\u201c\udc9d Trying LLM generation for session commit\")\n            llm_commit = self._call_claude_task(session_prompt)\n            if llm_commit and \":\" in llm_commit and len(llm_commit) > 10:\n                cleaned = self._clean_commit_message(llm_commit)\n                self._log_debug(f\"\u00e2\u0153\u2026 LLM generated session commit: {cleaned}\")\n                return cleaned\n            \n            # Final fallback\n            return self._create_session_fallback_commit(session_context, git_context)\n            \n        except Exception as e:\n            self._log_debug(f\"Session commit generation error: {e}\")\n            return self._create_session_fallback_commit(session_context, git_context)\n    \n    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        \n        if not file_operations:\n            return \"chore: session updates\"\n            \n        # Count operation types\n        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")\n        \n        # Analyze file types\n        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]\n        \n        # Smart pattern matching\n        if len(files_changed) == 1:\n            file_name = files_changed[0].get(\"file\", \"\")\n            if \"test\" in file_name.lower():\n                return \"test: update test files\"\n            elif \"config\" in file_name.lower():\n                return \"chore(config): update settings\"\n            elif file_name.endswith(\".py\"):\n                return \"refactor: update Python code\"\n            elif file_name.endswith((\".js\", \".ts\")):\n                return \"refactor: update JavaScript code\"\n            else:\n                return f\"chore: update {file_name}\"\n        \n        elif len(py_files) > 0 and len(js_files) == 0:\n            return f\"refactor: update {len(py_files)} Python files\"\n        elif len(js_files) > 0 and len(py_files) == 0:\n            return f\"refactor: update {len(js_files)} JavaScript files\"\n        elif len(config_files) > 0:\n            return \"chore(config): update configuration\"\n        else:\n            return f\"chore: update {len(files_changed)} files\"\n    \n    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any],", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:\n        \"\"\"\n        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.\n        \n        Args:\n            session_id: Session identifier\n            stop_payload: Stop hook payload with session information\n        \"\"\"\n        try:\n            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")\n            \n            # Load all tool usage from the entire session\n            tool_history = self._load_tool_usage_history(session_id)\n            \n            # Check if there were any meaningful file operations\n            file_operations = tool_history.get(\"file_operations\", [])\n            if not file_operations:\n                self._log_debug(\"No file operations found, skipping checkpoint\")\n                return\n                \n            # Analyze git repository state\n            git_context = self._analyze_git_changes()\n            if not git_context.get(\"files\"):\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return\n                \n            # Build session context\n            session_context = {\n                \"session_id\": session_id,\n                \"total_operations\": len(file_operations),\n                \"file_count\": len(git_context.get(\"files\", [])),\n                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")\n            }\n            \n            # Generate commit for entire session (with unlimited time!)\n            commit_message = self._generate_session_commit(session_context, git_context, tool_history)\n            \n            # Create the commit\n            if self._create_commit(commit_message):\n                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")\n            else:\n                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")\n                \n        except Exception as e:\n            self._log_debug(f\"Session checkpoint error: {e}\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 485, "oldLines": 6, "newStart": 485, "newLines": 115, "lines": ["             self._log_debug(f\"AI commit generation failed: {e}\")", "             return self._create_fallback_commit(tool_context, git_context)", "     ", "+    def _generate_session_commit(self, session_context: Dict[str, Any], ", "+                               git_context: Dict[str, Any],", "+                               tool_history: Dict[str, Any]) -> str:", "+        \"\"\"", "+        Generate commit message for entire session - much simpler and more reliable.", "+        Since this runs in Stop hook, we have unlimited time for LLM calls.", "+        \"\"\"", "+        try:", "+            # Build session-level prompt", "+            file_operations = tool_history.get(\"file_operations\", [])", "+            total_ops = session_context.get(\"total_operations\", 0)", "+            file_count = session_context.get(\"file_count\", 0)", "+            ", "+            # Create simple but effective prompt", "+            session_prompt = f\"\"\"Generate a git commit message for this session.", "+", "+SESSION SUMMARY:", "+- Total operations: {total_ops}", "+- Files changed: {file_count}", "+- Activity: {tool_history.get('session_summary', 'code changes')}", "+", "+FILES CHANGED:", "+{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}", "+{'- ...' if len(file_operations) > 5 else ''}", "+", "+FORMAT: type(scope): description", "+EXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure", "+", "+COMMIT MESSAGE:\"\"\"", "+", "+            # Since we're in Stop hook, we can take time for LLM", "+            self._log_debug(\"\u00f0\u0178\u0161\u20ac Session commit generation (unlimited time)\")", "+            ", "+            # Try simple pattern matching first (instant)", "+            pattern_commit = self._generate_pattern_commit(session_context, git_context, tool_history)", "+            if pattern_commit and pattern_commit != \"chore: update files\":", "+                self._log_debug(f\"\u00e2\u0153\u2026 Using pattern-based commit: {pattern_commit}\")", "+                return pattern_commit", "+            ", "+            # If pattern matching fails, use LLM (with time to complete)", "+            self._log_debug(\"\u00f0\u0178\u201c\udc9d Trying LLM generation for session commit\")", "+            llm_commit = self._call_claude_task(session_prompt)", "+            if llm_commit and \":\" in llm_commit and len(llm_commit) > 10:", "+                cleaned = self._clean_commit_message(llm_commit)", "+                self._log_debug(f\"\u00e2\u0153\u2026 LLM generated session commit: {cleaned}\")", "+                return cleaned", "+            ", "+            # Final fallback", "+            return self._create_session_fallback_commit(session_context, git_context)", "+            ", "+        except Exception as e:", "+            self._log_debug(f\"Session commit generation error: {e}\")", "+            return self._create_session_fallback_commit(session_context, git_context)", "+    ", "+    def _generate_pattern_commit(self, session_context: Dict[str, Any], ", "+                               git_context: Dict[str, Any],", "+                               tool_history: Dict[str, Any]) -> str:", "+        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"", "+        file_operations = tool_history.get(\"file_operations\", [])", "+        files_changed = git_context.get(\"files\", [])", "+        ", "+        if not file_operations:", "+            return \"chore: session updates\"", "+            ", "+        # Count operation types", "+        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")", "+        ", "+        # Analyze file types", "+        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]", "+        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]", "+        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]", "+        ", "+        # Smart pattern matching", "+        if len(files_changed) == 1:", "+            file_name = files_changed[0].get(\"file\", \"\")", "+            if \"test\" in file_name.lower():", "+                return \"test: update test files\"", "+            elif \"config\" in file_name.lower():", "+                return \"chore(config): update settings\"", "+            elif file_name.endswith(\".py\"):", "+                return \"refactor: update Python code\"", "+            elif file_name.endswith((\".js\", \".ts\")):", "+                return \"refactor: update JavaScript code\"", "+            else:", "+                return f\"chore: update {file_name}\"", "+        ", "+        elif len(py_files) > 0 and len(js_files) == 0:", "+            return f\"refactor: update {len(py_files)} Python files\"", "+        elif len(js_files) > 0 and len(py_files) == 0:", "+            return f\"refactor: update {len(js_files)} JavaScript files\"", "+        elif len(config_files) > 0:", "+            return \"chore(config): update configuration\"", "+        else:", "+            return f\"chore: update {len(files_changed)} files\"", "+    ", "+    def _create_session_fallback_commit(self, session_context: Dict[str, Any], ", "+                                      git_context: Dict[str, Any]) -> str:", "+        \"\"\"Create fallback commit for session-level processing.\"\"\"", "+        file_count = session_context.get(\"file_count\", 0)", "+        total_ops = session_context.get(\"total_operations\", 0)", "+        ", "+        if file_count == 1:", "+            files = git_context.get(\"files\", [])", "+            if files:", "+                file_name = files[0].get(\"file\", \"file\")", "+                return f\"chore: update {file_name}\"", "+        ", "+        return f\"chore: session with {total_ops} operations on {file_count} files\"", "+    ", "     def _build_ai_prompt(self, tool_context: Dict[str, Any], ", "                         session_context: Dict[str, Any], ", "                         git_context: Dict[str, Any],"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:23:58.140341", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime", "old_string": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_git_checkpoints import process_tool_checkpoint", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "oldString": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_git_checkpoints import process_tool_checkpoint", "newString": "import json\nimport sys\nimport pathlib\nimport datetime", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"requests>=2.31.0\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_git_checkpoints import process_tool_checkpoint\n\ndef main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler - YouTuber's approach.\n    Directly processes smart git checkpoints from transcript data.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Log tool usage to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process smart checkpoint creation directly from transcript\n        checkpoint_success = process_tool_checkpoint(payload)\n        \n        # Exit with success\n        sys.exit(0 if checkpoint_success else 1)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PostToolUse event to logs directory.\n    \n    Args:\n        payload: Hook payload containing tool information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"post_tool_use.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PostToolUse\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": payload.get(\"tool_response\", {}),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 10, "oldLines": 7, "newStart": 10, "newLines": 6, "lines": [" import sys", " import pathlib", " import datetime", "-from utils.smart_git_checkpoints import process_tool_checkpoint", " ", " def main() -> None:", "     \"\"\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:24:09.161624", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "new_string": "def main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler.\n    Now just logs tool usage - smart commits moved to Stop hook to avoid timing issues.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Just log tool usage to logs directory\n        # Smart git commits now happen in Stop hook (no timing constraints)\n        log_to_logs_directory(payload)\n        \n        # Exit with success\n        sys.exit(0)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)", "old_string": "def main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler - YouTuber's approach.\n    Directly processes smart git checkpoints from transcript data.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Log tool usage to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process smart checkpoint creation directly from transcript\n        checkpoint_success = process_tool_checkpoint(payload)\n        \n        # Exit with success\n        sys.exit(0 if checkpoint_success else 1)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "oldString": "def main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler - YouTuber's approach.\n    Directly processes smart git checkpoints from transcript data.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Log tool usage to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process smart checkpoint creation directly from transcript\n        checkpoint_success = process_tool_checkpoint(payload)\n        \n        # Exit with success\n        sys.exit(0 if checkpoint_success else 1)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)", "newString": "def main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler.\n    Now just logs tool usage - smart commits moved to Stop hook to avoid timing issues.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Just log tool usage to logs directory\n        # Smart git commits now happen in Stop hook (no timing constraints)\n        log_to_logs_directory(payload)\n        \n        # Exit with success\n        sys.exit(0)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"requests>=2.31.0\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\n\ndef main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler - YouTuber's approach.\n    Directly processes smart git checkpoints from transcript data.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Log tool usage to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process smart checkpoint creation directly from transcript\n        checkpoint_success = process_tool_checkpoint(payload)\n        \n        # Exit with success\n        sys.exit(0 if checkpoint_success else 1)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PostToolUse event to logs directory.\n    \n    Args:\n        payload: Hook payload containing tool information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"post_tool_use.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PostToolUse\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": payload.get(\"tool_response\", {}),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 13, "oldLines": 8, "newStart": 13, "newLines": 8, "lines": [" ", " def main() -> None:", "     \"\"\"", "-    Simplified PostToolUse hook handler - YouTuber's approach.", "-    Directly processes smart git checkpoints from transcript data.", "+    Simplified PostToolUse hook handler.", "+    Now just logs tool usage - smart commits moved to Stop hook to avoid timing issues.", "     \"\"\"", "     try:", "         # Read JSON payload from stdin"]}, {"oldStart": 27, "oldLines": 14, "newStart": 27, "newLines": 12, "lines": ["         sys.exit(1)", "     ", "     try:", "-        # Log tool usage to logs directory", "+        # Just log tool usage to logs directory", "+        # Smart git commits now happen in Stop hook (no timing constraints)", "         log_to_logs_directory(payload)", "         ", "-        # Process smart checkpoint creation directly from transcript", "-        checkpoint_success = process_tool_checkpoint(payload)", "-        ", "         # Exit with success", "-        sys.exit(0 if checkpoint_success else 1)", "+        sys.exit(0)", "         ", "     except Exception as e:", "         print(f\"Hook processing error: {e}\", file=sys.stderr)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:25:08.956746", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "from utils.smart_git_checkpoints import SmartGitCheckpoints", "old_string": "from utils.smart_git_checkpoints import SmartGitCheckpoint", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "from utils.smart_git_checkpoints import SmartGitCheckpoint", "newString": "from utils.smart_git_checkpoints import SmartGitCheckpoints", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\nfrom utils.smart_git_checkpoints import SmartGitCheckpoint\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process smart git checkpoints for the entire session\n    process_session_git_checkpoint(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef process_session_git_checkpoint(payload) -> None:\n    \"\"\"\n    Process smart git checkpoints for the entire session.\n    This runs after session ends, so no timing issues with LLM calls.\n    \n    Args:\n        payload: Stop hook payload containing session information\n    \"\"\"\n    try:\n        session_id = payload.get(\"session_id\")\n        if not session_id:\n            return\n            \n        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoint()\n        \n        # Process the entire session at once\n        # This is much better than processing individual tools\n        checkpoint.process_session_checkpoint(session_id, payload)\n        \n    except Exception as e:\n        # Don't fail the hook if git processing fails\n        print(f\"Git checkpoint error: {e}\", file=sys.stderr)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 13, "oldLines": 7, "newStart": 13, "newLines": 7, "lines": [" import pathlib", " import datetime", " from utils.smart_voice_notify import process_stop_notification", "-from utils.smart_git_checkpoints import SmartGitCheckpoint", "+from utils.smart_git_checkpoints import SmartGitCheckpoints", " ", " def main() -> None:", "     \"\"\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:25:17.154250", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoints()", "old_string": "        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoint()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoint()", "newString": "        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoints()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\nfrom utils.smart_git_checkpoints import SmartGitCheckpoints\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process smart git checkpoints for the entire session\n    process_session_git_checkpoint(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef process_session_git_checkpoint(payload) -> None:\n    \"\"\"\n    Process smart git checkpoints for the entire session.\n    This runs after session ends, so no timing issues with LLM calls.\n    \n    Args:\n        payload: Stop hook payload containing session information\n    \"\"\"\n    try:\n        session_id = payload.get(\"session_id\")\n        if not session_id:\n            return\n            \n        # Create smart checkpoint processor\n        checkpoint = SmartGitCheckpoint()\n        \n        # Process the entire session at once\n        # This is much better than processing individual tools\n        checkpoint.process_session_checkpoint(session_id, payload)\n        \n    except Exception as e:\n        # Don't fail the hook if git processing fails\n        print(f\"Git checkpoint error: {e}\", file=sys.stderr)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 52, "oldLines": 7, "newStart": 52, "newLines": 7, "lines": ["             return", "             ", "         # Create smart checkpoint processor", "-        checkpoint = SmartGitCheckpoint()", "+        checkpoint = SmartGitCheckpoints()", "         ", "         # Process the entire session at once", "         # This is much better than processing individual tools"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:30:04.041794", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_tool_use.py", "new_string": "try:\n    from smart_voice_notify import speak\n    VOICE_AVAILABLE = True\nexcept ImportError:\n    VOICE_AVAILABLE = False\n    def speak(text: str):\n        \"\"\"Fallback if voice utilities unavailable\"\"\"\n        pass", "old_string": "try:\n    from smart_voice_notify import speak\n    VOICE_AVAILABLE = True\nexcept ImportError:\n    try:\n        import pyttsx3\n        def speak(text: str):\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(text)\n            eng.runAndWait()\n        VOICE_AVAILABLE = True\n    except ImportError:\n        VOICE_AVAILABLE = False", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_tool_use.py", "oldString": "try:\n    from smart_voice_notify import speak\n    VOICE_AVAILABLE = True\nexcept ImportError:\n    try:\n        import pyttsx3\n        def speak(text: str):\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(text)\n            eng.runAndWait()\n        VOICE_AVAILABLE = True\n    except ImportError:\n        VOICE_AVAILABLE = False", "newString": "try:\n    from smart_voice_notify import speak\n    VOICE_AVAILABLE = True\nexcept ImportError:\n    VOICE_AVAILABLE = False\n    def speak(text: str):\n        \"\"\"Fallback if voice utilities unavailable\"\"\"\n        pass", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport re\nimport pathlib\nimport datetime\nfrom typing import Dict, Any, List, Tuple\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import speak\n    VOICE_AVAILABLE = True\nexcept ImportError:\n    try:\n        import pyttsx3\n        def speak(text: str):\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(text)\n            eng.runAndWait()\n        VOICE_AVAILABLE = True\n    except ImportError:\n        VOICE_AVAILABLE = False\n\ndef main() -> None:\n    \"\"\"\n    PreToolUse hook handler - Deletion prevention system and tool logging.\n    Blocks dangerous deletion operations targeting critical directories.\n    Logs all tool usage for audit trail.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Log all tool usage to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process deletion prevention check\n        result = process_deletion_check(payload)\n        \n        # Output the decision as JSON\n        print(json.dumps(result))\n        \n        # Exit with appropriate code\n        sys.exit(0 if result.get(\"decision\") == \"approve\" else 1)\n        \n    except Exception as e:\n        # Log error and allow operation (fail-open for safety)\n        log_debug(f\"Hook processing error: {e}\")\n        print(json.dumps({\"decision\": \"approve\"}))\n        sys.exit(0)\n\ndef process_deletion_check(payload: Dict[str, Any]) -> Dict[str, str]:\n    \"\"\"\n    Main deletion prevention logic.\n    \n    Args:\n        payload: JSON payload from Claude Code containing tool information\n        \n    Returns:\n        Dict with decision and optional reason\n    \"\"\"\n    # Only process Bash tool calls\n    tool_name = payload.get(\"tool_name\", \"\")\n    if tool_name != \"Bash\":\n        return {\"decision\": \"approve\"}\n    \n    # Extract the bash command\n    tool_input = payload.get(\"tool_input\", {})\n    command = tool_input.get(\"command\", \"\")\n    \n    if not command:\n        return {\"decision\": \"approve\"}\n    \n    # Check for dangerous deletion patterns\n    is_dangerous, reason = is_dangerous_deletion(command)\n    \n    if is_dangerous:\n        # Log the blocked operation\n        log_blocked_operation(payload, command, reason)\n        \n        # Voice notification for blocked command\n        notify_blocked_command(command, reason)\n        \n        return {\n            \"decision\": \"block\",\n            \"reason\": f\"BLOCKED: {reason}\\nCommand: {command}\\n\\nThis operation was blocked to prevent accidental deletion of critical files/directories.\"\n        }\n    \n    return {\"decision\": \"approve\"}\n\ndef is_dangerous_deletion(command: str) -> Tuple[bool, str]:\n    \"\"\"\n    Check if a bash command contains dangerous deletion patterns.\n    \n    Args:\n        command: The bash command to analyze\n        \n    Returns:\n        Tuple of (is_dangerous: bool, reason: str)\n    \"\"\"\n    # Normalize command for analysis\n    cmd_lower = command.lower().strip()\n    \n    # Define dangerous deletion patterns\n    dangerous_patterns = [\n        # Unix/Linux rm patterns\n        (r'\\brm\\s+.*-[rf]*r[rf]*\\s+[./]', \"Recursive rm command detected\"),\n        (r'\\brm\\s+.*-[rf]*f[rf]*\\s+[./]', \"Force rm command detected\"),\n        (r'\\brm\\s+-rf\\b', \"rm -rf detected\"),\n        (r'\\brm\\s+-fr\\b', \"rm -fr detected\"),\n        (r'\\brm\\s+--recursive\\b', \"rm --recursive detected\"),\n        (r'\\brm\\s+--force\\b', \"rm --force detected\"),\n        (r'\\brm\\s+-r\\b', \"rm -r detected\"),\n        (r'\\brm\\s+-f\\b', \"rm -f detected\"),\n        \n        # Glob patterns for destructive commands\n        (r'\\brm\\s+.*\\*', \"rm with glob pattern detected\"),\n        (r'\\brm\\s+.*\\?', \"rm with glob pattern detected\"),\n        (r'\\brm\\s+.*\\[.*\\]', \"rm with glob pattern detected\"),\n        (r'\\brm\\s+.*\\{.*\\}', \"rm with brace expansion detected\"),\n        (r'\\bdel\\s+.*\\*', \"del with glob pattern detected\"),\n        (r'\\bdel\\s+.*\\?', \"del with glob pattern detected\"),\n        (r'\\bremove-item\\s+.*\\*', \"Remove-Item with glob pattern detected\"),\n        (r'\\bremove-item\\s+.*\\?', \"Remove-Item with glob pattern detected\"),\n        (r'\\brm\\s+.*\\.\\*', \"rm with dot glob pattern detected\"),\n        (r'\\bdel\\s+.*\\.\\*', \"del with dot glob pattern detected\"),\n        (r'\\bremove-item\\s+.*\\.\\*', \"Remove-Item with dot glob pattern detected\"),\n        \n        # Windows CMD deletion patterns\n        (r'\\brmdir\\s+/s\\b', \"rmdir /s detected\"),\n        (r'\\brmdir\\s+.*\\s+/s\\b', \"rmdir with /s flag detected\"),\n        (r'\\brmdir\\s+/q\\b', \"rmdir /q detected\"),\n        (r'\\brmdir\\s+.*\\s+/q\\b', \"rmdir with /q flag detected\"),\n        (r'\\bdel\\s+/s\\b', \"del /s detected\"),\n        (r'\\bdel\\s+.*\\s+/s\\b', \"del with /s flag detected\"),\n        (r'\\bdel\\s+/q\\b', \"del /q detected\"),\n        (r'\\bdel\\s+.*\\s+/q\\b', \"del with /q flag detected\"),\n        (r'\\bdel\\s+/f\\b', \"del /f detected\"),\n        (r'\\bdel\\s+.*\\s+/f\\b', \"del with /f flag detected\"),\n        (r'\\berase\\s+/s\\b', \"erase /s detected\"),\n        (r'\\berase\\s+.*\\s+/s\\b', \"erase with /s flag detected\"),\n        \n        # PowerShell destructive patterns\n        (r'\\bremove-item\\s+.*-recurse\\b', \"PowerShell Remove-Item -Recurse detected\"),\n        (r'\\bremove-item\\s+.*-force\\b', \"PowerShell Remove-Item -Force detected\"),\n        (r'\\brm\\s+.*-recurse\\b', \"PowerShell rm -Recurse detected\"),\n        (r'\\brm\\s+.*-force\\b', \"PowerShell rm -Force detected\"),\n        (r'\\bri\\s+.*-recurse\\b', \"PowerShell ri -Recurse detected\"),\n        (r'\\bri\\s+.*-force\\b', \"PowerShell ri -Force detected\"),\n        (r'\\bget-childitem\\s+.*\\|\\s*remove-item\\b', \"PowerShell pipeline deletion detected\"),\n        (r'\\bgci\\s+.*\\|\\s*remove-item\\b', \"PowerShell gci pipeline deletion detected\"),\n        (r'\\bls\\s+.*\\|\\s*remove-item\\b', \"PowerShell ls pipeline deletion detected\"),\n        \n        # Format and destructive system commands\n        (r'\\bformat\\s+[a-z]:\\b', \"Format drive command detected\"),\n        (r'\\bdiskpart\\b', \"Diskpart utility detected\"),\n        (r'\\bfsutil\\s+.*delete\\b', \"Fsutil delete detected\"),\n        (r'\\bcipher\\s+/w\\b', \"Cipher wipe command detected\"),\n        (r'\\bsdelete\\b', \"Secure delete utility detected\"),\n        (r'\\bshred\\b', \"Shred command detected\"),\n        (r'\\bwipe\\b', \"Wipe command detected\"),\n        \n        # Mass deletion patterns\n        (r'\\bfind\\s+.*-delete\\b', \"find with -delete detected\"),\n        (r'\\bxargs\\s+.*rm\\b', \"xargs rm combination detected\"),\n        (r'\\bxargs\\s+.*del\\b', \"xargs del combination detected\"),\n        (r'\\.*\\*.*rm\\b', \"Wildcard rm pattern detected\"),\n        (r'\\.*\\*.*del\\b', \"Wildcard del pattern detected\"),\n        (r'\\.*\\*.*remove-item\\b', \"Wildcard Remove-Item pattern detected\"),\n        \n        # Registry destructive operations\n        (r'\\breg\\s+delete\\b', \"Registry delete command detected\"),\n        (r'\\bregedit\\s+.*-s\\b', \"Silent registry edit detected\"),\n        \n        # Service and process destruction\n        (r'\\btaskkill\\s+/f\\b', \"Force task kill detected\"),\n        (r'\\bsc\\s+delete\\b', \"Service delete detected\"),\n        (r'\\bnet\\s+stop\\b', \"Service stop detected\"),\n        \n        # Network destructive commands\n        (r'\\bnetsh\\s+.*reset\\b', \"Network reset command detected\"),\n        (r'\\bipconfig\\s+/flushdns\\b', \"DNS flush detected\"),\n        \n        # Boot and system destruction\n        (r'\\bbcdedit\\s+.*delete\\b', \"Boot configuration delete detected\"),\n        (r'\\battrib\\s+.*-s\\s+-h\\b', \"System file attribute removal detected\"),\n        (r'\\bbootrec\\s+/fixmbr\\b', \"Master boot record modification detected\"),\n    ]\n    \n    # Check against dangerous patterns - BLOCK ALL MATCHES\n    for pattern, description in dangerous_patterns:\n        if re.search(pattern, cmd_lower):\n            return True, description\n    \n    # Additional broad blocking for any deletion commands\n    broad_deletion_patterns = [\n        (r'\\brm\\s+', \"rm command detected\"),\n        (r'\\bdel\\s+', \"del command detected\"), \n        (r'\\berase\\s+', \"erase command detected\"),\n        (r'\\brmdir\\s+', \"rmdir command detected\"),\n        (r'\\bremove-item\\s+', \"PowerShell Remove-Item detected\"),\n        (r'\\bri\\s+', \"PowerShell ri (Remove-Item alias) detected\"),\n    ]\n    \n    # Block these broad patterns too\n    for pattern, description in broad_deletion_patterns:\n        if re.search(pattern, cmd_lower):\n            return True, description\n    \n    return False, \"\"\n\ndef get_protected_directories() -> List[str]:\n    \"\"\"\n    Get list of directories that should be protected from deletion.\n    \n    Returns:\n        List of directory names/patterns to protect\n    \"\"\"\n    return [\n        \"apps/\",\n        \"app/\",\n        \"src/\",\n        \"source/\",\n        \".git/\",\n        \".github/\",\n        \"node_modules/\",\n        \"packages/\",\n        \"lib/\",\n        \"libs/\",\n        \"components/\",\n        \"pages/\",\n        \"public/\",\n        \"assets/\",\n        \"static/\",\n        \"build/\",\n        \"dist/\",\n        \"docs/\",\n        \".vscode/\",\n        \".idea/\",\n        \"config/\",\n        \"configs/\",\n        \"database/\",\n        \"migrations/\",\n        \"models/\",\n        \"views/\",\n        \"controllers/\",\n        \"services/\",\n        \"utils/\",\n        \"helpers/\",\n        \"middleware/\",\n        \"schemas/\",\n        \"types/\",\n        \"interfaces/\",\n        \"prompts/\"\n    ]\n\ndef log_to_logs_directory(payload: Dict[str, Any]) -> None:\n    \"\"\"\n    Log PreToolUse event to logs directory.\n    \n    Args:\n        payload: Hook payload containing tool information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"pre_tool_use.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PreToolUse\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreToolUse\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        log_debug(f\"Failed to log to logs directory: {e}\")\n\ndef log_blocked_operation(payload: Dict[str, Any], command: str, reason: str) -> None:\n    \"\"\"\n    Log blocked deletion operation for audit trail.\n    \n    Args:\n        payload: Original hook payload\n        command: The blocked command\n        reason: Reason for blocking\n    \"\"\"\n    try:\n        debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        \n        timestamp = datetime.datetime.now().isoformat()\n        session_id = payload.get(\"session_id\", \"unknown\")\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"DELETION_BLOCKED\",\n            \"session_id\": session_id,\n            \"command\": command,\n            \"reason\": reason,\n            \"tool_name\": payload.get(\"tool_name\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\")\n        }\n        \n        with open(debug_log, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        log_debug(f\"Failed to log blocked operation: {e}\")\n\ndef notify_blocked_command(command: str, reason: str) -> None:\n    \"\"\"\n    Send voice notification for blocked command.\n    \n    Args:\n        command: The blocked command\n        reason: Reason for blocking\n    \"\"\"\n    try:\n        if VOICE_AVAILABLE:\n            # Create short, clear voice message\n            if \"rm -rf\" in reason.lower():\n                voice_message = \"Blocked dangerous rm rf command\"\n            elif \"del\" in reason.lower() or \"erase\" in reason.lower():\n                voice_message = \"Blocked dangerous deletion command\"\n            elif \"format\" in reason.lower():\n                voice_message = \"Blocked disk format command\"\n            elif \"remove-item\" in reason.lower():\n                voice_message = \"Blocked PowerShell removal command\"\n            else:\n                voice_message = \"Blocked dangerous command\"\n            \n            log_debug(f\"Sending voice notification: {voice_message}\")\n            speak(voice_message)\n            log_debug(\"Voice notification sent successfully\")\n        else:\n            log_debug(\"Voice notification unavailable\")\n        \n    except Exception as e:\n        # Don't fail the hook if voice notification fails\n        log_debug(f\"Voice notification failed: {e}\")\n\ndef log_debug(message: str) -> None:\n    \"\"\"\n    Log debug message to debug.log file.\n    \n    Args:\n        message: Debug message to log\n    \"\"\"\n    try:\n        debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        timestamp = datetime.datetime.now().isoformat()\n        \n        with open(debug_log, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"[{timestamp}] PRE_TOOL_USE: {message}\\n\")\n            \n    except Exception:\n        # Silently fail if logging doesn't work\n        pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 22, "oldLines": 16, "newStart": 22, "newLines": 10, "lines": ["     from smart_voice_notify import speak", "     VOICE_AVAILABLE = True", " except ImportError:", "-    try:", "-        import pyttsx3", "-        def speak(text: str):", "-            eng = pyttsx3.init()", "-            eng.setProperty(\"rate\", 185)", "-            eng.say(text)", "-            eng.runAndWait()", "-        VOICE_AVAILABLE = True", "-    except ImportError:", "-        VOICE_AVAILABLE = False", "+    VOICE_AVAILABLE = False", "+    def speak(text: str):", "+        \"\"\"Fallback if voice utilities unavailable\"\"\"", "+        pass", " ", " def main() -> None:", "     \"\"\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:30:23.998046", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "new_string": "    except Exception as e:\n        # Fallback if processing fails - use centralized voice function\n        try:\n            from utils.smart_voice_notify import speak\n            speak(\"Claude notification error\")\n        except:\n            # If even centralized TTS fails, just exit silently\n            pass", "old_string": "    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "oldString": "    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass", "newString": "    except Exception as e:\n        # Fallback if processing fails - use centralized voice function\n        try:\n            from utils.smart_voice_notify import speak\n            speak(\"Claude notification error\")\n        except:\n            # If even centralized TTS fails, just exit silently\n            pass", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification\n\ndef main() -> None:\n    \"\"\"\n    Simplified notification handler - just voice notifications.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create error payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Notification\"}\n    except Exception as e:\n        # Handle any other input errors\n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Notification\"}\n    \n    # Validate that this is a Notification hook event\n    if payload.get(\"hook_event_name\") != \"Notification\" and \"transcript_path\" not in payload:\n        # If it's not a proper notification, try to process anyway\n        payload[\"hook_event_name\"] = \"Notification\"\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Notification event to logs directory.\n    \n    Args:\n        payload: Hook payload containing notification information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"notifications.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Notification\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"message\": payload.get(\"message\", \"\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Notification\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 40, "oldLines": 15, "newStart": 40, "newLines": 12, "lines": ["         process_notification(payload)", "         ", "     except Exception as e:", "-        # Fallback if processing fails - at least say something", "-        import pyttsx3", "+        # Fallback if processing fails - use centralized voice function", "         try:", "-            eng = pyttsx3.init()", "-            eng.setProperty(\"rate\", 185)", "-            eng.say(\"Claude notification error\")", "-            eng.runAndWait()", "+            from utils.smart_voice_notify import speak", "+            speak(\"Claude notification error\")", "         except:", "-            # If even basic TTS fails, just exit silently", "+            # If even centralized TTS fails, just exit silently", "             pass", " ", " def log_to_logs_directory(payload) -> None:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:30:49.034350", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "except ImportError as e:\n    # Fallback if import fails - use simplified approach\n    def fallback_speak(text: str):\n        \"\"\"Simplified fallback TTS\"\"\"\n        pass\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation  \n        fallback_speak(\"Compacting the conversation\")", "old_string": "except ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "except ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")", "newString": "except ImportError as e:\n    # Fallback if import fails - use simplified approach\n    def fallback_speak(text: str):\n        \"\"\"Simplified fallback TTS\"\"\"\n        pass\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation  \n        fallback_speak(\"Compacting the conversation\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PreCompact event to logs directory.\n    \n    Args:\n        payload: Hook payload containing compact information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"pre_compact.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PreCompact\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"trigger\": payload.get(\"trigger\", \"unknown\"),\n            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),\n            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 19, "oldLines": 24, "newStart": 19, "newLines": 14, "lines": [" try:", "     from smart_voice_notify import process_compact_notification", " except ImportError as e:", "-    # Fallback if import fails", "-    import pyttsx3", "+    # Fallback if import fails - use simplified approach", "     def fallback_speak(text: str):", "-        eng = pyttsx3.init()", "-        eng.setProperty(\"rate\", 185)", "-        eng.say(text)", "-        eng.runAndWait()", "+        \"\"\"Simplified fallback TTS\"\"\"", "+        pass", "     ", "     def process_compact_notification(payload: dict):", "-        # Simple fallback implementation", "-        compact_type = \"automatic\"", "-        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():", "-            compact_type = \"manual\"", "-        ", "-        if compact_type == \"automatic\":", "-            fallback_speak(\"Automatic compacting the conversation\")", "-        else:", "-            fallback_speak(\"Manual compacting the conversation\")", "+        # Simple fallback implementation  ", "+        fallback_speak(\"Compacting the conversation\")", " ", " def main():", "     \"\"\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:30:59.678145", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "    except Exception as e:\n        # Ultimate fallback - use centralized voice if possible\n        try:\n            from smart_voice_notify import speak\n            speak(\"Compacting the conversation\")\n        except:\n            # If all else fails, just exit silently\n            pass", "old_string": "    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass", "newString": "    except Exception as e:\n        # Ultimate fallback - use centralized voice if possible\n        try:\n            from smart_voice_notify import speak\n            speak(\"Compacting the conversation\")\n        except:\n            # If all else fails, just exit silently\n            pass", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails - use simplified approach\n    def fallback_speak(text: str):\n        \"\"\"Simplified fallback TTS\"\"\"\n        pass\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation  \n        fallback_speak(\"Compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PreCompact event to logs directory.\n    \n    Args:\n        payload: Hook payload containing compact information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"pre_compact.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PreCompact\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"trigger\": payload.get(\"trigger\", \"unknown\"),\n            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),\n            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 53, "oldLines": 13, "newStart": 53, "newLines": 10, "lines": ["         # Fallback for invalid JSON", "         process_compact_notification({\"compact_type\": \"automatic\"})", "     except Exception as e:", "-        # Ultimate fallback - just speak something", "+        # Ultimate fallback - use centralized voice if possible", "         try:", "-            import pyttsx3", "-            eng = pyttsx3.init()", "-            eng.setProperty(\"rate\", 185)", "-            eng.say(\"Compacting the conversation\")", "-            eng.runAndWait()", "+            from smart_voice_notify import speak", "+            speak(\"Compacting the conversation\")", "         except:", "             # If all else fails, just exit silently", "             pass"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:31:21.114987", "event": "PostToolUse", "session_id": "c4e017a9-a989-427b-899c-b4e42c1011b7", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\__init__.py", "new_string": "# Import from the available client\nfrom .client import ask, ask_concise", "old_string": "# Import production-ready functions by default\ntry:\n    from .production_client import ask as prod_ask, ask_concise as prod_ask_concise\n    # Use production client for better reliability\n    ask = prod_ask\n    ask_concise = prod_ask_concise\nexcept ImportError:\n    # Fallback to full client\n    from .client import ask, ask_concise", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\__init__.py", "oldString": "# Import production-ready functions by default\ntry:\n    from .production_client import ask as prod_ask, ask_concise as prod_ask_concise\n    # Use production client for better reliability\n    ask = prod_ask\n    ask_concise = prod_ask_concise\nexcept ImportError:\n    # Fallback to full client\n    from .client import ask, ask_concise", "newString": "# Import from the available client\nfrom .client import ask, ask_concise", "originalFile": "\"\"\"\nLLM Utilities Package for Claude Code Hooks\nCost-efficient AI integration using Claude 3.5 Haiku by default\n\nSimple Usage:\n    from utils.llms import LLMClient, ask, ask_concise\n    \n    # Full client with all features\n    llm = LLMClient()\n    response = llm.ask(\"Generate a commit message for auth.js\")\n    \n    # Quick convenience functions\n    answer = ask(\"What is this error?\")\n    summary = ask_concise(\"Summarize this code\")\n\"\"\"\n\n# Import production-ready functions by default\ntry:\n    from .production_client import ask as prod_ask, ask_concise as prod_ask_concise\n    # Use production client for better reliability\n    ask = prod_ask\n    ask_concise = prod_ask_concise\nexcept ImportError:\n    # Fallback to full client\n    from .client import ask, ask_concise\n\nfrom .client import LLMClient, ask_json\nfrom .config import get_config, update_config, apply_preset, COST_PRESETS\n\n# Version info\n__version__ = \"1.0.0\"\n__author__ = \"Claude Code Hooks\"\n\n# Default exports for easy importing\n__all__ = [\n    # Main client\n    \"LLMClient\",\n    \n    # Convenience functions\n    \"ask\",\n    \"ask_concise\", \n    \"ask_json\",\n    \n    # Configuration\n    \"get_config\",\n    \"update_config\",\n    \"apply_preset\",\n    \"COST_PRESETS\"\n]\n\n# Package-level configuration\nDEFAULT_MODEL = \"claude-3-5-haiku-20241022\"\nPACKAGE_INFO = {\n    \"name\": \"llms\",\n    \"version\": __version__,\n    \"description\": \"Cost-efficient LLM utilities for Claude Code hooks\",\n    \"default_model\": DEFAULT_MODEL,\n    \"features\": [\n        \"Claude 3.5 Haiku by default (cost-efficient)\",\n        \"Automatic model fallbacks (Haiku \u00e2\u2020\u2019 Sonnet \u00e2\u2020\u2019 Manual)\",\n        \"Response caching with TTL\",\n        \"Token usage tracking\",\n        \"Simple API: ask(), ask_concise(), ask_json()\",\n        \"Context-aware prompting with file support\",\n        \"Comprehensive error handling and logging\"\n    ]\n}\n\ndef get_package_info():\n    \"\"\"Get package information and capabilities.\"\"\"\n    return PACKAGE_INFO\n\ndef quick_start_guide():\n    \"\"\"Print quick start guide for new users.\"\"\"\n    guide = \"\"\"\n\u00f0\u0178\u0161\u20ac LLM Utilities Quick Start Guide\n\n1. Basic Usage:\n   from utils.llms import ask\n   response = ask(\"Your question here\")\n\n2. Cost-Efficient Queries:\n   from utils.llms import ask_concise\n   answer = ask_concise(\"Brief answer needed\")\n\n3. Structured Responses:\n   from utils.llms import ask_json\n   data = ask_json(\"Return user info as JSON\")\n\n4. Full Client Features:\n   from utils.llms import LLMClient\n   llm = LLMClient()\n   response = llm.ask_with_context(\"Question\", [\"file1.py\", \"file2.js\"])\n\n5. Configuration:\n   from utils.llms import update_config, apply_preset\n   update_config(default_model=\"claude-3-5-sonnet-20241022\")\n   apply_preset(\"ultra_efficient\")\n\nCost Optimization:\n- Default: Claude 3.5 Haiku (most cost-efficient)\n- Fallbacks: Haiku \u00e2\u2020\u2019 Sonnet \u00e2\u2020\u2019 Manual responses\n- Caching: Automatic response caching (60min TTL)\n- Monitoring: Optional token usage tracking\n\nExample Integration in Hooks:\n```python\nfrom utils.llms import ask_concise\n\ndef your_hook(payload):\n    error_summary = ask_concise(f\"Summarize this error: {error_msg}\")\n    return f\"Error: {error_summary}\"\n```\n\"\"\"\n    print(guide)\n\n# Auto-import check\ndef _check_claude_availability():\n    \"\"\"Check if Claude executable is available.\"\"\"\n    try:\n        import subprocess\n        result = subprocess.run([\"claude\", \"--version\"], \n                              capture_output=True, timeout=5)\n        return result.returncode == 0\n    except:\n        return False\n\n# Package initialization\nif __name__ == \"__main__\":\n    quick_start_guide()\nelse:\n    # Silent availability check on import\n    _claude_available = _check_claude_availability()\n    if not _claude_available:\n        import warnings\n        warnings.warn(\n            \"Claude executable not found. LLM features may not work. \"\n            \"Install Claude Code CLI: https://claude.ai/code\",\n            ImportWarning\n        )", "structuredPatch": [{"oldStart": 14, "oldLines": 15, "newStart": 14, "newLines": 8, "lines": ["     summary = ask_concise(\"Summarize this code\")", " \"\"\"", " ", "-# Import production-ready functions by default", "-try:", "-    from .production_client import ask as prod_ask, ask_concise as prod_ask_concise", "-    # Use production client for better reliability", "-    ask = prod_ask", "-    ask_concise = prod_ask_concise", "-except ImportError:", "-    # Fallback to full client", "-    from .client import ask, ask_concise", "+# Import from the available client", "+from .client import ask, ask_concise", " ", " from .client import LLMClient, ask_json", " from .config import get_config, update_config, apply_preset, COST_PRESETS"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\c4e017a9-a989-427b-899c-b4e42c1011b7.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:48:57.391581", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_voice_notify.py", "new_string": "import json, os, sys, pyttsx3, pathlib, itertools\nfrom utils.llms import ask_concise", "old_string": "import json, os, sys, pyttsx3, pathlib, itertools", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_voice_notify.py", "oldString": "import json, os, sys, pyttsx3, pathlib, itertools", "newString": "import json, os, sys, pyttsx3, pathlib, itertools\nfrom utils.llms import ask_concise", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json, os, sys, pyttsx3, pathlib, itertools\n\ndef speak(text: str, voice_index: int = None) -> None:\n    eng = pyttsx3.init()        # Windows SAPI-5 voice\n    voices = eng.getProperty('voices')\n    \n    # Manual voice selection override\n    if voice_index is not None and voices and 0 <= voice_index < len(voices):\n        eng.setProperty('voice', voices[voice_index].id)\n    elif voices:\n        # Automatic voice selection - try to find a female voice or different one\n        preferred_voices = []\n        for voice in voices:\n            voice_name = voice.name.lower()\n            # Look for female voices or specific good voices\n            if any(keyword in voice_name for keyword in ['zira', 'hazel', 'helen', 'female', 'woman']):\n                preferred_voices.append(voice)\n        \n        # If we found preferred voices, use the first one\n        if preferred_voices:\n            eng.setProperty('voice', preferred_voices[0].id)\n        # Otherwise, use the second voice if available (usually different from default)\n        elif len(voices) > 1:\n            eng.setProperty('voice', voices[1].id)\n    \n    eng.setProperty(\"rate\", 185)\n    eng.say(text)\n    eng.runAndWait()\n\ndef get_simple_notification(context: str, tool: str) -> str:\n    \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"\n    if context == \"permission_request\":\n        # Simple permission requests\n        tool_messages = {\n            \"Read\": \"Permission for Read\",\n            \"Write\": \"Permission for Write\", \n            \"Edit\": \"Permission for Edit\",\n            \"MultiEdit\": \"Permission for MultiEdit\",\n            \"Bash\": \"Permission for Bash\",\n            \"LS\": \"Permission for LS\",\n            \"Grep\": \"Permission for Grep\",\n            \"Glob\": \"Permission for Glob\",\n            \"Update\": \"Permission for Update\",\n            \"Task\": \"Permission for Task\",\n            \"Plan\": \"Permission for Plan\"\n        }\n        return tool_messages.get(tool, f\"Permission for {tool}\")\n    \n    elif context == \"tool_completion\":\n        # Simple completion messages\n        tool_messages = {\n            \"Read\": \"Read complete\",\n            \"Write\": \"Write complete\",\n            \"Edit\": \"Edit complete\", \n            \"MultiEdit\": \"MultiEdit complete\",\n            \"Bash\": \"Command complete\",\n            \"LS\": \"Directory listed\",\n            \"Grep\": \"Search complete\",\n            \"Glob\": \"Files found\",\n            \"Update\": \"Update complete\",\n            \"Task\": \"Task complete\"\n        }\n        return tool_messages.get(tool, f\"{tool} complete\")\n    \n    elif context == \"session_end\":\n        if tool and any(keyword in tool.lower() for keyword in [\"commit\", \"git\", \"file\"]):\n            return \"Session complete with changes\"\n        return \"Claude session complete\"\n    \n    elif context == \"error_notification\":\n        return \"Error occurred\"\n    \n    elif context == \"waiting\":\n        return \"Claude ready\"\n    \n    elif context == \"compact_notification\":\n        # Extract compact type from tool parameter\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting the conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting the conversation\"\n        else:\n            return \"Compacting the conversation\"\n    \n    else:\n        return \"Claude notification\"\n\ndef get_fallback_response(context: str, tool: str) -> str:\n    \"\"\"\n    Provide fallback responses when Gemini fails or returns empty\n    \"\"\"\n    if context == \"permission_request\":\n        return f\"Claude needs your confirmation for {tool}\"\n    elif context == \"tool_completion\":\n        if tool:\n            return f\"{tool} completed successfully\"\n        else:\n            return \"Tool operation completed\"\n    elif context == \"error_notification\":\n        return \"Claude encountered an error\"\n    elif context == \"completion_notification\":\n        return \"Task completed successfully\"\n    elif context == \"input_required\":\n        return \"Claude needs your input\"\n    elif context == \"status_update\":\n        return \"Claude status update\"\n    elif context == \"general_notification\":\n        return \"Claude notification received\"\n    elif context == \"waiting\":\n        return \"Claude is ready\"\n    elif context == \"session_end\":\n        if tool:  # tool parameter contains session info for Stop context\n            return f\"Claude session finished, {tool}\"\n        else:\n            return \"Claude session completed successfully\"\n    elif context == \"compact_notification\":\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting conversation\"\n        else:\n            return \"Compacting conversation\"\n    else:\n        return \"Claude notification received\"\n\ndef generate_context_prompt(context: str, tool: str, result: str) -> str:\n    \"\"\"\n    Generate simple, clear prompts that speak TO the user ABOUT Claude\n    \"\"\"\n    if context == \"permission_request\":\n        return (\n            f\"Say in 6 words or less that Claude needs your confirmation for {tool}. \"\n            f\"Speak to the user, not to Claude. Example: 'Claude needs your confirmation for {tool}' or 'Confirm {tool} permission'\"\n        )\n    elif context == \"tool_completion\":\n        # Check if result indicates error or success\n        if any(error_word in result.lower() for error_word in [\"error\", \"failed\", \"exception\", \"denied\"]):\n            return (\n                f\"Tell the user in 5 words that {tool} failed. \"\n                f\"Example: '{tool} failed' or 'Error in {tool}'\"\n            )\n        else:\n            return (\n                f\"Tell the user in 5 words that {tool} completed successfully. \"\n                f\"Example: '{tool} finished' or '{tool} completed successfully'\"\n            )\n    elif context == \"error_notification\":\n        return (\n            f\"Tell the user in 4 words that Claude encountered an error: {result[:30]}. \"\n            f\"Example: 'Claude encountered error' or 'Error occurred'\"\n        )\n    elif context == \"completion_notification\":\n        return (\n            f\"Tell the user in 4 words that a task completed: {result[:30]}. \"\n            f\"Example: 'Task completed successfully' or 'Operation finished'\"\n        )\n    elif context == \"input_required\":\n        return (\n            f\"Tell the user in 5 words that Claude needs their input. \"\n            f\"Example: 'Claude needs your input' or 'Your input required'\"\n        )\n    elif context == \"status_update\":\n        return (\n            f\"Tell the user in 4 words about Claude's status: {result[:30]}. \"\n            f\"Example: 'Claude status update' or 'Claude ready'\"\n        )\n    elif context == \"general_notification\":\n        return (\n            f\"Tell the user in 5 words about this notification: {result[:40]}. \"\n            f\"Example: 'Claude notification received' or brief summary of notification\"\n        )\n    elif context == \"waiting\":\n        return (\n            f\"Tell the user in 3 words that Claude is ready. \"\n            f\"Example: 'Claude ready' or 'Ready for input'\"\n        )\n    elif context == \"session_end\":\n        if tool and result:\n            return (\n                f\"Tell the user Claude session ended with comprehensive context: {tool}. \"\n                f\"Be smart and meaningful, under 8 words. \"\n                f\"Example: 'Claude finished, {tool}' or 'Session complete, {result}'\"\n            )\n        elif tool:\n            return (\n                f\"Tell the user Claude session ended with: {tool}. \"\n                f\"Be comprehensive but under 6 words. \"\n                f\"Example: 'Claude finished working with {tool}' or 'Session complete, used {tool}'\"\n            )\n        else:\n            return (\n                f\"Tell the user Claude session ended successfully. \"\n                f\"Be professional and brief, under 5 words. \"\n                f\"Example: 'Claude session completed' or 'Work finished successfully'\"\n            )\n    elif context == \"compact_notification\":\n        return (\n            f\"Tell the user that Claude is compacting the conversation. \"\n            f\"Type is: {tool}. Be concise, under 6 words. \"\n            f\"Example: 'Automatic compacting the conversation' or 'Manual compacting the conversation'\"\n        )\n    else:\n        return (\n            f\"Say 'Claude notification' in 2 words or less.\"\n        )\n\ndef detect_notification_context(payload: dict, transcript_path: pathlib.Path) -> tuple[str, str, str]:\n    \"\"\"\n    Detect the context of a notification and extract tool/result information\n    Returns: (context, tool, result)\n    \"\"\"\n    message = payload.get(\"message\", \"\")\n    \n    # Enhanced detection patterns for various notification types\n    \n    # 1. Permission/Confirmation requests - Multiple patterns\n    if any(pattern in message.lower() for pattern in [\n        \"needs your permission to use\",\n        \"needs permission to use\", \n        \"wants to use\",\n        \"requesting permission\",\n        \"confirm to proceed\",\n        \"confirmation required\",\n        \"needs your confirmation\",\n        \"confirm this action\",\n        \"proceed with\",\n        \"allow claude to\"\n    ]):\n        # Extract tool name from various message formats\n        tool = \"unknown tool\"\n        \n        # Try different extraction patterns\n        if \"use \" in message:\n            parts = message.split(\"use \")\n            if len(parts) > 1:\n                tool = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n        elif \"with \" in message:\n            parts = message.split(\"with \")\n            if len(parts) > 1:\n                tool = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n        elif \"to \" in message:\n            parts = message.split(\"to \")\n            if len(parts) > 1:\n                extracted = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n                # Only use if it looks like a tool name (short, no spaces)\n                if len(extracted.split()) <= 2:\n                    tool = extracted\n        \n        return \"permission_request\", tool, f\"Requesting permission for {tool}\"\n    \n    # 2. Error/Warning notifications\n    if any(pattern in message.lower() for pattern in [\n        \"error occurred\",\n        \"failed to\",\n        \"warning:\",\n        \"could not\",\n        \"unable to\",\n        \"permission denied\",\n        \"access denied\",\n        \"file not found\",\n        \"network error\"\n    ]):\n        return \"error_notification\", \"error\", f\"Error: {message[:50]}...\"\n    \n    # 3. Task completion notifications  \n    if any(pattern in message.lower() for pattern in [\n        \"task completed\",\n        \"operation finished\",\n        \"successfully completed\",\n        \"done\",\n        \"finished\",\n        \"completed successfully\"\n    ]):\n        return \"completion_notification\", \"task\", message\n    \n    # 4. User input required\n    if any(pattern in message.lower() for pattern in [\n        \"waiting for input\",\n        \"please respond\",\n        \"your input needed\",\n        \"waiting for your response\",\n        \"please provide\"\n    ]):\n        return \"input_required\", \"user_input\", \"Waiting for your input\"\n    \n    # 5. System status updates\n    if any(pattern in message.lower() for pattern in [\n        \"ready for\",\n        \"standing by\",\n        \"available\",\n        \"idle\",\n        \"waiting\"\n    ]):\n        return \"status_update\", \"system\", message\n    \n    # 6. If not a specific notification, check transcript for recent tool activity\n    tool, result = last_post_tooluse(transcript_path)\n    if tool:\n        return \"tool_completion\", tool, result\n    \n    # 7. Default case - general notification\n    if message and len(message.strip()) > 0:\n        return \"general_notification\", \"notification\", message\n    \n    # 8. Final fallback\n    return \"waiting\", \"\", \"Claude is ready\"\n\ndef last_post_tooluse(transcript: pathlib.Path) -> tuple[str, str]:\n    \"\"\"\n    Scan the transcript bottom-up and return (tool_name, summary)\n    Enhanced to provide more intelligent summaries\n    \"\"\"\n    if not transcript.exists():\n        return \"\", \"\"\n        \n    with transcript.open(\"r\", encoding=\"utf-8\") as f:\n        lines = f.readlines()\n        \n    # Look for the most recent PostToolUse event\n    for line in reversed(lines):\n        try:\n            record = json.loads(line.strip())\n        except json.JSONDecodeError:\n            continue\n            \n        if record.get(\"hook_event_name\") == \"PostToolUse\":\n            tool = record.get(\"tool_name\", \"\")\n            tool_response = record.get(\"tool_response\", {})\n            tool_input = record.get(\"tool_input\", {})\n            \n            # Generate intelligent summary based on tool type\n            summary = generate_tool_summary(tool, tool_input, tool_response)\n                \n            return tool, summary\n            \n    return \"\", \"\"\n\ndef generate_tool_summary(tool: str, tool_input: dict, tool_response: any) -> str:\n    \"\"\"\n    Generate intelligent summaries based on tool type and response\n    \"\"\"\n    if tool == \"Write\":\n        if isinstance(tool_response, dict):\n            file_path = tool_response.get(\"filePath\", tool_input.get(\"file_path\", \"\"))\n            if file_path:\n                return f\"Created/updated file: {file_path.split('/')[-1]}\"\n        return \"File operation completed\"\n    \n    elif tool == \"Edit\" or tool == \"MultiEdit\":\n        if isinstance(tool_input, dict):\n            file_path = tool_input.get(\"file_path\", \"\")\n            if file_path:\n                return f\"Modified file: {file_path.split('/')[-1]}\"\n        return \"File editing completed\"\n    \n    elif tool == \"Read\":\n        if isinstance(tool_input, dict):\n            file_path = tool_input.get(\"file_path\", \"\")\n            if file_path:\n                return f\"Read file: {file_path.split('/')[-1]}\"\n        return \"File reading completed\"\n    \n    elif tool == \"Bash\":\n        if isinstance(tool_response, dict):\n            stdout = tool_response.get(\"stdout\", \"\")\n            stderr = tool_response.get(\"stderr\", \"\")\n            exit_code = tool_response.get(\"exit_code\", 0)\n            \n            if exit_code != 0:\n                return f\"Command failed with exit code {exit_code}\"\n            elif stdout:\n                return f\"Command output: {stdout[:50]}...\"\n            else:\n                return \"Command executed successfully\"\n        return \"Command completed\"\n    \n    elif tool == \"LS\":\n        if isinstance(tool_response, str):\n            file_count = len(tool_response.strip().split('\\n')) if tool_response.strip() else 0\n            return f\"Listed {file_count} items in directory\"\n        return \"Directory listing completed\"\n    \n    elif tool == \"Grep\":\n        if isinstance(tool_response, str):\n            match_count = len(tool_response.strip().split('\\n')) if tool_response.strip() else 0\n            return f\"Found {match_count} matches\"\n        return \"Search completed\"\n    \n    else:\n        # Generic summary for unknown tools\n        if isinstance(tool_response, dict):\n            if \"error\" in str(tool_response).lower():\n                return f\"{tool} encountered an error\"\n            else:\n                return f\"{tool} completed successfully\"\n        elif isinstance(tool_response, str):\n            if tool_response and len(tool_response) > 0:\n                return f\"{tool} returned: {tool_response[:50]}...\"\n            else:\n                return f\"{tool} completed\"\n        else:\n            return f\"{tool} operation completed\"\n\ndef list_available_voices() -> None:\n    \"\"\"List all available voices on the system for user selection.\"\"\"\n    print(\"\u00f0\u0178\u017d\u00a4 Available voices on your system:\")\n    eng = pyttsx3.init()\n    voices = eng.getProperty('voices')\n    \n    if voices:\n        for i, voice in enumerate(voices):\n            print(f\"{i}: {voice.name} - {voice.id}\")\n            print(f\"   Languages: {getattr(voice, 'languages', 'Unknown')}\")\n            print(f\"   Gender: {getattr(voice, 'gender', 'Unknown')}\")\n            print()\n    else:\n        print(\"No voices found!\")\n    \n    # Test the current voice selection\n    print(\"\u00f0\u0178\u201d\u0160 Testing current voice selection...\")\n    speak(\"Hello! This is your Claude Code voice assistant.\")\n\ndef test_voice_notification() -> None:\n    \"\"\"Manual test mode - simulate different notification scenarios\"\"\"\n    print(\"Testing voice notification system...\")\n    \n    # First, show available voices\n    list_available_voices()\n    \n    # Test scenarios\n    scenarios = [\n        {\n            \"name\": \"Permission Request\",\n            \"context\": \"permission_request\",\n            \"tool\": \"Bash\",\n            \"result\": \"Requesting permission to use Bash\"\n        },\n        {\n            \"name\": \"Successful Tool Completion\",\n            \"context\": \"tool_completion\", \n            \"tool\": \"Read\",\n            \"result\": \"File contents loaded successfully\"\n        },\n        {\n            \"name\": \"Tool Error\",\n            \"context\": \"tool_completion\",\n            \"tool\": \"Write\", \n            \"result\": \"Error: Permission denied\"\n        },\n        {\n            \"name\": \"Waiting/Ready\",\n            \"context\": \"waiting\",\n            \"tool\": \"\",\n            \"result\": \"Claude is ready\"\n        },\n        {\n            \"name\": \"Automatic Compact\",\n            \"context\": \"compact_notification\",\n            \"tool\": \"automatic\",\n            \"result\": \"Starting automatic compacting\"\n        },\n        {\n            \"name\": \"Manual Compact\",\n            \"context\": \"compact_notification\",\n            \"tool\": \"manual\",\n            \"result\": \"Starting manual compacting\"\n        }\n    ]\n    \n    for i, scenario in enumerate(scenarios, 1):\n        print(f\"\\n--- Test {i}: {scenario['name']} ---\")\n        print(f\"Context: {scenario['context']}\")\n        print(f\"Tool: {scenario['tool']}\")\n        print(f\"Result: {scenario['result']}\")\n        \n        text = get_simple_notification(scenario['context'], scenario['tool'])\n        \n        print(f\"Simple notification: {text}\")\n        print(\"Speaking...\")\n        speak(text or \"Notification received.\")\n        print(\"Done.\")\n    \n    print(\"\\nAll tests complete!\")\n\ndef process_notification(payload: dict) -> None:\n    \"\"\"\n    Main notification processing function called by the hook handler.\n    Takes a payload dict and handles the voice notification logic.\n    \"\"\"\n    # Debug: Log detailed hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"unknown\"\n        }\n    }\n    \n    # Determine hook type from payload\n    if \"hook_event_name\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = payload[\"hook_event_name\"]\n    elif \"transcript_path\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = \"Notification\"\n    else:\n        debug_info[\"environment\"][\"hook_type\"] = \"Unknown/Direct\"\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Handle pure Notification events only\n    if \"transcript_path\" in payload:\n        transcript_path = pathlib.Path(payload[\"transcript_path\"])\n        notification_message = payload.get(\"message\", \"\")\n        \n        # Detect notification context\n        context, tool, result = detect_notification_context(payload, transcript_path)\n        \n        if not tool and not result:\n            speak(\"Claude is ready.\")\n            return\n    else:\n        # Unknown format - should not happen with pure Notification hooks\n        speak(\"Claude notification received.\")\n        return\n\n    # Generate simple, direct notification\n    text = get_simple_notification(context, tool)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude notification\"\n    speak(final_text)\n\ndef detect_stop_context(payload: dict) -> tuple[str, str]:\n    \"\"\"\n    Analyze Stop hook payload to extract meaningful session context.\n    Returns: (context_summary, detailed_info)\n    \"\"\"\n    # Look for git activity or recent commits\n    recent_commits = payload.get(\"recent_commits\", [])\n    files_changed = payload.get(\"files_changed\", [])\n    session_duration = payload.get(\"session_duration\", \"\")\n    tools_used = payload.get(\"tools_used\", [])\n    \n    # Build smart context summary\n    if recent_commits and len(recent_commits) > 0:\n        commit_count = len(recent_commits)\n        if commit_count == 1:\n            return f\"saved 1 commit\", f\"git activity with {commit_count} commit\"\n        else:\n            return f\"saved {commit_count} commits\", f\"git activity with {commit_count} commits\"\n    \n    elif files_changed and len(files_changed) > 0:\n        file_count = len(files_changed)\n        if file_count == 1:\n            return f\"modified 1 file\", f\"file changes: {file_count} file\"\n        else:\n            return f\"modified {file_count} files\", f\"file changes: {file_count} files\"\n    \n    elif tools_used and len(tools_used) > 0:\n        if len(tools_used) == 1:\n            return f\"used {tools_used[0]}\", f\"tools: {tools_used[0]}\"\n        elif len(tools_used) <= 3:\n            tool_list = \", \".join(tools_used)\n            return f\"used {tool_list}\", f\"tools: {tool_list}\"\n        else:\n            return f\"used {len(tools_used)} tools\", f\"tools: {len(tools_used)} different tools\"\n    \n    elif session_duration:\n        return f\"worked for {session_duration}\", f\"duration: {session_duration}\"\n    \n    else:\n        return \"completed work\", \"general session completion\"\n\ndef process_stop_notification(payload: dict) -> None:\n    \"\"\"\n    Process Stop hook events and provide smart voice feedback about session completion.\n    Uses existing utilities for consistency.\n    \"\"\"\n    # Debug: Log Stop hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"stop_hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"Stop\"\n        }\n    }\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Analyze session context for simple feedback\n    context_summary, detailed_info = detect_stop_context(payload)\n    \n    # Generate simple session end notification\n    text = get_simple_notification(\"session_end\", context_summary)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude session complete\"\n    speak(final_text)\n\ndef process_compact_notification(payload: dict) -> None:\n    \"\"\"\n    Process PreCompact hook events and provide voice feedback about compacting.\n    Uses existing utilities for consistency.\n    \"\"\"\n    # Debug: Log PreCompact hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"pre_compact_hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"PreCompact\"\n        }\n    }\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Determine if it's automatic or manual compacting\n    # Check payload for compact type indicators\n    compact_type = \"unknown\"\n    \n    # Check various payload fields that might indicate automatic vs manual\n    if \"automatic\" in str(payload).lower() or \"auto\" in str(payload).lower():\n        compact_type = \"automatic\"\n    elif \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n        compact_type = \"manual\"\n    else:\n        # Default to automatic if we can't determine\n        compact_type = \"automatic\"\n    \n    # Generate compact notification\n    text = get_simple_notification(\"compact_notification\", compact_type)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Compacting the conversation\"\n    speak(final_text)\n\nif __name__ == \"__main__\":\n    # If run directly, enter test mode\n    test_voice_notification()", "structuredPatch": [{"oldStart": 8, "oldLines": 6, "newStart": 8, "newLines": 7, "lines": [" # ///", " ", " import json, os, sys, pyttsx3, pathlib, itertools", "+from utils.llms import ask_concise", " ", " def speak(text: str, voice_index: int = None) -> None:", "     eng = pyttsx3.init()        # Windows SAPI-5 voice"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:49:22.217459", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_voice_notify.py", "new_string": "def get_dynamic_notification(tool: str, summary: str) -> str:\n    \"\"\"Generate a friendly, dynamic voice notification using an LLM.\"\"\"\n    if not summary:\n        return \"\" # Can't generate a notification without a summary\n\n    try:\n        # We use a very specific prompt to get a short, conversational response.\n        prompt = (\n            f\"You are a voice assistant for a programmer. Create a very short, friendly notification \"\n            f\"(under 12 words) for the following completed action. Be conversational. \"\n            f\"Do not say 'task completed'.\\n\\n\"\n            f\"Tool Used: '{tool}'\\n\"\n            f\"Action Summary: '{summary}'\\n\\n\"\n            f\"Example: If the summary is 'Modified file: auth.py', a good response would be \"\n            f\"'Okay, I've just updated the auth file for you.'\\n\\n\"\n            f\"Your notification:\"\n        )\n        \n        # Use the cost-efficient LLM utility\n        notification_text = ask_concise(prompt)\n        \n        if notification_text and \"unavailable\" not in notification_text:\n            return notification_text\n        return \"\"\n    except Exception:\n        # If the LLM call fails for any reason, return an empty string\n        # The system will then fall back to the simple notification\n        return \"\"\n\ndef get_simple_notification(context: str, tool: str) -> str:\n    \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"\n    if context == \"permission_request\":\n        # Simple permission requests\n        tool_messages = {\n            \"Read\": \"Permission for Read\",\n            \"Write\": \"Permission for Write\", \n            \"Edit\": \"Permission for Edit\",\n            \"MultiEdit\": \"Permission for MultiEdit\",\n            \"Bash\": \"Permission for Bash\",\n            \"LS\": \"Permission for LS\",\n            \"Grep\": \"Permission for Grep\",\n            \"Glob\": \"Permission for Glob\",\n            \"Update\": \"Permission for Update\",\n            \"Task\": \"Permission for Task\",\n            \"Plan\": \"Permission for Plan\"\n        }\n        return tool_messages.get(tool, f\"Permission for {tool}\")\n    \n    elif context == \"tool_completion\":\n        # Simple completion messages\n        tool_messages = {\n            \"Read\": \"Read complete\",\n            \"Write\": \"Write complete\",\n            \"Edit\": \"Edit complete\", \n            \"MultiEdit\": \"MultiEdit complete\",\n            \"Bash\": \"Command complete\",\n            \"LS\": \"Directory listed\",\n            \"Grep\": \"Search complete\",\n            \"Glob\": \"Files found\",\n            \"Update\": \"Update complete\",\n            \"Task\": \"Task complete\"\n        }\n        return tool_messages.get(tool, f\"{tool} complete\")\n    \n    elif context == \"session_end\":\n        if tool and any(keyword in tool.lower() for keyword in [\"commit\", \"git\", \"file\"]):\n            return \"Session complete with changes\"\n        return \"Claude session complete\"\n    \n    elif context == \"error_notification\":\n        return \"Error occurred\"\n    \n    elif context == \"waiting\":\n        return \"Claude ready\"\n    \n    elif context == \"compact_notification\":\n        # Extract compact type from tool parameter\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting the conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting the conversation\"\n        else:\n            return \"Compacting the conversation\"\n    \n    else:\n        return \"Claude notification\"", "old_string": "def get_simple_notification(context: str, tool: str) -> str:\n    \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"\n    if context == \"permission_request\":\n        # Simple permission requests\n        tool_messages = {\n            \"Read\": \"Permission for Read\",\n            \"Write\": \"Permission for Write\", \n            \"Edit\": \"Permission for Edit\",\n            \"MultiEdit\": \"Permission for MultiEdit\",\n            \"Bash\": \"Permission for Bash\",\n            \"LS\": \"Permission for LS\",\n            \"Grep\": \"Permission for Grep\",\n            \"Glob\": \"Permission for Glob\",\n            \"Update\": \"Permission for Update\",\n            \"Task\": \"Permission for Task\",\n            \"Plan\": \"Permission for Plan\"\n        }\n        return tool_messages.get(tool, f\"Permission for {tool}\")\n    \n    elif context == \"tool_completion\":\n        # Simple completion messages\n        tool_messages = {\n            \"Read\": \"Read complete\",\n            \"Write\": \"Write complete\",\n            \"Edit\": \"Edit complete\", \n            \"MultiEdit\": \"MultiEdit complete\",\n            \"Bash\": \"Command complete\",\n            \"LS\": \"Directory listed\",\n            \"Grep\": \"Search complete\",\n            \"Glob\": \"Files found\",\n            \"Update\": \"Update complete\",\n            \"Task\": \"Task complete\"\n        }\n        return tool_messages.get(tool, f\"{tool} complete\")\n    \n    elif context == \"session_end\":\n        if tool and any(keyword in tool.lower() for keyword in [\"commit\", \"git\", \"file\"]):\n            return \"Session complete with changes\"\n        return \"Claude session complete\"\n    \n    elif context == \"error_notification\":\n        return \"Error occurred\"\n    \n    elif context == \"waiting\":\n        return \"Claude ready\"\n    \n    elif context == \"compact_notification\":\n        # Extract compact type from tool parameter\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting the conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting the conversation\"\n        else:\n            return \"Compacting the conversation\"\n    \n    else:\n        return \"Claude notification\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_voice_notify.py", "oldString": "def get_simple_notification(context: str, tool: str) -> str:\n    \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"\n    if context == \"permission_request\":\n        # Simple permission requests\n        tool_messages = {\n            \"Read\": \"Permission for Read\",\n            \"Write\": \"Permission for Write\", \n            \"Edit\": \"Permission for Edit\",\n            \"MultiEdit\": \"Permission for MultiEdit\",\n            \"Bash\": \"Permission for Bash\",\n            \"LS\": \"Permission for LS\",\n            \"Grep\": \"Permission for Grep\",\n            \"Glob\": \"Permission for Glob\",\n            \"Update\": \"Permission for Update\",\n            \"Task\": \"Permission for Task\",\n            \"Plan\": \"Permission for Plan\"\n        }\n        return tool_messages.get(tool, f\"Permission for {tool}\")\n    \n    elif context == \"tool_completion\":\n        # Simple completion messages\n        tool_messages = {\n            \"Read\": \"Read complete\",\n            \"Write\": \"Write complete\",\n            \"Edit\": \"Edit complete\", \n            \"MultiEdit\": \"MultiEdit complete\",\n            \"Bash\": \"Command complete\",\n            \"LS\": \"Directory listed\",\n            \"Grep\": \"Search complete\",\n            \"Glob\": \"Files found\",\n            \"Update\": \"Update complete\",\n            \"Task\": \"Task complete\"\n        }\n        return tool_messages.get(tool, f\"{tool} complete\")\n    \n    elif context == \"session_end\":\n        if tool and any(keyword in tool.lower() for keyword in [\"commit\", \"git\", \"file\"]):\n            return \"Session complete with changes\"\n        return \"Claude session complete\"\n    \n    elif context == \"error_notification\":\n        return \"Error occurred\"\n    \n    elif context == \"waiting\":\n        return \"Claude ready\"\n    \n    elif context == \"compact_notification\":\n        # Extract compact type from tool parameter\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting the conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting the conversation\"\n        else:\n            return \"Compacting the conversation\"\n    \n    else:\n        return \"Claude notification\"", "newString": "def get_dynamic_notification(tool: str, summary: str) -> str:\n    \"\"\"Generate a friendly, dynamic voice notification using an LLM.\"\"\"\n    if not summary:\n        return \"\" # Can't generate a notification without a summary\n\n    try:\n        # We use a very specific prompt to get a short, conversational response.\n        prompt = (\n            f\"You are a voice assistant for a programmer. Create a very short, friendly notification \"\n            f\"(under 12 words) for the following completed action. Be conversational. \"\n            f\"Do not say 'task completed'.\\n\\n\"\n            f\"Tool Used: '{tool}'\\n\"\n            f\"Action Summary: '{summary}'\\n\\n\"\n            f\"Example: If the summary is 'Modified file: auth.py', a good response would be \"\n            f\"'Okay, I've just updated the auth file for you.'\\n\\n\"\n            f\"Your notification:\"\n        )\n        \n        # Use the cost-efficient LLM utility\n        notification_text = ask_concise(prompt)\n        \n        if notification_text and \"unavailable\" not in notification_text:\n            return notification_text\n        return \"\"\n    except Exception:\n        # If the LLM call fails for any reason, return an empty string\n        # The system will then fall back to the simple notification\n        return \"\"\n\ndef get_simple_notification(context: str, tool: str) -> str:\n    \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"\n    if context == \"permission_request\":\n        # Simple permission requests\n        tool_messages = {\n            \"Read\": \"Permission for Read\",\n            \"Write\": \"Permission for Write\", \n            \"Edit\": \"Permission for Edit\",\n            \"MultiEdit\": \"Permission for MultiEdit\",\n            \"Bash\": \"Permission for Bash\",\n            \"LS\": \"Permission for LS\",\n            \"Grep\": \"Permission for Grep\",\n            \"Glob\": \"Permission for Glob\",\n            \"Update\": \"Permission for Update\",\n            \"Task\": \"Permission for Task\",\n            \"Plan\": \"Permission for Plan\"\n        }\n        return tool_messages.get(tool, f\"Permission for {tool}\")\n    \n    elif context == \"tool_completion\":\n        # Simple completion messages\n        tool_messages = {\n            \"Read\": \"Read complete\",\n            \"Write\": \"Write complete\",\n            \"Edit\": \"Edit complete\", \n            \"MultiEdit\": \"MultiEdit complete\",\n            \"Bash\": \"Command complete\",\n            \"LS\": \"Directory listed\",\n            \"Grep\": \"Search complete\",\n            \"Glob\": \"Files found\",\n            \"Update\": \"Update complete\",\n            \"Task\": \"Task complete\"\n        }\n        return tool_messages.get(tool, f\"{tool} complete\")\n    \n    elif context == \"session_end\":\n        if tool and any(keyword in tool.lower() for keyword in [\"commit\", \"git\", \"file\"]):\n            return \"Session complete with changes\"\n        return \"Claude session complete\"\n    \n    elif context == \"error_notification\":\n        return \"Error occurred\"\n    \n    elif context == \"waiting\":\n        return \"Claude ready\"\n    \n    elif context == \"compact_notification\":\n        # Extract compact type from tool parameter\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting the conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting the conversation\"\n        else:\n            return \"Compacting the conversation\"\n    \n    else:\n        return \"Claude notification\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json, os, sys, pyttsx3, pathlib, itertools\nfrom utils.llms import ask_concise\n\ndef speak(text: str, voice_index: int = None) -> None:\n    eng = pyttsx3.init()        # Windows SAPI-5 voice\n    voices = eng.getProperty('voices')\n    \n    # Manual voice selection override\n    if voice_index is not None and voices and 0 <= voice_index < len(voices):\n        eng.setProperty('voice', voices[voice_index].id)\n    elif voices:\n        # Automatic voice selection - try to find a female voice or different one\n        preferred_voices = []\n        for voice in voices:\n            voice_name = voice.name.lower()\n            # Look for female voices or specific good voices\n            if any(keyword in voice_name for keyword in ['zira', 'hazel', 'helen', 'female', 'woman']):\n                preferred_voices.append(voice)\n        \n        # If we found preferred voices, use the first one\n        if preferred_voices:\n            eng.setProperty('voice', preferred_voices[0].id)\n        # Otherwise, use the second voice if available (usually different from default)\n        elif len(voices) > 1:\n            eng.setProperty('voice', voices[1].id)\n    \n    eng.setProperty(\"rate\", 185)\n    eng.say(text)\n    eng.runAndWait()\n\ndef get_simple_notification(context: str, tool: str) -> str:\n    \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"\n    if context == \"permission_request\":\n        # Simple permission requests\n        tool_messages = {\n            \"Read\": \"Permission for Read\",\n            \"Write\": \"Permission for Write\", \n            \"Edit\": \"Permission for Edit\",\n            \"MultiEdit\": \"Permission for MultiEdit\",\n            \"Bash\": \"Permission for Bash\",\n            \"LS\": \"Permission for LS\",\n            \"Grep\": \"Permission for Grep\",\n            \"Glob\": \"Permission for Glob\",\n            \"Update\": \"Permission for Update\",\n            \"Task\": \"Permission for Task\",\n            \"Plan\": \"Permission for Plan\"\n        }\n        return tool_messages.get(tool, f\"Permission for {tool}\")\n    \n    elif context == \"tool_completion\":\n        # Simple completion messages\n        tool_messages = {\n            \"Read\": \"Read complete\",\n            \"Write\": \"Write complete\",\n            \"Edit\": \"Edit complete\", \n            \"MultiEdit\": \"MultiEdit complete\",\n            \"Bash\": \"Command complete\",\n            \"LS\": \"Directory listed\",\n            \"Grep\": \"Search complete\",\n            \"Glob\": \"Files found\",\n            \"Update\": \"Update complete\",\n            \"Task\": \"Task complete\"\n        }\n        return tool_messages.get(tool, f\"{tool} complete\")\n    \n    elif context == \"session_end\":\n        if tool and any(keyword in tool.lower() for keyword in [\"commit\", \"git\", \"file\"]):\n            return \"Session complete with changes\"\n        return \"Claude session complete\"\n    \n    elif context == \"error_notification\":\n        return \"Error occurred\"\n    \n    elif context == \"waiting\":\n        return \"Claude ready\"\n    \n    elif context == \"compact_notification\":\n        # Extract compact type from tool parameter\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting the conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting the conversation\"\n        else:\n            return \"Compacting the conversation\"\n    \n    else:\n        return \"Claude notification\"\n\ndef get_fallback_response(context: str, tool: str) -> str:\n    \"\"\"\n    Provide fallback responses when Gemini fails or returns empty\n    \"\"\"\n    if context == \"permission_request\":\n        return f\"Claude needs your confirmation for {tool}\"\n    elif context == \"tool_completion\":\n        if tool:\n            return f\"{tool} completed successfully\"\n        else:\n            return \"Tool operation completed\"\n    elif context == \"error_notification\":\n        return \"Claude encountered an error\"\n    elif context == \"completion_notification\":\n        return \"Task completed successfully\"\n    elif context == \"input_required\":\n        return \"Claude needs your input\"\n    elif context == \"status_update\":\n        return \"Claude status update\"\n    elif context == \"general_notification\":\n        return \"Claude notification received\"\n    elif context == \"waiting\":\n        return \"Claude is ready\"\n    elif context == \"session_end\":\n        if tool:  # tool parameter contains session info for Stop context\n            return f\"Claude session finished, {tool}\"\n        else:\n            return \"Claude session completed successfully\"\n    elif context == \"compact_notification\":\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting conversation\"\n        else:\n            return \"Compacting conversation\"\n    else:\n        return \"Claude notification received\"\n\ndef generate_context_prompt(context: str, tool: str, result: str) -> str:\n    \"\"\"\n    Generate simple, clear prompts that speak TO the user ABOUT Claude\n    \"\"\"\n    if context == \"permission_request\":\n        return (\n            f\"Say in 6 words or less that Claude needs your confirmation for {tool}. \"\n            f\"Speak to the user, not to Claude. Example: 'Claude needs your confirmation for {tool}' or 'Confirm {tool} permission'\"\n        )\n    elif context == \"tool_completion\":\n        # Check if result indicates error or success\n        if any(error_word in result.lower() for error_word in [\"error\", \"failed\", \"exception\", \"denied\"]):\n            return (\n                f\"Tell the user in 5 words that {tool} failed. \"\n                f\"Example: '{tool} failed' or 'Error in {tool}'\"\n            )\n        else:\n            return (\n                f\"Tell the user in 5 words that {tool} completed successfully. \"\n                f\"Example: '{tool} finished' or '{tool} completed successfully'\"\n            )\n    elif context == \"error_notification\":\n        return (\n            f\"Tell the user in 4 words that Claude encountered an error: {result[:30]}. \"\n            f\"Example: 'Claude encountered error' or 'Error occurred'\"\n        )\n    elif context == \"completion_notification\":\n        return (\n            f\"Tell the user in 4 words that a task completed: {result[:30]}. \"\n            f\"Example: 'Task completed successfully' or 'Operation finished'\"\n        )\n    elif context == \"input_required\":\n        return (\n            f\"Tell the user in 5 words that Claude needs their input. \"\n            f\"Example: 'Claude needs your input' or 'Your input required'\"\n        )\n    elif context == \"status_update\":\n        return (\n            f\"Tell the user in 4 words about Claude's status: {result[:30]}. \"\n            f\"Example: 'Claude status update' or 'Claude ready'\"\n        )\n    elif context == \"general_notification\":\n        return (\n            f\"Tell the user in 5 words about this notification: {result[:40]}. \"\n            f\"Example: 'Claude notification received' or brief summary of notification\"\n        )\n    elif context == \"waiting\":\n        return (\n            f\"Tell the user in 3 words that Claude is ready. \"\n            f\"Example: 'Claude ready' or 'Ready for input'\"\n        )\n    elif context == \"session_end\":\n        if tool and result:\n            return (\n                f\"Tell the user Claude session ended with comprehensive context: {tool}. \"\n                f\"Be smart and meaningful, under 8 words. \"\n                f\"Example: 'Claude finished, {tool}' or 'Session complete, {result}'\"\n            )\n        elif tool:\n            return (\n                f\"Tell the user Claude session ended with: {tool}. \"\n                f\"Be comprehensive but under 6 words. \"\n                f\"Example: 'Claude finished working with {tool}' or 'Session complete, used {tool}'\"\n            )\n        else:\n            return (\n                f\"Tell the user Claude session ended successfully. \"\n                f\"Be professional and brief, under 5 words. \"\n                f\"Example: 'Claude session completed' or 'Work finished successfully'\"\n            )\n    elif context == \"compact_notification\":\n        return (\n            f\"Tell the user that Claude is compacting the conversation. \"\n            f\"Type is: {tool}. Be concise, under 6 words. \"\n            f\"Example: 'Automatic compacting the conversation' or 'Manual compacting the conversation'\"\n        )\n    else:\n        return (\n            f\"Say 'Claude notification' in 2 words or less.\"\n        )\n\ndef detect_notification_context(payload: dict, transcript_path: pathlib.Path) -> tuple[str, str, str]:\n    \"\"\"\n    Detect the context of a notification and extract tool/result information\n    Returns: (context, tool, result)\n    \"\"\"\n    message = payload.get(\"message\", \"\")\n    \n    # Enhanced detection patterns for various notification types\n    \n    # 1. Permission/Confirmation requests - Multiple patterns\n    if any(pattern in message.lower() for pattern in [\n        \"needs your permission to use\",\n        \"needs permission to use\", \n        \"wants to use\",\n        \"requesting permission\",\n        \"confirm to proceed\",\n        \"confirmation required\",\n        \"needs your confirmation\",\n        \"confirm this action\",\n        \"proceed with\",\n        \"allow claude to\"\n    ]):\n        # Extract tool name from various message formats\n        tool = \"unknown tool\"\n        \n        # Try different extraction patterns\n        if \"use \" in message:\n            parts = message.split(\"use \")\n            if len(parts) > 1:\n                tool = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n        elif \"with \" in message:\n            parts = message.split(\"with \")\n            if len(parts) > 1:\n                tool = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n        elif \"to \" in message:\n            parts = message.split(\"to \")\n            if len(parts) > 1:\n                extracted = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n                # Only use if it looks like a tool name (short, no spaces)\n                if len(extracted.split()) <= 2:\n                    tool = extracted\n        \n        return \"permission_request\", tool, f\"Requesting permission for {tool}\"\n    \n    # 2. Error/Warning notifications\n    if any(pattern in message.lower() for pattern in [\n        \"error occurred\",\n        \"failed to\",\n        \"warning:\",\n        \"could not\",\n        \"unable to\",\n        \"permission denied\",\n        \"access denied\",\n        \"file not found\",\n        \"network error\"\n    ]):\n        return \"error_notification\", \"error\", f\"Error: {message[:50]}...\"\n    \n    # 3. Task completion notifications  \n    if any(pattern in message.lower() for pattern in [\n        \"task completed\",\n        \"operation finished\",\n        \"successfully completed\",\n        \"done\",\n        \"finished\",\n        \"completed successfully\"\n    ]):\n        return \"completion_notification\", \"task\", message\n    \n    # 4. User input required\n    if any(pattern in message.lower() for pattern in [\n        \"waiting for input\",\n        \"please respond\",\n        \"your input needed\",\n        \"waiting for your response\",\n        \"please provide\"\n    ]):\n        return \"input_required\", \"user_input\", \"Waiting for your input\"\n    \n    # 5. System status updates\n    if any(pattern in message.lower() for pattern in [\n        \"ready for\",\n        \"standing by\",\n        \"available\",\n        \"idle\",\n        \"waiting\"\n    ]):\n        return \"status_update\", \"system\", message\n    \n    # 6. If not a specific notification, check transcript for recent tool activity\n    tool, result = last_post_tooluse(transcript_path)\n    if tool:\n        return \"tool_completion\", tool, result\n    \n    # 7. Default case - general notification\n    if message and len(message.strip()) > 0:\n        return \"general_notification\", \"notification\", message\n    \n    # 8. Final fallback\n    return \"waiting\", \"\", \"Claude is ready\"\n\ndef last_post_tooluse(transcript: pathlib.Path) -> tuple[str, str]:\n    \"\"\"\n    Scan the transcript bottom-up and return (tool_name, summary)\n    Enhanced to provide more intelligent summaries\n    \"\"\"\n    if not transcript.exists():\n        return \"\", \"\"\n        \n    with transcript.open(\"r\", encoding=\"utf-8\") as f:\n        lines = f.readlines()\n        \n    # Look for the most recent PostToolUse event\n    for line in reversed(lines):\n        try:\n            record = json.loads(line.strip())\n        except json.JSONDecodeError:\n            continue\n            \n        if record.get(\"hook_event_name\") == \"PostToolUse\":\n            tool = record.get(\"tool_name\", \"\")\n            tool_response = record.get(\"tool_response\", {})\n            tool_input = record.get(\"tool_input\", {})\n            \n            # Generate intelligent summary based on tool type\n            summary = generate_tool_summary(tool, tool_input, tool_response)\n                \n            return tool, summary\n            \n    return \"\", \"\"\n\ndef generate_tool_summary(tool: str, tool_input: dict, tool_response: any) -> str:\n    \"\"\"\n    Generate intelligent summaries based on tool type and response\n    \"\"\"\n    if tool == \"Write\":\n        if isinstance(tool_response, dict):\n            file_path = tool_response.get(\"filePath\", tool_input.get(\"file_path\", \"\"))\n            if file_path:\n                return f\"Created/updated file: {file_path.split('/')[-1]}\"\n        return \"File operation completed\"\n    \n    elif tool == \"Edit\" or tool == \"MultiEdit\":\n        if isinstance(tool_input, dict):\n            file_path = tool_input.get(\"file_path\", \"\")\n            if file_path:\n                return f\"Modified file: {file_path.split('/')[-1]}\"\n        return \"File editing completed\"\n    \n    elif tool == \"Read\":\n        if isinstance(tool_input, dict):\n            file_path = tool_input.get(\"file_path\", \"\")\n            if file_path:\n                return f\"Read file: {file_path.split('/')[-1]}\"\n        return \"File reading completed\"\n    \n    elif tool == \"Bash\":\n        if isinstance(tool_response, dict):\n            stdout = tool_response.get(\"stdout\", \"\")\n            stderr = tool_response.get(\"stderr\", \"\")\n            exit_code = tool_response.get(\"exit_code\", 0)\n            \n            if exit_code != 0:\n                return f\"Command failed with exit code {exit_code}\"\n            elif stdout:\n                return f\"Command output: {stdout[:50]}...\"\n            else:\n                return \"Command executed successfully\"\n        return \"Command completed\"\n    \n    elif tool == \"LS\":\n        if isinstance(tool_response, str):\n            file_count = len(tool_response.strip().split('\\n')) if tool_response.strip() else 0\n            return f\"Listed {file_count} items in directory\"\n        return \"Directory listing completed\"\n    \n    elif tool == \"Grep\":\n        if isinstance(tool_response, str):\n            match_count = len(tool_response.strip().split('\\n')) if tool_response.strip() else 0\n            return f\"Found {match_count} matches\"\n        return \"Search completed\"\n    \n    else:\n        # Generic summary for unknown tools\n        if isinstance(tool_response, dict):\n            if \"error\" in str(tool_response).lower():\n                return f\"{tool} encountered an error\"\n            else:\n                return f\"{tool} completed successfully\"\n        elif isinstance(tool_response, str):\n            if tool_response and len(tool_response) > 0:\n                return f\"{tool} returned: {tool_response[:50]}...\"\n            else:\n                return f\"{tool} completed\"\n        else:\n            return f\"{tool} operation completed\"\n\ndef list_available_voices() -> None:\n    \"\"\"List all available voices on the system for user selection.\"\"\"\n    print(\"\u00f0\u0178\u017d\u00a4 Available voices on your system:\")\n    eng = pyttsx3.init()\n    voices = eng.getProperty('voices')\n    \n    if voices:\n        for i, voice in enumerate(voices):\n            print(f\"{i}: {voice.name} - {voice.id}\")\n            print(f\"   Languages: {getattr(voice, 'languages', 'Unknown')}\")\n            print(f\"   Gender: {getattr(voice, 'gender', 'Unknown')}\")\n            print()\n    else:\n        print(\"No voices found!\")\n    \n    # Test the current voice selection\n    print(\"\u00f0\u0178\u201d\u0160 Testing current voice selection...\")\n    speak(\"Hello! This is your Claude Code voice assistant.\")\n\ndef test_voice_notification() -> None:\n    \"\"\"Manual test mode - simulate different notification scenarios\"\"\"\n    print(\"Testing voice notification system...\")\n    \n    # First, show available voices\n    list_available_voices()\n    \n    # Test scenarios\n    scenarios = [\n        {\n            \"name\": \"Permission Request\",\n            \"context\": \"permission_request\",\n            \"tool\": \"Bash\",\n            \"result\": \"Requesting permission to use Bash\"\n        },\n        {\n            \"name\": \"Successful Tool Completion\",\n            \"context\": \"tool_completion\", \n            \"tool\": \"Read\",\n            \"result\": \"File contents loaded successfully\"\n        },\n        {\n            \"name\": \"Tool Error\",\n            \"context\": \"tool_completion\",\n            \"tool\": \"Write\", \n            \"result\": \"Error: Permission denied\"\n        },\n        {\n            \"name\": \"Waiting/Ready\",\n            \"context\": \"waiting\",\n            \"tool\": \"\",\n            \"result\": \"Claude is ready\"\n        },\n        {\n            \"name\": \"Automatic Compact\",\n            \"context\": \"compact_notification\",\n            \"tool\": \"automatic\",\n            \"result\": \"Starting automatic compacting\"\n        },\n        {\n            \"name\": \"Manual Compact\",\n            \"context\": \"compact_notification\",\n            \"tool\": \"manual\",\n            \"result\": \"Starting manual compacting\"\n        }\n    ]\n    \n    for i, scenario in enumerate(scenarios, 1):\n        print(f\"\\n--- Test {i}: {scenario['name']} ---\")\n        print(f\"Context: {scenario['context']}\")\n        print(f\"Tool: {scenario['tool']}\")\n        print(f\"Result: {scenario['result']}\")\n        \n        text = get_simple_notification(scenario['context'], scenario['tool'])\n        \n        print(f\"Simple notification: {text}\")\n        print(\"Speaking...\")\n        speak(text or \"Notification received.\")\n        print(\"Done.\")\n    \n    print(\"\\nAll tests complete!\")\n\ndef process_notification(payload: dict) -> None:\n    \"\"\"\n    Main notification processing function called by the hook handler.\n    Takes a payload dict and handles the voice notification logic.\n    \"\"\"\n    # Debug: Log detailed hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"unknown\"\n        }\n    }\n    \n    # Determine hook type from payload\n    if \"hook_event_name\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = payload[\"hook_event_name\"]\n    elif \"transcript_path\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = \"Notification\"\n    else:\n        debug_info[\"environment\"][\"hook_type\"] = \"Unknown/Direct\"\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Handle pure Notification events only\n    if \"transcript_path\" in payload:\n        transcript_path = pathlib.Path(payload[\"transcript_path\"])\n        notification_message = payload.get(\"message\", \"\")\n        \n        # Detect notification context\n        context, tool, result = detect_notification_context(payload, transcript_path)\n        \n        if not tool and not result:\n            speak(\"Claude is ready.\")\n            return\n    else:\n        # Unknown format - should not happen with pure Notification hooks\n        speak(\"Claude notification received.\")\n        return\n\n    # Generate simple, direct notification\n    text = get_simple_notification(context, tool)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude notification\"\n    speak(final_text)\n\ndef detect_stop_context(payload: dict) -> tuple[str, str]:\n    \"\"\"\n    Analyze Stop hook payload to extract meaningful session context.\n    Returns: (context_summary, detailed_info)\n    \"\"\"\n    # Look for git activity or recent commits\n    recent_commits = payload.get(\"recent_commits\", [])\n    files_changed = payload.get(\"files_changed\", [])\n    session_duration = payload.get(\"session_duration\", \"\")\n    tools_used = payload.get(\"tools_used\", [])\n    \n    # Build smart context summary\n    if recent_commits and len(recent_commits) > 0:\n        commit_count = len(recent_commits)\n        if commit_count == 1:\n            return f\"saved 1 commit\", f\"git activity with {commit_count} commit\"\n        else:\n            return f\"saved {commit_count} commits\", f\"git activity with {commit_count} commits\"\n    \n    elif files_changed and len(files_changed) > 0:\n        file_count = len(files_changed)\n        if file_count == 1:\n            return f\"modified 1 file\", f\"file changes: {file_count} file\"\n        else:\n            return f\"modified {file_count} files\", f\"file changes: {file_count} files\"\n    \n    elif tools_used and len(tools_used) > 0:\n        if len(tools_used) == 1:\n            return f\"used {tools_used[0]}\", f\"tools: {tools_used[0]}\"\n        elif len(tools_used) <= 3:\n            tool_list = \", \".join(tools_used)\n            return f\"used {tool_list}\", f\"tools: {tool_list}\"\n        else:\n            return f\"used {len(tools_used)} tools\", f\"tools: {len(tools_used)} different tools\"\n    \n    elif session_duration:\n        return f\"worked for {session_duration}\", f\"duration: {session_duration}\"\n    \n    else:\n        return \"completed work\", \"general session completion\"\n\ndef process_stop_notification(payload: dict) -> None:\n    \"\"\"\n    Process Stop hook events and provide smart voice feedback about session completion.\n    Uses existing utilities for consistency.\n    \"\"\"\n    # Debug: Log Stop hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"stop_hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"Stop\"\n        }\n    }\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Analyze session context for simple feedback\n    context_summary, detailed_info = detect_stop_context(payload)\n    \n    # Generate simple session end notification\n    text = get_simple_notification(\"session_end\", context_summary)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude session complete\"\n    speak(final_text)\n\ndef process_compact_notification(payload: dict) -> None:\n    \"\"\"\n    Process PreCompact hook events and provide voice feedback about compacting.\n    Uses existing utilities for consistency.\n    \"\"\"\n    # Debug: Log PreCompact hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"pre_compact_hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"PreCompact\"\n        }\n    }\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Determine if it's automatic or manual compacting\n    # Check payload for compact type indicators\n    compact_type = \"unknown\"\n    \n    # Check various payload fields that might indicate automatic vs manual\n    if \"automatic\" in str(payload).lower() or \"auto\" in str(payload).lower():\n        compact_type = \"automatic\"\n    elif \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n        compact_type = \"manual\"\n    else:\n        # Default to automatic if we can't determine\n        compact_type = \"automatic\"\n    \n    # Generate compact notification\n    text = get_simple_notification(\"compact_notification\", compact_type)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Compacting the conversation\"\n    speak(final_text)\n\nif __name__ == \"__main__\":\n    # If run directly, enter test mode\n    test_voice_notification()", "structuredPatch": [{"oldStart": 37, "oldLines": 6, "newStart": 37, "newLines": 35, "lines": ["     eng.say(text)", "     eng.runAndWait()", " ", "+def get_dynamic_notification(tool: str, summary: str) -> str:", "+    \"\"\"Generate a friendly, dynamic voice notification using an LLM.\"\"\"", "+    if not summary:", "+        return \"\" # Can't generate a notification without a summary", "+", "+    try:", "+        # We use a very specific prompt to get a short, conversational response.", "+        prompt = (", "+            f\"You are a voice assistant for a programmer. Create a very short, friendly notification \"", "+            f\"(under 12 words) for the following completed action. Be conversational. \"", "+            f\"Do not say 'task completed'.\\n\\n\"", "+            f\"Tool Used: '{tool}'\\n\"", "+            f\"Action Summary: '{summary}'\\n\\n\"", "+            f\"Example: If the summary is 'Modified file: auth.py', a good response would be \"", "+            f\"'Okay, I've just updated the auth file for you.'\\n\\n\"", "+            f\"Your notification:\"", "+        )", "+        ", "+        # Use the cost-efficient LLM utility", "+        notification_text = ask_concise(prompt)", "+        ", "+        if notification_text and \"unavailable\" not in notification_text:", "+            return notification_text", "+        return \"\"", "+    except Exception:", "+        # If the LLM call fails for any reason, return an empty string", "+        # The system will then fall back to the simple notification", "+        return \"\"", "+", " def get_simple_notification(context: str, tool: str) -> str:", "     \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"", "     if context == \"permission_request\":"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:49:46.980567", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_voice_notify.py", "new_string": "def process_notification(payload: dict) -> None:\n    \"\"\"\n    Main notification processing function called by the hook handler.\n    Takes a payload dict and handles the voice notification logic.\n    \"\"\"\n    # Debug: Log detailed hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"unknown\"\n        }\n    }\n    \n    # Determine hook type from payload\n    if \"hook_event_name\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = payload[\"hook_event_name\"]\n    elif \"transcript_path\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = \"Notification\"\n    else:\n        debug_info[\"environment\"][\"hook_type\"] = \"Unknown/Direct\"\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Handle pure Notification events only\n    if \"transcript_path\" in payload:\n        transcript_path = pathlib.Path(payload[\"transcript_path\"])\n        notification_message = payload.get(\"message\", \"\")\n        \n        # Detect notification context\n        context, tool, result_summary = detect_notification_context(payload, transcript_path)\n        \n        # If there's no specific tool context, use a simple ready message\n        if not tool and not result_summary:\n            speak(\"Claude is ready.\")\n            return\n    else:\n        # Unknown format - should not happen with pure Notification hooks\n        speak(\"Claude notification received.\")\n        return\n\n    # --- NEW DYNAMIC LOGIC ---\n    final_text = \"\"\n    # 1. Try to generate a dynamic notification first\n    if context == \"tool_completion\":\n        dynamic_text = get_dynamic_notification(tool, result_summary)\n        if dynamic_text:\n            final_text = dynamic_text\n            \n    # 2. If dynamic generation failed or isn't applicable, use the simple one\n    if not final_text:\n        final_text = get_simple_notification(context, tool)\n    \n    # 3. Final fallback to ensure we always say something\n    final_text = final_text or \"Claude notification\"\n    speak(final_text)", "old_string": "def process_notification(payload: dict) -> None:\n    \"\"\"\n    Main notification processing function called by the hook handler.\n    Takes a payload dict and handles the voice notification logic.\n    \"\"\"\n    # Debug: Log detailed hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"unknown\"\n        }\n    }\n    \n    # Determine hook type from payload\n    if \"hook_event_name\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = payload[\"hook_event_name\"]\n    elif \"transcript_path\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = \"Notification\"\n    else:\n        debug_info[\"environment\"][\"hook_type\"] = \"Unknown/Direct\"\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Handle pure Notification events only\n    if \"transcript_path\" in payload:\n        transcript_path = pathlib.Path(payload[\"transcript_path\"])\n        notification_message = payload.get(\"message\", \"\")\n        \n        # Detect notification context\n        context, tool, result = detect_notification_context(payload, transcript_path)\n        \n        if not tool and not result:\n            speak(\"Claude is ready.\")\n            return\n    else:\n        # Unknown format - should not happen with pure Notification hooks\n        speak(\"Claude notification received.\")\n        return\n\n    # Generate simple, direct notification\n    text = get_simple_notification(context, tool)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude notification\"\n    speak(final_text)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_voice_notify.py", "oldString": "def process_notification(payload: dict) -> None:\n    \"\"\"\n    Main notification processing function called by the hook handler.\n    Takes a payload dict and handles the voice notification logic.\n    \"\"\"\n    # Debug: Log detailed hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"unknown\"\n        }\n    }\n    \n    # Determine hook type from payload\n    if \"hook_event_name\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = payload[\"hook_event_name\"]\n    elif \"transcript_path\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = \"Notification\"\n    else:\n        debug_info[\"environment\"][\"hook_type\"] = \"Unknown/Direct\"\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Handle pure Notification events only\n    if \"transcript_path\" in payload:\n        transcript_path = pathlib.Path(payload[\"transcript_path\"])\n        notification_message = payload.get(\"message\", \"\")\n        \n        # Detect notification context\n        context, tool, result = detect_notification_context(payload, transcript_path)\n        \n        if not tool and not result:\n            speak(\"Claude is ready.\")\n            return\n    else:\n        # Unknown format - should not happen with pure Notification hooks\n        speak(\"Claude notification received.\")\n        return\n\n    # Generate simple, direct notification\n    text = get_simple_notification(context, tool)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude notification\"\n    speak(final_text)", "newString": "def process_notification(payload: dict) -> None:\n    \"\"\"\n    Main notification processing function called by the hook handler.\n    Takes a payload dict and handles the voice notification logic.\n    \"\"\"\n    # Debug: Log detailed hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"unknown\"\n        }\n    }\n    \n    # Determine hook type from payload\n    if \"hook_event_name\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = payload[\"hook_event_name\"]\n    elif \"transcript_path\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = \"Notification\"\n    else:\n        debug_info[\"environment\"][\"hook_type\"] = \"Unknown/Direct\"\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Handle pure Notification events only\n    if \"transcript_path\" in payload:\n        transcript_path = pathlib.Path(payload[\"transcript_path\"])\n        notification_message = payload.get(\"message\", \"\")\n        \n        # Detect notification context\n        context, tool, result_summary = detect_notification_context(payload, transcript_path)\n        \n        # If there's no specific tool context, use a simple ready message\n        if not tool and not result_summary:\n            speak(\"Claude is ready.\")\n            return\n    else:\n        # Unknown format - should not happen with pure Notification hooks\n        speak(\"Claude notification received.\")\n        return\n\n    # --- NEW DYNAMIC LOGIC ---\n    final_text = \"\"\n    # 1. Try to generate a dynamic notification first\n    if context == \"tool_completion\":\n        dynamic_text = get_dynamic_notification(tool, result_summary)\n        if dynamic_text:\n            final_text = dynamic_text\n            \n    # 2. If dynamic generation failed or isn't applicable, use the simple one\n    if not final_text:\n        final_text = get_simple_notification(context, tool)\n    \n    # 3. Final fallback to ensure we always say something\n    final_text = final_text or \"Claude notification\"\n    speak(final_text)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json, os, sys, pyttsx3, pathlib, itertools\nfrom utils.llms import ask_concise\n\ndef speak(text: str, voice_index: int = None) -> None:\n    eng = pyttsx3.init()        # Windows SAPI-5 voice\n    voices = eng.getProperty('voices')\n    \n    # Manual voice selection override\n    if voice_index is not None and voices and 0 <= voice_index < len(voices):\n        eng.setProperty('voice', voices[voice_index].id)\n    elif voices:\n        # Automatic voice selection - try to find a female voice or different one\n        preferred_voices = []\n        for voice in voices:\n            voice_name = voice.name.lower()\n            # Look for female voices or specific good voices\n            if any(keyword in voice_name for keyword in ['zira', 'hazel', 'helen', 'female', 'woman']):\n                preferred_voices.append(voice)\n        \n        # If we found preferred voices, use the first one\n        if preferred_voices:\n            eng.setProperty('voice', preferred_voices[0].id)\n        # Otherwise, use the second voice if available (usually different from default)\n        elif len(voices) > 1:\n            eng.setProperty('voice', voices[1].id)\n    \n    eng.setProperty(\"rate\", 185)\n    eng.say(text)\n    eng.runAndWait()\n\ndef get_dynamic_notification(tool: str, summary: str) -> str:\n    \"\"\"Generate a friendly, dynamic voice notification using an LLM.\"\"\"\n    if not summary:\n        return \"\" # Can't generate a notification without a summary\n\n    try:\n        # We use a very specific prompt to get a short, conversational response.\n        prompt = (\n            f\"You are a voice assistant for a programmer. Create a very short, friendly notification \"\n            f\"(under 12 words) for the following completed action. Be conversational. \"\n            f\"Do not say 'task completed'.\\n\\n\"\n            f\"Tool Used: '{tool}'\\n\"\n            f\"Action Summary: '{summary}'\\n\\n\"\n            f\"Example: If the summary is 'Modified file: auth.py', a good response would be \"\n            f\"'Okay, I've just updated the auth file for you.'\\n\\n\"\n            f\"Your notification:\"\n        )\n        \n        # Use the cost-efficient LLM utility\n        notification_text = ask_concise(prompt)\n        \n        if notification_text and \"unavailable\" not in notification_text:\n            return notification_text\n        return \"\"\n    except Exception:\n        # If the LLM call fails for any reason, return an empty string\n        # The system will then fall back to the simple notification\n        return \"\"\n\ndef get_simple_notification(context: str, tool: str) -> str:\n    \"\"\"Generate simple, direct voice notifications for each tool.\"\"\"\n    if context == \"permission_request\":\n        # Simple permission requests\n        tool_messages = {\n            \"Read\": \"Permission for Read\",\n            \"Write\": \"Permission for Write\", \n            \"Edit\": \"Permission for Edit\",\n            \"MultiEdit\": \"Permission for MultiEdit\",\n            \"Bash\": \"Permission for Bash\",\n            \"LS\": \"Permission for LS\",\n            \"Grep\": \"Permission for Grep\",\n            \"Glob\": \"Permission for Glob\",\n            \"Update\": \"Permission for Update\",\n            \"Task\": \"Permission for Task\",\n            \"Plan\": \"Permission for Plan\"\n        }\n        return tool_messages.get(tool, f\"Permission for {tool}\")\n    \n    elif context == \"tool_completion\":\n        # Simple completion messages\n        tool_messages = {\n            \"Read\": \"Read complete\",\n            \"Write\": \"Write complete\",\n            \"Edit\": \"Edit complete\", \n            \"MultiEdit\": \"MultiEdit complete\",\n            \"Bash\": \"Command complete\",\n            \"LS\": \"Directory listed\",\n            \"Grep\": \"Search complete\",\n            \"Glob\": \"Files found\",\n            \"Update\": \"Update complete\",\n            \"Task\": \"Task complete\"\n        }\n        return tool_messages.get(tool, f\"{tool} complete\")\n    \n    elif context == \"session_end\":\n        if tool and any(keyword in tool.lower() for keyword in [\"commit\", \"git\", \"file\"]):\n            return \"Session complete with changes\"\n        return \"Claude session complete\"\n    \n    elif context == \"error_notification\":\n        return \"Error occurred\"\n    \n    elif context == \"waiting\":\n        return \"Claude ready\"\n    \n    elif context == \"compact_notification\":\n        # Extract compact type from tool parameter\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting the conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting the conversation\"\n        else:\n            return \"Compacting the conversation\"\n    \n    else:\n        return \"Claude notification\"\n\ndef get_fallback_response(context: str, tool: str) -> str:\n    \"\"\"\n    Provide fallback responses when Gemini fails or returns empty\n    \"\"\"\n    if context == \"permission_request\":\n        return f\"Claude needs your confirmation for {tool}\"\n    elif context == \"tool_completion\":\n        if tool:\n            return f\"{tool} completed successfully\"\n        else:\n            return \"Tool operation completed\"\n    elif context == \"error_notification\":\n        return \"Claude encountered an error\"\n    elif context == \"completion_notification\":\n        return \"Task completed successfully\"\n    elif context == \"input_required\":\n        return \"Claude needs your input\"\n    elif context == \"status_update\":\n        return \"Claude status update\"\n    elif context == \"general_notification\":\n        return \"Claude notification received\"\n    elif context == \"waiting\":\n        return \"Claude is ready\"\n    elif context == \"session_end\":\n        if tool:  # tool parameter contains session info for Stop context\n            return f\"Claude session finished, {tool}\"\n        else:\n            return \"Claude session completed successfully\"\n    elif context == \"compact_notification\":\n        if \"automatic\" in tool.lower():\n            return \"Automatic compacting conversation\"\n        elif \"manual\" in tool.lower():\n            return \"Manual compacting conversation\"\n        else:\n            return \"Compacting conversation\"\n    else:\n        return \"Claude notification received\"\n\ndef generate_context_prompt(context: str, tool: str, result: str) -> str:\n    \"\"\"\n    Generate simple, clear prompts that speak TO the user ABOUT Claude\n    \"\"\"\n    if context == \"permission_request\":\n        return (\n            f\"Say in 6 words or less that Claude needs your confirmation for {tool}. \"\n            f\"Speak to the user, not to Claude. Example: 'Claude needs your confirmation for {tool}' or 'Confirm {tool} permission'\"\n        )\n    elif context == \"tool_completion\":\n        # Check if result indicates error or success\n        if any(error_word in result.lower() for error_word in [\"error\", \"failed\", \"exception\", \"denied\"]):\n            return (\n                f\"Tell the user in 5 words that {tool} failed. \"\n                f\"Example: '{tool} failed' or 'Error in {tool}'\"\n            )\n        else:\n            return (\n                f\"Tell the user in 5 words that {tool} completed successfully. \"\n                f\"Example: '{tool} finished' or '{tool} completed successfully'\"\n            )\n    elif context == \"error_notification\":\n        return (\n            f\"Tell the user in 4 words that Claude encountered an error: {result[:30]}. \"\n            f\"Example: 'Claude encountered error' or 'Error occurred'\"\n        )\n    elif context == \"completion_notification\":\n        return (\n            f\"Tell the user in 4 words that a task completed: {result[:30]}. \"\n            f\"Example: 'Task completed successfully' or 'Operation finished'\"\n        )\n    elif context == \"input_required\":\n        return (\n            f\"Tell the user in 5 words that Claude needs their input. \"\n            f\"Example: 'Claude needs your input' or 'Your input required'\"\n        )\n    elif context == \"status_update\":\n        return (\n            f\"Tell the user in 4 words about Claude's status: {result[:30]}. \"\n            f\"Example: 'Claude status update' or 'Claude ready'\"\n        )\n    elif context == \"general_notification\":\n        return (\n            f\"Tell the user in 5 words about this notification: {result[:40]}. \"\n            f\"Example: 'Claude notification received' or brief summary of notification\"\n        )\n    elif context == \"waiting\":\n        return (\n            f\"Tell the user in 3 words that Claude is ready. \"\n            f\"Example: 'Claude ready' or 'Ready for input'\"\n        )\n    elif context == \"session_end\":\n        if tool and result:\n            return (\n                f\"Tell the user Claude session ended with comprehensive context: {tool}. \"\n                f\"Be smart and meaningful, under 8 words. \"\n                f\"Example: 'Claude finished, {tool}' or 'Session complete, {result}'\"\n            )\n        elif tool:\n            return (\n                f\"Tell the user Claude session ended with: {tool}. \"\n                f\"Be comprehensive but under 6 words. \"\n                f\"Example: 'Claude finished working with {tool}' or 'Session complete, used {tool}'\"\n            )\n        else:\n            return (\n                f\"Tell the user Claude session ended successfully. \"\n                f\"Be professional and brief, under 5 words. \"\n                f\"Example: 'Claude session completed' or 'Work finished successfully'\"\n            )\n    elif context == \"compact_notification\":\n        return (\n            f\"Tell the user that Claude is compacting the conversation. \"\n            f\"Type is: {tool}. Be concise, under 6 words. \"\n            f\"Example: 'Automatic compacting the conversation' or 'Manual compacting the conversation'\"\n        )\n    else:\n        return (\n            f\"Say 'Claude notification' in 2 words or less.\"\n        )\n\ndef detect_notification_context(payload: dict, transcript_path: pathlib.Path) -> tuple[str, str, str]:\n    \"\"\"\n    Detect the context of a notification and extract tool/result information\n    Returns: (context, tool, result)\n    \"\"\"\n    message = payload.get(\"message\", \"\")\n    \n    # Enhanced detection patterns for various notification types\n    \n    # 1. Permission/Confirmation requests - Multiple patterns\n    if any(pattern in message.lower() for pattern in [\n        \"needs your permission to use\",\n        \"needs permission to use\", \n        \"wants to use\",\n        \"requesting permission\",\n        \"confirm to proceed\",\n        \"confirmation required\",\n        \"needs your confirmation\",\n        \"confirm this action\",\n        \"proceed with\",\n        \"allow claude to\"\n    ]):\n        # Extract tool name from various message formats\n        tool = \"unknown tool\"\n        \n        # Try different extraction patterns\n        if \"use \" in message:\n            parts = message.split(\"use \")\n            if len(parts) > 1:\n                tool = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n        elif \"with \" in message:\n            parts = message.split(\"with \")\n            if len(parts) > 1:\n                tool = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n        elif \"to \" in message:\n            parts = message.split(\"to \")\n            if len(parts) > 1:\n                extracted = parts[-1].strip().rstrip(\"?\").rstrip(\".\")\n                # Only use if it looks like a tool name (short, no spaces)\n                if len(extracted.split()) <= 2:\n                    tool = extracted\n        \n        return \"permission_request\", tool, f\"Requesting permission for {tool}\"\n    \n    # 2. Error/Warning notifications\n    if any(pattern in message.lower() for pattern in [\n        \"error occurred\",\n        \"failed to\",\n        \"warning:\",\n        \"could not\",\n        \"unable to\",\n        \"permission denied\",\n        \"access denied\",\n        \"file not found\",\n        \"network error\"\n    ]):\n        return \"error_notification\", \"error\", f\"Error: {message[:50]}...\"\n    \n    # 3. Task completion notifications  \n    if any(pattern in message.lower() for pattern in [\n        \"task completed\",\n        \"operation finished\",\n        \"successfully completed\",\n        \"done\",\n        \"finished\",\n        \"completed successfully\"\n    ]):\n        return \"completion_notification\", \"task\", message\n    \n    # 4. User input required\n    if any(pattern in message.lower() for pattern in [\n        \"waiting for input\",\n        \"please respond\",\n        \"your input needed\",\n        \"waiting for your response\",\n        \"please provide\"\n    ]):\n        return \"input_required\", \"user_input\", \"Waiting for your input\"\n    \n    # 5. System status updates\n    if any(pattern in message.lower() for pattern in [\n        \"ready for\",\n        \"standing by\",\n        \"available\",\n        \"idle\",\n        \"waiting\"\n    ]):\n        return \"status_update\", \"system\", message\n    \n    # 6. If not a specific notification, check transcript for recent tool activity\n    tool, result = last_post_tooluse(transcript_path)\n    if tool:\n        return \"tool_completion\", tool, result\n    \n    # 7. Default case - general notification\n    if message and len(message.strip()) > 0:\n        return \"general_notification\", \"notification\", message\n    \n    # 8. Final fallback\n    return \"waiting\", \"\", \"Claude is ready\"\n\ndef last_post_tooluse(transcript: pathlib.Path) -> tuple[str, str]:\n    \"\"\"\n    Scan the transcript bottom-up and return (tool_name, summary)\n    Enhanced to provide more intelligent summaries\n    \"\"\"\n    if not transcript.exists():\n        return \"\", \"\"\n        \n    with transcript.open(\"r\", encoding=\"utf-8\") as f:\n        lines = f.readlines()\n        \n    # Look for the most recent PostToolUse event\n    for line in reversed(lines):\n        try:\n            record = json.loads(line.strip())\n        except json.JSONDecodeError:\n            continue\n            \n        if record.get(\"hook_event_name\") == \"PostToolUse\":\n            tool = record.get(\"tool_name\", \"\")\n            tool_response = record.get(\"tool_response\", {})\n            tool_input = record.get(\"tool_input\", {})\n            \n            # Generate intelligent summary based on tool type\n            summary = generate_tool_summary(tool, tool_input, tool_response)\n                \n            return tool, summary\n            \n    return \"\", \"\"\n\ndef generate_tool_summary(tool: str, tool_input: dict, tool_response: any) -> str:\n    \"\"\"\n    Generate intelligent summaries based on tool type and response\n    \"\"\"\n    if tool == \"Write\":\n        if isinstance(tool_response, dict):\n            file_path = tool_response.get(\"filePath\", tool_input.get(\"file_path\", \"\"))\n            if file_path:\n                return f\"Created/updated file: {file_path.split('/')[-1]}\"\n        return \"File operation completed\"\n    \n    elif tool == \"Edit\" or tool == \"MultiEdit\":\n        if isinstance(tool_input, dict):\n            file_path = tool_input.get(\"file_path\", \"\")\n            if file_path:\n                return f\"Modified file: {file_path.split('/')[-1]}\"\n        return \"File editing completed\"\n    \n    elif tool == \"Read\":\n        if isinstance(tool_input, dict):\n            file_path = tool_input.get(\"file_path\", \"\")\n            if file_path:\n                return f\"Read file: {file_path.split('/')[-1]}\"\n        return \"File reading completed\"\n    \n    elif tool == \"Bash\":\n        if isinstance(tool_response, dict):\n            stdout = tool_response.get(\"stdout\", \"\")\n            stderr = tool_response.get(\"stderr\", \"\")\n            exit_code = tool_response.get(\"exit_code\", 0)\n            \n            if exit_code != 0:\n                return f\"Command failed with exit code {exit_code}\"\n            elif stdout:\n                return f\"Command output: {stdout[:50]}...\"\n            else:\n                return \"Command executed successfully\"\n        return \"Command completed\"\n    \n    elif tool == \"LS\":\n        if isinstance(tool_response, str):\n            file_count = len(tool_response.strip().split('\\n')) if tool_response.strip() else 0\n            return f\"Listed {file_count} items in directory\"\n        return \"Directory listing completed\"\n    \n    elif tool == \"Grep\":\n        if isinstance(tool_response, str):\n            match_count = len(tool_response.strip().split('\\n')) if tool_response.strip() else 0\n            return f\"Found {match_count} matches\"\n        return \"Search completed\"\n    \n    else:\n        # Generic summary for unknown tools\n        if isinstance(tool_response, dict):\n            if \"error\" in str(tool_response).lower():\n                return f\"{tool} encountered an error\"\n            else:\n                return f\"{tool} completed successfully\"\n        elif isinstance(tool_response, str):\n            if tool_response and len(tool_response) > 0:\n                return f\"{tool} returned: {tool_response[:50]}...\"\n            else:\n                return f\"{tool} completed\"\n        else:\n            return f\"{tool} operation completed\"\n\ndef list_available_voices() -> None:\n    \"\"\"List all available voices on the system for user selection.\"\"\"\n    print(\"\u00f0\u0178\u017d\u00a4 Available voices on your system:\")\n    eng = pyttsx3.init()\n    voices = eng.getProperty('voices')\n    \n    if voices:\n        for i, voice in enumerate(voices):\n            print(f\"{i}: {voice.name} - {voice.id}\")\n            print(f\"   Languages: {getattr(voice, 'languages', 'Unknown')}\")\n            print(f\"   Gender: {getattr(voice, 'gender', 'Unknown')}\")\n            print()\n    else:\n        print(\"No voices found!\")\n    \n    # Test the current voice selection\n    print(\"\u00f0\u0178\u201d\u0160 Testing current voice selection...\")\n    speak(\"Hello! This is your Claude Code voice assistant.\")\n\ndef test_voice_notification() -> None:\n    \"\"\"Manual test mode - simulate different notification scenarios\"\"\"\n    print(\"Testing voice notification system...\")\n    \n    # First, show available voices\n    list_available_voices()\n    \n    # Test scenarios\n    scenarios = [\n        {\n            \"name\": \"Permission Request\",\n            \"context\": \"permission_request\",\n            \"tool\": \"Bash\",\n            \"result\": \"Requesting permission to use Bash\"\n        },\n        {\n            \"name\": \"Successful Tool Completion\",\n            \"context\": \"tool_completion\", \n            \"tool\": \"Read\",\n            \"result\": \"File contents loaded successfully\"\n        },\n        {\n            \"name\": \"Tool Error\",\n            \"context\": \"tool_completion\",\n            \"tool\": \"Write\", \n            \"result\": \"Error: Permission denied\"\n        },\n        {\n            \"name\": \"Waiting/Ready\",\n            \"context\": \"waiting\",\n            \"tool\": \"\",\n            \"result\": \"Claude is ready\"\n        },\n        {\n            \"name\": \"Automatic Compact\",\n            \"context\": \"compact_notification\",\n            \"tool\": \"automatic\",\n            \"result\": \"Starting automatic compacting\"\n        },\n        {\n            \"name\": \"Manual Compact\",\n            \"context\": \"compact_notification\",\n            \"tool\": \"manual\",\n            \"result\": \"Starting manual compacting\"\n        }\n    ]\n    \n    for i, scenario in enumerate(scenarios, 1):\n        print(f\"\\n--- Test {i}: {scenario['name']} ---\")\n        print(f\"Context: {scenario['context']}\")\n        print(f\"Tool: {scenario['tool']}\")\n        print(f\"Result: {scenario['result']}\")\n        \n        text = get_simple_notification(scenario['context'], scenario['tool'])\n        \n        print(f\"Simple notification: {text}\")\n        print(\"Speaking...\")\n        speak(text or \"Notification received.\")\n        print(\"Done.\")\n    \n    print(\"\\nAll tests complete!\")\n\ndef process_notification(payload: dict) -> None:\n    \"\"\"\n    Main notification processing function called by the hook handler.\n    Takes a payload dict and handles the voice notification logic.\n    \"\"\"\n    # Debug: Log detailed hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"unknown\"\n        }\n    }\n    \n    # Determine hook type from payload\n    if \"hook_event_name\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = payload[\"hook_event_name\"]\n    elif \"transcript_path\" in payload:\n        debug_info[\"environment\"][\"hook_type\"] = \"Notification\"\n    else:\n        debug_info[\"environment\"][\"hook_type\"] = \"Unknown/Direct\"\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Handle pure Notification events only\n    if \"transcript_path\" in payload:\n        transcript_path = pathlib.Path(payload[\"transcript_path\"])\n        notification_message = payload.get(\"message\", \"\")\n        \n        # Detect notification context\n        context, tool, result = detect_notification_context(payload, transcript_path)\n        \n        if not tool and not result:\n            speak(\"Claude is ready.\")\n            return\n    else:\n        # Unknown format - should not happen with pure Notification hooks\n        speak(\"Claude notification received.\")\n        return\n\n    # Generate simple, direct notification\n    text = get_simple_notification(context, tool)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude notification\"\n    speak(final_text)\n\ndef detect_stop_context(payload: dict) -> tuple[str, str]:\n    \"\"\"\n    Analyze Stop hook payload to extract meaningful session context.\n    Returns: (context_summary, detailed_info)\n    \"\"\"\n    # Look for git activity or recent commits\n    recent_commits = payload.get(\"recent_commits\", [])\n    files_changed = payload.get(\"files_changed\", [])\n    session_duration = payload.get(\"session_duration\", \"\")\n    tools_used = payload.get(\"tools_used\", [])\n    \n    # Build smart context summary\n    if recent_commits and len(recent_commits) > 0:\n        commit_count = len(recent_commits)\n        if commit_count == 1:\n            return f\"saved 1 commit\", f\"git activity with {commit_count} commit\"\n        else:\n            return f\"saved {commit_count} commits\", f\"git activity with {commit_count} commits\"\n    \n    elif files_changed and len(files_changed) > 0:\n        file_count = len(files_changed)\n        if file_count == 1:\n            return f\"modified 1 file\", f\"file changes: {file_count} file\"\n        else:\n            return f\"modified {file_count} files\", f\"file changes: {file_count} files\"\n    \n    elif tools_used and len(tools_used) > 0:\n        if len(tools_used) == 1:\n            return f\"used {tools_used[0]}\", f\"tools: {tools_used[0]}\"\n        elif len(tools_used) <= 3:\n            tool_list = \", \".join(tools_used)\n            return f\"used {tool_list}\", f\"tools: {tool_list}\"\n        else:\n            return f\"used {len(tools_used)} tools\", f\"tools: {len(tools_used)} different tools\"\n    \n    elif session_duration:\n        return f\"worked for {session_duration}\", f\"duration: {session_duration}\"\n    \n    else:\n        return \"completed work\", \"general session completion\"\n\ndef process_stop_notification(payload: dict) -> None:\n    \"\"\"\n    Process Stop hook events and provide smart voice feedback about session completion.\n    Uses existing utilities for consistency.\n    \"\"\"\n    # Debug: Log Stop hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"stop_hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"Stop\"\n        }\n    }\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Analyze session context for simple feedback\n    context_summary, detailed_info = detect_stop_context(payload)\n    \n    # Generate simple session end notification\n    text = get_simple_notification(\"session_end\", context_summary)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Claude session complete\"\n    speak(final_text)\n\ndef process_compact_notification(payload: dict) -> None:\n    \"\"\"\n    Process PreCompact hook events and provide voice feedback about compacting.\n    Uses existing utilities for consistency.\n    \"\"\"\n    # Debug: Log PreCompact hook information\n    import datetime\n    debug_info = {\n        \"timestamp\": datetime.datetime.now().isoformat(),\n        \"event\": \"pre_compact_hook_triggered\",\n        \"payload\": payload,\n        \"environment\": {\n            \"cwd\": str(pathlib.Path.cwd()),\n            \"hook_type\": \"PreCompact\"\n        }\n    }\n    \n    # Write debug log\n    with open(\"C:/Users/NATH/.claude/hooks/debug.log\", \"a\", encoding=\"utf-8\") as f:\n        f.write(f\"{json.dumps(debug_info, indent=2)}\\n\")\n        f.write(\"=\"*80 + \"\\n\")\n    \n    # Determine if it's automatic or manual compacting\n    # Check payload for compact type indicators\n    compact_type = \"unknown\"\n    \n    # Check various payload fields that might indicate automatic vs manual\n    if \"automatic\" in str(payload).lower() or \"auto\" in str(payload).lower():\n        compact_type = \"automatic\"\n    elif \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n        compact_type = \"manual\"\n    else:\n        # Default to automatic if we can't determine\n        compact_type = \"automatic\"\n    \n    # Generate compact notification\n    text = get_simple_notification(\"compact_notification\", compact_type)\n    \n    # Ensure we always have something to say\n    final_text = text or \"Compacting the conversation\"\n    speak(final_text)\n\nif __name__ == \"__main__\":\n    # If run directly, enter test mode\n    test_voice_notification()", "structuredPatch": [{"oldStart": 557, "oldLines": 9, "newStart": 557, "newLines": 10, "lines": ["         notification_message = payload.get(\"message\", \"\")", "         ", "         # Detect notification context", "-        context, tool, result = detect_notification_context(payload, transcript_path)", "+        context, tool, result_summary = detect_notification_context(payload, transcript_path)", "         ", "-        if not tool and not result:", "+        # If there's no specific tool context, use a simple ready message", "+        if not tool and not result_summary:", "             speak(\"Claude is ready.\")", "             return", "     else:"]}, {"oldStart": 567, "oldLines": 11, "newStart": 568, "newLines": 20, "lines": ["         speak(\"Claude notification received.\")", "         return", " ", "-    # Generate simple, direct notification", "-    text = get_simple_notification(context, tool)", "+    # --- NEW DYNAMIC LOGIC ---", "+    final_text = \"\"", "+    # 1. Try to generate a dynamic notification first", "+    if context == \"tool_completion\":", "+        dynamic_text = get_dynamic_notification(tool, result_summary)", "+        if dynamic_text:", "+            final_text = dynamic_text", "+            ", "+    # 2. If dynamic generation failed or isn't applicable, use the simple one", "+    if not final_text:", "+        final_text = get_simple_notification(context, tool)", "     ", "-    # Ensure we always have something to say", "-    final_text = text or \"Claude notification\"", "+    # 3. Final fallback to ensure we always say something", "+    final_text = final_text or \"Claude notification\"", "     speak(final_text)", " ", " def detect_stop_context(payload: dict) -> tuple[str, str]:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:50:43.473618", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:250] # Increased length slightly\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        change_description = self._classify_file_operation(tool_input)\n            \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        \n        # Build a more robust prompt that emphasizes user intent\n        prompt = f\"\"\"Generate a git commit message in the conventional commit format.\nYour primary goal is to reflect the user's original request.\n\n**User's Goal:**\n{user_intent}\n\n**Session Context:**\n- **File(s) Changed:** {', '.join(files_changed)}\n- **Primary Change Type:** {change_description} on {primary_file.get('file', 'unknown')}\n- **Recent Activity:** {session_activity}\n\n**Instructions:**\n1.  **Prioritize the User's Goal.** The commit message must align with their request.\n2.  **Format:** `type(scope): description`\n3.  **Be Concise:** Under 50 characters.\n4.  **Use Present Tense.**\n5.  **Types:** feat, fix, refactor, docs, style, test, chore.\n\nBased on the user's goal, generate ONLY the single-line commit message:\"\"\"\n        \n        return prompt", "old_string": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt", "newString": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:250] # Increased length slightly\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        change_description = self._classify_file_operation(tool_input)\n            \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        \n        # Build a more robust prompt that emphasizes user intent\n        prompt = f\"\"\"Generate a git commit message in the conventional commit format.\nYour primary goal is to reflect the user's original request.\n\n**User's Goal:**\n{user_intent}\n\n**Session Context:**\n- **File(s) Changed:** {', '.join(files_changed)}\n- **Primary Change Type:** {change_description} on {primary_file.get('file', 'unknown')}\n- **Recent Activity:** {session_activity}\n\n**Instructions:**\n1.  **Prioritize the User's Goal.** The commit message must align with their request.\n2.  **Format:** `type(scope): description`\n3.  **Be Concise:** Under 50 characters.\n4.  **Use Present Tense.**\n5.  **Types:** feat, fix, refactor, docs, style, test, chore.\n\nBased on the user's goal, generate ONLY the single-line commit message:\"\"\"\n        \n        return prompt", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:\n        \"\"\"\n        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.\n        \n        Args:\n            session_id: Session identifier\n            stop_payload: Stop hook payload with session information\n        \"\"\"\n        try:\n            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")\n            \n            # Load all tool usage from the entire session\n            tool_history = self._load_tool_usage_history(session_id)\n            \n            # Check if there were any meaningful file operations\n            file_operations = tool_history.get(\"file_operations\", [])\n            if not file_operations:\n                self._log_debug(\"No file operations found, skipping checkpoint\")\n                return\n                \n            # Analyze git repository state\n            git_context = self._analyze_git_changes()\n            if not git_context.get(\"files\"):\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return\n                \n            # Build session context\n            session_context = {\n                \"session_id\": session_id,\n                \"total_operations\": len(file_operations),\n                \"file_count\": len(git_context.get(\"files\", [])),\n                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")\n            }\n            \n            # Generate commit for entire session (with unlimited time!)\n            commit_message = self._generate_session_commit(session_context, git_context, tool_history)\n            \n            # Create the commit\n            if self._create_commit(commit_message):\n                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")\n            else:\n                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")\n                \n        except Exception as e:\n            self._log_debug(f\"Session checkpoint error: {e}\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _generate_session_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate commit message for entire session - much simpler and more reliable.\n        Since this runs in Stop hook, we have unlimited time for LLM calls.\n        \"\"\"\n        try:\n            # Build session-level prompt\n            file_operations = tool_history.get(\"file_operations\", [])\n            total_ops = session_context.get(\"total_operations\", 0)\n            file_count = session_context.get(\"file_count\", 0)\n            \n            # Create simple but effective prompt\n            session_prompt = f\"\"\"Generate a git commit message for this session.\n\nSESSION SUMMARY:\n- Total operations: {total_ops}\n- Files changed: {file_count}\n- Activity: {tool_history.get('session_summary', 'code changes')}\n\nFILES CHANGED:\n{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nFORMAT: type(scope): description\nEXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure\n\nCOMMIT MESSAGE:\"\"\"\n\n            # Since we're in Stop hook, we can take time for LLM\n            self._log_debug(\"\u00f0\u0178\u0161\u20ac Session commit generation (unlimited time)\")\n            \n            # Try simple pattern matching first (instant)\n            pattern_commit = self._generate_pattern_commit(session_context, git_context, tool_history)\n            if pattern_commit and pattern_commit != \"chore: update files\":\n                self._log_debug(f\"\u00e2\u0153\u2026 Using pattern-based commit: {pattern_commit}\")\n                return pattern_commit\n            \n            # If pattern matching fails, use LLM (with time to complete)\n            self._log_debug(\"\u00f0\u0178\u201c\udc9d Trying LLM generation for session commit\")\n            llm_commit = self._call_claude_task(session_prompt)\n            if llm_commit and \":\" in llm_commit and len(llm_commit) > 10:\n                cleaned = self._clean_commit_message(llm_commit)\n                self._log_debug(f\"\u00e2\u0153\u2026 LLM generated session commit: {cleaned}\")\n                return cleaned\n            \n            # Final fallback\n            return self._create_session_fallback_commit(session_context, git_context)\n            \n        except Exception as e:\n            self._log_debug(f\"Session commit generation error: {e}\")\n            return self._create_session_fallback_commit(session_context, git_context)\n    \n    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        \n        if not file_operations:\n            return \"chore: session updates\"\n            \n        # Count operation types\n        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")\n        \n        # Analyze file types\n        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]\n        \n        # Smart pattern matching\n        if len(files_changed) == 1:\n            file_name = files_changed[0].get(\"file\", \"\")\n            if \"test\" in file_name.lower():\n                return \"test: update test files\"\n            elif \"config\" in file_name.lower():\n                return \"chore(config): update settings\"\n            elif file_name.endswith(\".py\"):\n                return \"refactor: update Python code\"\n            elif file_name.endswith((\".js\", \".ts\")):\n                return \"refactor: update JavaScript code\"\n            else:\n                return f\"chore: update {file_name}\"\n        \n        elif len(py_files) > 0 and len(js_files) == 0:\n            return f\"refactor: update {len(py_files)} Python files\"\n        elif len(js_files) > 0 and len(py_files) == 0:\n            return f\"refactor: update {len(js_files)} JavaScript files\"\n        elif len(config_files) > 0:\n            return \"chore(config): update configuration\"\n        else:\n            return f\"chore: update {len(files_changed)} files\"\n    \n    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 601, "oldLines": 57, "newStart": 601, "newLines": 38, "lines": ["         \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"", "         ", "         # Extract detailed context", "-        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]", "+        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:250] # Increased length slightly", "         tool_name = tool_context.get(\"tool_name\", \"unknown\")", "         files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]", "         primary_file = git_context.get(\"primary_file\", {})", "         ", "         # Get file content context from tool_input", "         tool_input = tool_context.get(\"tool_input\", {})", "-        file_path = tool_input.get(\"file_path\", \"\")", "-        old_string = tool_input.get(\"old_string\", \"\")[:100]", "-        new_string = tool_input.get(\"new_string\", \"\")[:100]", "-        ", "-        # Extract specific changes", "-        change_description = \"\"", "-        if old_string and new_string:", "-            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"", "-        ", "+        change_description = self._classify_file_operation(tool_input)", "+            ", "         # Extract tool history context", "         session_activity = tool_history.get(\"session_summary\", \"unknown activity\")", "-        total_ops = tool_history.get(\"total_operations\", 0)", "-        file_ops = tool_history.get(\"file_operations\", [])", "         ", "-        # Build tool history summary", "-        tool_context_summary = \"\"", "-        if file_ops:", "-            recent_file_ops = file_ops[-3:]  # Last 3 file operations", "-            ops_summary = []", "-            for op in recent_file_ops:", "-                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")", "-            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"", "-        ", "-        prompt = f\"\"\"Generate a git commit message using conventional commit format.", "+        # Build a more robust prompt that emphasizes user intent", "+        prompt = f\"\"\"Generate a git commit message in the conventional commit format.", "+Your primary goal is to reflect the user's original request.", " ", "-Context:", "-- User request: {user_intent}", "-- File: {primary_file.get('file', 'unknown')}", "-- Operation: {tool_name}", "-- Session activity: {session_activity}", "-- Change: {change_description}", "+**User's Goal:**", "+{user_intent}", " ", "-Rules:", "-- Format: type(scope): description", "-- Under 50 characters", "-- Present tense", "-- Types: feat, fix, refactor, docs, style, test, chore", "+**Session Context:**", "+- **File(s) Changed:** {', '.join(files_changed)}", "+- **Primary Change Type:** {change_description} on {primary_file.get('file', 'unknown')}", "+- **Recent Activity:** {session_activity}", " ", "-Examples:", "-- feat(auth): add login validation", "-- fix(parser): handle null values", "-- refactor(ui): extract components", "+**Instructions:**", "+1.  **Prioritize the User's Goal.** The commit message must align with their request.", "+2.  **Format:** `type(scope): description`", "+3.  **Be Concise:** Under 50 characters.", "+4.  **Use Present Tense.**", "+5.  **Types:** feat, fix, refactor, docs, style, test, chore.", " ", "-Generate ONLY the commit message:\"\"\"", "+Based on the user's goal, generate ONLY the single-line commit message:\"\"\"", "         ", "         return prompt", "     "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:51:45.300250", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Write", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\subagent_stop.py", "content": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport re\nimport datetime\n\ndef main() -> None:\n    \"\"\"\n    SubagentStop hook to automatically chain tasks.\n    If a new function is written, it prompts Claude to write a unit test.\n    \"\"\"\n    try:\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError:\n        # If there's no payload, there's nothing to do.\n        print(json.dumps({\"decision\": \"approve\"}))\n        sys.exit(0)\n\n    decision = {\"decision\": \"approve\"}\n    \n    try:\n        tool_name = payload.get(\"tool_name\")\n        tool_input = payload.get(\"tool_input\", {})\n        \n        # We only care about successful Write/Edit operations\n        if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n            # Check if the tool output indicates success\n            tool_response = payload.get(\"tool_response\", {})\n            success = tool_response.get(\"success\", False)\n            if isinstance(tool_response, dict) and \"filePath\" in tool_response:\n                success = True\n\n            if success:\n                # Get the content that was written or added\n                content_added = \"\"\n                if \"content\" in tool_input: # From Write tool\n                    content_added = tool_input[\"content\"]\n                elif \"new_string\" in tool_input: # From Edit tool\n                    content_added = tool_input[\"new_string\"]\n\n                # Check if the added content looks like a new function or class\n                # This is a simple but effective check for Python and JavaScript/TypeScript\n                if re.search(r'^\\s*(def|class|function|const|let|var)\\s+\\w+', content_added, re.MULTILINE):\n                    log_debug(f\"Detected new function/class in {tool_name} operation. Prompting for tests.\")\n                    decision = {\n                        \"decision\": \"block\",\n                        \"reason\": \"You have successfully added a new function or class. As the next logical step, please write a comprehensive unit test for the code you just added.\"\n                    }\n    except Exception as e:\n        log_debug(f\"Error in subagent_stop.py: {e}\")\n        # Fail open to not interrupt the user's workflow\n        decision = {\"decision\": \"approve\"}\n\n    # Log the decision and output it to Claude\n    log_debug(f\"SubagentStop decision: {decision['decision']}\")\n    print(json.dumps(decision))\n    sys.exit(0)\n\ndef log_debug(message: str) -> None:\n    \"\"\"Logs a debug message to the central debug log.\"\"\"\n    try:\n        debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        timestamp = datetime.datetime.now().isoformat()\n        with open(debug_log, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"[{timestamp}] SUBAGENT_STOP: {message}\\n\")\n    except Exception:\n        pass # Silently fail if logging doesn't work\n\nif __name__ == \"__main__\":\n    main()"}, "tool_response": {"type": "create", "filePath": "C:\\Users\\NATH\\.claude\\hooks\\subagent_stop.py", "content": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport re\nimport datetime\n\ndef main() -> None:\n    \"\"\"\n    SubagentStop hook to automatically chain tasks.\n    If a new function is written, it prompts Claude to write a unit test.\n    \"\"\"\n    try:\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError:\n        # If there's no payload, there's nothing to do.\n        print(json.dumps({\"decision\": \"approve\"}))\n        sys.exit(0)\n\n    decision = {\"decision\": \"approve\"}\n    \n    try:\n        tool_name = payload.get(\"tool_name\")\n        tool_input = payload.get(\"tool_input\", {})\n        \n        # We only care about successful Write/Edit operations\n        if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n            # Check if the tool output indicates success\n            tool_response = payload.get(\"tool_response\", {})\n            success = tool_response.get(\"success\", False)\n            if isinstance(tool_response, dict) and \"filePath\" in tool_response:\n                success = True\n\n            if success:\n                # Get the content that was written or added\n                content_added = \"\"\n                if \"content\" in tool_input: # From Write tool\n                    content_added = tool_input[\"content\"]\n                elif \"new_string\" in tool_input: # From Edit tool\n                    content_added = tool_input[\"new_string\"]\n\n                # Check if the added content looks like a new function or class\n                # This is a simple but effective check for Python and JavaScript/TypeScript\n                if re.search(r'^\\s*(def|class|function|const|let|var)\\s+\\w+', content_added, re.MULTILINE):\n                    log_debug(f\"Detected new function/class in {tool_name} operation. Prompting for tests.\")\n                    decision = {\n                        \"decision\": \"block\",\n                        \"reason\": \"You have successfully added a new function or class. As the next logical step, please write a comprehensive unit test for the code you just added.\"\n                    }\n    except Exception as e:\n        log_debug(f\"Error in subagent_stop.py: {e}\")\n        # Fail open to not interrupt the user's workflow\n        decision = {\"decision\": \"approve\"}\n\n    # Log the decision and output it to Claude\n    log_debug(f\"SubagentStop decision: {decision['decision']}\")\n    print(json.dumps(decision))\n    sys.exit(0)\n\ndef log_debug(message: str) -> None:\n    \"\"\"Logs a debug message to the central debug log.\"\"\"\n    try:\n        debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        timestamp = datetime.datetime.now().isoformat()\n        with open(debug_log, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"[{timestamp}] SUBAGENT_STOP: {message}\\n\")\n    except Exception:\n        pass # Silently fail if logging doesn't work\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": []}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:52:10.293561", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\settings.json", "new_string": "    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/post_tool_use.py\",\n            \"timeout\": 60\n          }\n        ]\n      }\n    ],\n    \"SubagentStop\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/subagent_stop.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],", "old_string": "    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/post_tool_use.py\",\n            \"timeout\": 60\n          }\n        ]\n      }\n    ],", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\settings.json", "oldString": "    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/post_tool_use.py\",\n            \"timeout\": 60\n          }\n        ]\n      }\n    ],", "newString": "    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/post_tool_use.py\",\n            \"timeout\": 60\n          }\n        ]\n      }\n    ],\n    \"SubagentStop\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/subagent_stop.py\",\n            \"timeout\": 10\n          }\n        ]\n      }\n    ],", "originalFile": "{\n  \"env\": {\n    \"ANTHROPIC_MODEL\": \"sonnet\"\n  },\n  \"permissions\": {\n    \"allow\": [\n      \"Read(*)\",\n      \"WebFetch(domain:*)\",\n      \"mcp__sequentialthinking__sequentialthinking_tools\"\n    ],\n    \"defaultMode\": \"plan\"\n  },\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/pre_tool_use.py\",\n            \"timeout\": 30\n          }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|MultiEdit\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/post_tool_use.py\",\n            \"timeout\": 60\n          }\n        ]\n      }\n    ],\n    \"Stop\": [\n      {\n        \"matcher\": \"\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/stop.py\"\n          }\n        ]\n      }\n    ],\n    \"Notification\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/notifications.py\"\n          }\n        ]\n      }\n    ],\n    \"PreCompact\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"uv run C:/Users/NATH/.claude/hooks/pre_compact.py\"\n          }\n        ]\n      }\n    ]\n  }\n}", "structuredPatch": [{"oldStart": 35, "oldLines": 6, "newStart": 35, "newLines": 18, "lines": ["         ]", "       }", "     ],", "+    \"SubagentStop\": [", "+      {", "+        \"matcher\": \"Write|Edit|MultiEdit\",", "+        \"hooks\": [", "+          {", "+            \"type\": \"command\",", "+            \"command\": \"uv run C:/Users/NATH/.claude/hooks/subagent_stop.py\",", "+            \"timeout\": 10", "+          }", "+        ]", "+      }", "+    ],", "     \"Stop\": [", "       {", "         \"matcher\": \"\","]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:54:18.075621", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using intelligent pattern matching - analyze content and context.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        session_summary = tool_history.get(\"session_summary\", \"\")\n        \n        if not file_operations:\n            return \"\"  # Let LLM handle this case\n            \n        # Analyze the session summary for clues about what was done\n        summary_lower = session_summary.lower()\n        \n        # Look for specific development patterns\n        if \"creating files\" in summary_lower or \"write\" in summary_lower:\n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"feat: add {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            else:\n                return f\"feat: add {len(files_changed)} new files\"\n        \n        elif \"editing files\" in summary_lower or \"multi-file editing\" in summary_lower:\n            # Try to infer the purpose from file names and operations\n            file_names = [f.get(\"file\", \"\") for f in files_changed]\n            \n            # Check for specific patterns in file names\n            if any(\"hook\" in name.lower() for name in file_names):\n                return \"feat(hooks): enhance automation system\"\n            elif any(\"test\" in name.lower() for name in file_names):\n                return \"test: update test suite\"\n            elif any(\"util\" in name.lower() for name in file_names):\n                return \"refactor(utils): improve utilities\"\n            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):\n                return \"chore(config): update configuration\"\n            elif any(\"api\" in name.lower() for name in file_names):\n                return \"feat(api): enhance API functionality\"\n            elif any(\"ui\" in name.lower() or \"component\" in name.lower() for name in file_names):\n                return \"feat(ui): improve user interface\"\n            \n            # Analyze by file extension and count\n            py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n            js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n            \n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"refactor: enhance {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            elif len(py_files) > 0 and len(js_files) == 0:\n                return \"refactor: enhance Python modules\"\n            elif len(js_files) > 0 and len(py_files) == 0:\n                return \"refactor: enhance JavaScript components\"\n            else:\n                return f\"refactor: enhance {len(files_changed)} modules\"\n        \n        elif \"executing commands\" in summary_lower:\n            return \"chore: run maintenance tasks\"\n        \n        elif \"reading/analyzing code\" in summary_lower:\n            return \"\"  # Let LLM handle analysis sessions\n        \n        # If we can't determine intent from summary, return empty to use LLM\n        return \"\"", "old_string": "    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        \n        if not file_operations:\n            return \"chore: session updates\"\n            \n        # Count operation types\n        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")\n        \n        # Analyze file types\n        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]\n        \n        # Smart pattern matching\n        if len(files_changed) == 1:\n            file_name = files_changed[0].get(\"file\", \"\")\n            if \"test\" in file_name.lower():\n                return \"test: update test files\"\n            elif \"config\" in file_name.lower():\n                return \"chore(config): update settings\"\n            elif file_name.endswith(\".py\"):\n                return \"refactor: update Python code\"\n            elif file_name.endswith((\".js\", \".ts\")):\n                return \"refactor: update JavaScript code\"\n            else:\n                return f\"chore: update {file_name}\"\n        \n        elif len(py_files) > 0 and len(js_files) == 0:\n            return f\"refactor: update {len(py_files)} Python files\"\n        elif len(js_files) > 0 and len(py_files) == 0:\n            return f\"refactor: update {len(js_files)} JavaScript files\"\n        elif len(config_files) > 0:\n            return \"chore(config): update configuration\"\n        else:\n            return f\"chore: update {len(files_changed)} files\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        \n        if not file_operations:\n            return \"chore: session updates\"\n            \n        # Count operation types\n        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")\n        \n        # Analyze file types\n        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]\n        \n        # Smart pattern matching\n        if len(files_changed) == 1:\n            file_name = files_changed[0].get(\"file\", \"\")\n            if \"test\" in file_name.lower():\n                return \"test: update test files\"\n            elif \"config\" in file_name.lower():\n                return \"chore(config): update settings\"\n            elif file_name.endswith(\".py\"):\n                return \"refactor: update Python code\"\n            elif file_name.endswith((\".js\", \".ts\")):\n                return \"refactor: update JavaScript code\"\n            else:\n                return f\"chore: update {file_name}\"\n        \n        elif len(py_files) > 0 and len(js_files) == 0:\n            return f\"refactor: update {len(py_files)} Python files\"\n        elif len(js_files) > 0 and len(py_files) == 0:\n            return f\"refactor: update {len(js_files)} JavaScript files\"\n        elif len(config_files) > 0:\n            return \"chore(config): update configuration\"\n        else:\n            return f\"chore: update {len(files_changed)} files\"", "newString": "    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using intelligent pattern matching - analyze content and context.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        session_summary = tool_history.get(\"session_summary\", \"\")\n        \n        if not file_operations:\n            return \"\"  # Let LLM handle this case\n            \n        # Analyze the session summary for clues about what was done\n        summary_lower = session_summary.lower()\n        \n        # Look for specific development patterns\n        if \"creating files\" in summary_lower or \"write\" in summary_lower:\n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"feat: add {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            else:\n                return f\"feat: add {len(files_changed)} new files\"\n        \n        elif \"editing files\" in summary_lower or \"multi-file editing\" in summary_lower:\n            # Try to infer the purpose from file names and operations\n            file_names = [f.get(\"file\", \"\") for f in files_changed]\n            \n            # Check for specific patterns in file names\n            if any(\"hook\" in name.lower() for name in file_names):\n                return \"feat(hooks): enhance automation system\"\n            elif any(\"test\" in name.lower() for name in file_names):\n                return \"test: update test suite\"\n            elif any(\"util\" in name.lower() for name in file_names):\n                return \"refactor(utils): improve utilities\"\n            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):\n                return \"chore(config): update configuration\"\n            elif any(\"api\" in name.lower() for name in file_names):\n                return \"feat(api): enhance API functionality\"\n            elif any(\"ui\" in name.lower() or \"component\" in name.lower() for name in file_names):\n                return \"feat(ui): improve user interface\"\n            \n            # Analyze by file extension and count\n            py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n            js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n            \n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"refactor: enhance {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            elif len(py_files) > 0 and len(js_files) == 0:\n                return \"refactor: enhance Python modules\"\n            elif len(js_files) > 0 and len(py_files) == 0:\n                return \"refactor: enhance JavaScript components\"\n            else:\n                return f\"refactor: enhance {len(files_changed)} modules\"\n        \n        elif \"executing commands\" in summary_lower:\n            return \"chore: run maintenance tasks\"\n        \n        elif \"reading/analyzing code\" in summary_lower:\n            return \"\"  # Let LLM handle analysis sessions\n        \n        # If we can't determine intent from summary, return empty to use LLM\n        return \"\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:\n        \"\"\"\n        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.\n        \n        Args:\n            session_id: Session identifier\n            stop_payload: Stop hook payload with session information\n        \"\"\"\n        try:\n            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")\n            \n            # Load all tool usage from the entire session\n            tool_history = self._load_tool_usage_history(session_id)\n            \n            # Check if there were any meaningful file operations\n            file_operations = tool_history.get(\"file_operations\", [])\n            if not file_operations:\n                self._log_debug(\"No file operations found, skipping checkpoint\")\n                return\n                \n            # Analyze git repository state\n            git_context = self._analyze_git_changes()\n            if not git_context.get(\"files\"):\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return\n                \n            # Build session context\n            session_context = {\n                \"session_id\": session_id,\n                \"total_operations\": len(file_operations),\n                \"file_count\": len(git_context.get(\"files\", [])),\n                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")\n            }\n            \n            # Generate commit for entire session (with unlimited time!)\n            commit_message = self._generate_session_commit(session_context, git_context, tool_history)\n            \n            # Create the commit\n            if self._create_commit(commit_message):\n                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")\n            else:\n                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")\n                \n        except Exception as e:\n            self._log_debug(f\"Session checkpoint error: {e}\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _generate_session_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate commit message for entire session - much simpler and more reliable.\n        Since this runs in Stop hook, we have unlimited time for LLM calls.\n        \"\"\"\n        try:\n            # Build session-level prompt\n            file_operations = tool_history.get(\"file_operations\", [])\n            total_ops = session_context.get(\"total_operations\", 0)\n            file_count = session_context.get(\"file_count\", 0)\n            \n            # Create simple but effective prompt\n            session_prompt = f\"\"\"Generate a git commit message for this session.\n\nSESSION SUMMARY:\n- Total operations: {total_ops}\n- Files changed: {file_count}\n- Activity: {tool_history.get('session_summary', 'code changes')}\n\nFILES CHANGED:\n{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nFORMAT: type(scope): description\nEXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure\n\nCOMMIT MESSAGE:\"\"\"\n\n            # Since we're in Stop hook, we can take time for LLM\n            self._log_debug(\"\u00f0\u0178\u0161\u20ac Session commit generation (unlimited time)\")\n            \n            # Try simple pattern matching first (instant)\n            pattern_commit = self._generate_pattern_commit(session_context, git_context, tool_history)\n            if pattern_commit and pattern_commit != \"chore: update files\":\n                self._log_debug(f\"\u00e2\u0153\u2026 Using pattern-based commit: {pattern_commit}\")\n                return pattern_commit\n            \n            # If pattern matching fails, use LLM (with time to complete)\n            self._log_debug(\"\u00f0\u0178\u201c\udc9d Trying LLM generation for session commit\")\n            llm_commit = self._call_claude_task(session_prompt)\n            if llm_commit and \":\" in llm_commit and len(llm_commit) > 10:\n                cleaned = self._clean_commit_message(llm_commit)\n                self._log_debug(f\"\u00e2\u0153\u2026 LLM generated session commit: {cleaned}\")\n                return cleaned\n            \n            # Final fallback\n            return self._create_session_fallback_commit(session_context, git_context)\n            \n        except Exception as e:\n            self._log_debug(f\"Session commit generation error: {e}\")\n            return self._create_session_fallback_commit(session_context, git_context)\n    \n    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        \n        if not file_operations:\n            return \"chore: session updates\"\n            \n        # Count operation types\n        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")\n        \n        # Analyze file types\n        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]\n        \n        # Smart pattern matching\n        if len(files_changed) == 1:\n            file_name = files_changed[0].get(\"file\", \"\")\n            if \"test\" in file_name.lower():\n                return \"test: update test files\"\n            elif \"config\" in file_name.lower():\n                return \"chore(config): update settings\"\n            elif file_name.endswith(\".py\"):\n                return \"refactor: update Python code\"\n            elif file_name.endswith((\".js\", \".ts\")):\n                return \"refactor: update JavaScript code\"\n            else:\n                return f\"chore: update {file_name}\"\n        \n        elif len(py_files) > 0 and len(js_files) == 0:\n            return f\"refactor: update {len(py_files)} Python files\"\n        elif len(js_files) > 0 and len(py_files) == 0:\n            return f\"refactor: update {len(js_files)} JavaScript files\"\n        elif len(config_files) > 0:\n            return \"chore(config): update configuration\"\n        else:\n            return f\"chore: update {len(files_changed)} files\"\n    \n    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:250] # Increased length slightly\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        change_description = self._classify_file_operation(tool_input)\n            \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        \n        # Build a more robust prompt that emphasizes user intent\n        prompt = f\"\"\"Generate a git commit message in the conventional commit format.\nYour primary goal is to reflect the user's original request.\n\n**User's Goal:**\n{user_intent}\n\n**Session Context:**\n- **File(s) Changed:** {', '.join(files_changed)}\n- **Primary Change Type:** {change_description} on {primary_file.get('file', 'unknown')}\n- **Recent Activity:** {session_activity}\n\n**Instructions:**\n1.  **Prioritize the User's Goal.** The commit message must align with their request.\n2.  **Format:** `type(scope): description`\n3.  **Be Concise:** Under 50 characters.\n4.  **Use Present Tense.**\n5.  **Types:** feat, fix, refactor, docs, style, test, chore.\n\nBased on the user's goal, generate ONLY the single-line commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 542, "oldLines": 43, "newStart": 542, "newLines": 65, "lines": ["     def _generate_pattern_commit(self, session_context: Dict[str, Any], ", "                                git_context: Dict[str, Any],", "                                tool_history: Dict[str, Any]) -> str:", "-        \"\"\"Generate commit using simple pattern matching - instant and reliable.\"\"\"", "+        \"\"\"Generate commit using intelligent pattern matching - analyze content and context.\"\"\"", "         file_operations = tool_history.get(\"file_operations\", [])", "         files_changed = git_context.get(\"files\", [])", "+        session_summary = tool_history.get(\"session_summary\", \"\")", "         ", "         if not file_operations:", "-            return \"chore: session updates\"", "+            return \"\"  # Let LLM handle this case", "             ", "-        # Count operation types", "-        edit_count = sum(1 for op in file_operations if op.get(\"operation\", \"\").lower() == \"edit\")", "+        # Analyze the session summary for clues about what was done", "+        summary_lower = session_summary.lower()", "         ", "-        # Analyze file types", "-        py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]", "-        js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]", "-        config_files = [f for f in files_changed if \"config\" in f.get(\"file\", \"\").lower()]", "+        # Look for specific development patterns", "+        if \"creating files\" in summary_lower or \"write\" in summary_lower:", "+            if len(files_changed) == 1:", "+                file_name = files_changed[0].get(\"file\", \"\")", "+                return f\"feat: add {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"", "+            else:", "+                return f\"feat: add {len(files_changed)} new files\"", "         ", "-        # Smart pattern matching", "-        if len(files_changed) == 1:", "-            file_name = files_changed[0].get(\"file\", \"\")", "-            if \"test\" in file_name.lower():", "-                return \"test: update test files\"", "-            elif \"config\" in file_name.lower():", "-                return \"chore(config): update settings\"", "-            elif file_name.endswith(\".py\"):", "-                return \"refactor: update Python code\"", "-            elif file_name.endswith((\".js\", \".ts\")):", "-                return \"refactor: update JavaScript code\"", "+        elif \"editing files\" in summary_lower or \"multi-file editing\" in summary_lower:", "+            # Try to infer the purpose from file names and operations", "+            file_names = [f.get(\"file\", \"\") for f in files_changed]", "+            ", "+            # Check for specific patterns in file names", "+            if any(\"hook\" in name.lower() for name in file_names):", "+                return \"feat(hooks): enhance automation system\"", "+            elif any(\"test\" in name.lower() for name in file_names):", "+                return \"test: update test suite\"", "+            elif any(\"util\" in name.lower() for name in file_names):", "+                return \"refactor(utils): improve utilities\"", "+            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):", "+                return \"chore(config): update configuration\"", "+            elif any(\"api\" in name.lower() for name in file_names):", "+                return \"feat(api): enhance API functionality\"", "+            elif any(\"ui\" in name.lower() or \"component\" in name.lower() for name in file_names):", "+                return \"feat(ui): improve user interface\"", "+            ", "+            # Analyze by file extension and count", "+            py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]", "+            js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]", "+            ", "+            if len(files_changed) == 1:", "+                file_name = files_changed[0].get(\"file\", \"\")", "+                return f\"refactor: enhance {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"", "+            elif len(py_files) > 0 and len(js_files) == 0:", "+                return \"refactor: enhance Python modules\"", "+            elif len(js_files) > 0 and len(py_files) == 0:", "+                return \"refactor: enhance JavaScript components\"", "             else:", "-                return f\"chore: update {file_name}\"", "+                return f\"refactor: enhance {len(files_changed)} modules\"", "         ", "-        elif len(py_files) > 0 and len(js_files) == 0:", "-            return f\"refactor: update {len(py_files)} Python files\"", "-        elif len(js_files) > 0 and len(py_files) == 0:", "-            return f\"refactor: update {len(js_files)} JavaScript files\"", "-        elif len(config_files) > 0:", "-            return \"chore(config): update configuration\"", "-        else:", "-            return f\"chore: update {len(files_changed)} files\"", "+        elif \"executing commands\" in summary_lower:", "+            return \"chore: run maintenance tasks\"", "+        ", "+        elif \"reading/analyzing code\" in summary_lower:", "+            return \"\"  # Let LLM handle analysis sessions", "+        ", "+        # If we can't determine intent from summary, return empty to use LLM", "+        return \"\"", "     ", "     def _create_session_fallback_commit(self, session_context: Dict[str, Any], ", "                                       git_context: Dict[str, Any]) -> str:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:54:51.907032", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Extract more context about what actually happened\n            file_names = [op.get('file', 'unknown') for op in file_operations[:5]]\n            operation_types = [op.get('operation', 'edit') for op in file_operations[:5]]\n            \n            # Analyze the specific changes made\n            change_patterns = []\n            if any('hook' in name.lower() for name in file_names):\n                change_patterns.append(\"automation/hooks\")\n            if any('util' in name.lower() for name in file_names):\n                change_patterns.append(\"utilities\")\n            if any('config' in name.lower() or 'setting' in name.lower() for name in file_names):\n                change_patterns.append(\"configuration\")\n            if any('test' in name.lower() for name in file_names):\n                change_patterns.append(\"testing\")\n            \n            patterns_text = ', '.join(change_patterns) if change_patterns else 'code modules'\n            \n            # Build a much more detailed and context-rich prompt\n            session_prompt = f\"\"\"You are generating a git commit message that accurately reflects what the developer accomplished.\n\nWHAT THE DEVELOPER DID:\n- Session Activity: {tool_history.get('session_summary', 'code changes')}\n- Changed {file_count} files with {total_ops} operations\n- Areas modified: {patterns_text}\n\nSPECIFIC FILES AND OPERATIONS:\n{chr(10).join([f\"- {op.get('operation', 'edit').title()}: {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nCONTEXT CLUES:\n- If hooks were modified: likely \"feat(hooks)\" or \"refactor(hooks)\"\n- If utilities enhanced: likely \"refactor(utils)\" or \"feat(utils)\" \n- If configuration updated: likely \"chore(config)\" or \"feat(config)\"\n- If new features added: likely \"feat:\" \n- If bugs fixed: likely \"fix:\"\n- If code improved/cleaned: likely \"refactor:\"\n\nYOUR TASK:\nGenerate ONE conventional commit message that captures the main accomplishment.\nFormat: type(scope): description\nKeep under 50 characters and use present tense.\n\nExamples of GOOD commit messages:\n- feat(hooks): add automated task chaining\n- refactor(utils): enhance voice notifications  \n- feat(voice): implement dynamic LLM responses\n- refactor(git): improve context-aware commits\n\nCOMMIT MESSAGE:\"\"\"", "old_string": "            # Create simple but effective prompt\n            session_prompt = f\"\"\"Generate a git commit message for this session.\n\nSESSION SUMMARY:\n- Total operations: {total_ops}\n- Files changed: {file_count}\n- Activity: {tool_history.get('session_summary', 'code changes')}\n\nFILES CHANGED:\n{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nFORMAT: type(scope): description\nEXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure\n\nCOMMIT MESSAGE:\"\"\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Create simple but effective prompt\n            session_prompt = f\"\"\"Generate a git commit message for this session.\n\nSESSION SUMMARY:\n- Total operations: {total_ops}\n- Files changed: {file_count}\n- Activity: {tool_history.get('session_summary', 'code changes')}\n\nFILES CHANGED:\n{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nFORMAT: type(scope): description\nEXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure\n\nCOMMIT MESSAGE:\"\"\"", "newString": "            # Extract more context about what actually happened\n            file_names = [op.get('file', 'unknown') for op in file_operations[:5]]\n            operation_types = [op.get('operation', 'edit') for op in file_operations[:5]]\n            \n            # Analyze the specific changes made\n            change_patterns = []\n            if any('hook' in name.lower() for name in file_names):\n                change_patterns.append(\"automation/hooks\")\n            if any('util' in name.lower() for name in file_names):\n                change_patterns.append(\"utilities\")\n            if any('config' in name.lower() or 'setting' in name.lower() for name in file_names):\n                change_patterns.append(\"configuration\")\n            if any('test' in name.lower() for name in file_names):\n                change_patterns.append(\"testing\")\n            \n            patterns_text = ', '.join(change_patterns) if change_patterns else 'code modules'\n            \n            # Build a much more detailed and context-rich prompt\n            session_prompt = f\"\"\"You are generating a git commit message that accurately reflects what the developer accomplished.\n\nWHAT THE DEVELOPER DID:\n- Session Activity: {tool_history.get('session_summary', 'code changes')}\n- Changed {file_count} files with {total_ops} operations\n- Areas modified: {patterns_text}\n\nSPECIFIC FILES AND OPERATIONS:\n{chr(10).join([f\"- {op.get('operation', 'edit').title()}: {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nCONTEXT CLUES:\n- If hooks were modified: likely \"feat(hooks)\" or \"refactor(hooks)\"\n- If utilities enhanced: likely \"refactor(utils)\" or \"feat(utils)\" \n- If configuration updated: likely \"chore(config)\" or \"feat(config)\"\n- If new features added: likely \"feat:\" \n- If bugs fixed: likely \"fix:\"\n- If code improved/cleaned: likely \"refactor:\"\n\nYOUR TASK:\nGenerate ONE conventional commit message that captures the main accomplishment.\nFormat: type(scope): description\nKeep under 50 characters and use present tense.\n\nExamples of GOOD commit messages:\n- feat(hooks): add automated task chaining\n- refactor(utils): enhance voice notifications  \n- feat(voice): implement dynamic LLM responses\n- refactor(git): improve context-aware commits\n\nCOMMIT MESSAGE:\"\"\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:\n        \"\"\"\n        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.\n        \n        Args:\n            session_id: Session identifier\n            stop_payload: Stop hook payload with session information\n        \"\"\"\n        try:\n            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")\n            \n            # Load all tool usage from the entire session\n            tool_history = self._load_tool_usage_history(session_id)\n            \n            # Check if there were any meaningful file operations\n            file_operations = tool_history.get(\"file_operations\", [])\n            if not file_operations:\n                self._log_debug(\"No file operations found, skipping checkpoint\")\n                return\n                \n            # Analyze git repository state\n            git_context = self._analyze_git_changes()\n            if not git_context.get(\"files\"):\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return\n                \n            # Build session context\n            session_context = {\n                \"session_id\": session_id,\n                \"total_operations\": len(file_operations),\n                \"file_count\": len(git_context.get(\"files\", [])),\n                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")\n            }\n            \n            # Generate commit for entire session (with unlimited time!)\n            commit_message = self._generate_session_commit(session_context, git_context, tool_history)\n            \n            # Create the commit\n            if self._create_commit(commit_message):\n                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")\n            else:\n                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")\n                \n        except Exception as e:\n            self._log_debug(f\"Session checkpoint error: {e}\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _generate_session_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate commit message for entire session - much simpler and more reliable.\n        Since this runs in Stop hook, we have unlimited time for LLM calls.\n        \"\"\"\n        try:\n            # Build session-level prompt\n            file_operations = tool_history.get(\"file_operations\", [])\n            total_ops = session_context.get(\"total_operations\", 0)\n            file_count = session_context.get(\"file_count\", 0)\n            \n            # Create simple but effective prompt\n            session_prompt = f\"\"\"Generate a git commit message for this session.\n\nSESSION SUMMARY:\n- Total operations: {total_ops}\n- Files changed: {file_count}\n- Activity: {tool_history.get('session_summary', 'code changes')}\n\nFILES CHANGED:\n{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nFORMAT: type(scope): description\nEXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure\n\nCOMMIT MESSAGE:\"\"\"\n\n            # Since we're in Stop hook, we can take time for LLM\n            self._log_debug(\"\u00f0\u0178\u0161\u20ac Session commit generation (unlimited time)\")\n            \n            # Try simple pattern matching first (instant)\n            pattern_commit = self._generate_pattern_commit(session_context, git_context, tool_history)\n            if pattern_commit and pattern_commit != \"chore: update files\":\n                self._log_debug(f\"\u00e2\u0153\u2026 Using pattern-based commit: {pattern_commit}\")\n                return pattern_commit\n            \n            # If pattern matching fails, use LLM (with time to complete)\n            self._log_debug(\"\u00f0\u0178\u201c\udc9d Trying LLM generation for session commit\")\n            llm_commit = self._call_claude_task(session_prompt)\n            if llm_commit and \":\" in llm_commit and len(llm_commit) > 10:\n                cleaned = self._clean_commit_message(llm_commit)\n                self._log_debug(f\"\u00e2\u0153\u2026 LLM generated session commit: {cleaned}\")\n                return cleaned\n            \n            # Final fallback\n            return self._create_session_fallback_commit(session_context, git_context)\n            \n        except Exception as e:\n            self._log_debug(f\"Session commit generation error: {e}\")\n            return self._create_session_fallback_commit(session_context, git_context)\n    \n    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using intelligent pattern matching - analyze content and context.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        session_summary = tool_history.get(\"session_summary\", \"\")\n        \n        if not file_operations:\n            return \"\"  # Let LLM handle this case\n            \n        # Analyze the session summary for clues about what was done\n        summary_lower = session_summary.lower()\n        \n        # Look for specific development patterns\n        if \"creating files\" in summary_lower or \"write\" in summary_lower:\n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"feat: add {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            else:\n                return f\"feat: add {len(files_changed)} new files\"\n        \n        elif \"editing files\" in summary_lower or \"multi-file editing\" in summary_lower:\n            # Try to infer the purpose from file names and operations\n            file_names = [f.get(\"file\", \"\") for f in files_changed]\n            \n            # Check for specific patterns in file names\n            if any(\"hook\" in name.lower() for name in file_names):\n                return \"feat(hooks): enhance automation system\"\n            elif any(\"test\" in name.lower() for name in file_names):\n                return \"test: update test suite\"\n            elif any(\"util\" in name.lower() for name in file_names):\n                return \"refactor(utils): improve utilities\"\n            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):\n                return \"chore(config): update configuration\"\n            elif any(\"api\" in name.lower() for name in file_names):\n                return \"feat(api): enhance API functionality\"\n            elif any(\"ui\" in name.lower() or \"component\" in name.lower() for name in file_names):\n                return \"feat(ui): improve user interface\"\n            \n            # Analyze by file extension and count\n            py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n            js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n            \n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"refactor: enhance {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            elif len(py_files) > 0 and len(js_files) == 0:\n                return \"refactor: enhance Python modules\"\n            elif len(js_files) > 0 and len(py_files) == 0:\n                return \"refactor: enhance JavaScript components\"\n            else:\n                return f\"refactor: enhance {len(files_changed)} modules\"\n        \n        elif \"executing commands\" in summary_lower:\n            return \"chore: run maintenance tasks\"\n        \n        elif \"reading/analyzing code\" in summary_lower:\n            return \"\"  # Let LLM handle analysis sessions\n        \n        # If we can't determine intent from summary, return empty to use LLM\n        return \"\"\n    \n    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:250] # Increased length slightly\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        change_description = self._classify_file_operation(tool_input)\n            \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        \n        # Build a more robust prompt that emphasizes user intent\n        prompt = f\"\"\"Generate a git commit message in the conventional commit format.\nYour primary goal is to reflect the user's original request.\n\n**User's Goal:**\n{user_intent}\n\n**Session Context:**\n- **File(s) Changed:** {', '.join(files_changed)}\n- **Primary Change Type:** {change_description} on {primary_file.get('file', 'unknown')}\n- **Recent Activity:** {session_activity}\n\n**Instructions:**\n1.  **Prioritize the User's Goal.** The commit message must align with their request.\n2.  **Format:** `type(scope): description`\n3.  **Be Concise:** Under 50 characters.\n4.  **Use Present Tense.**\n5.  **Types:** feat, fix, refactor, docs, style, test, chore.\n\nBased on the user's goal, generate ONLY the single-line commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 498, "oldLines": 21, "newStart": 498, "newLines": 54, "lines": ["             total_ops = session_context.get(\"total_operations\", 0)", "             file_count = session_context.get(\"file_count\", 0)", "             ", "-            # Create simple but effective prompt", "-            session_prompt = f\"\"\"Generate a git commit message for this session.", "+            # Extract more context about what actually happened", "+            file_names = [op.get('file', 'unknown') for op in file_operations[:5]]", "+            operation_types = [op.get('operation', 'edit') for op in file_operations[:5]]", "+            ", "+            # Analyze the specific changes made", "+            change_patterns = []", "+            if any('hook' in name.lower() for name in file_names):", "+                change_patterns.append(\"automation/hooks\")", "+            if any('util' in name.lower() for name in file_names):", "+                change_patterns.append(\"utilities\")", "+            if any('config' in name.lower() or 'setting' in name.lower() for name in file_names):", "+                change_patterns.append(\"configuration\")", "+            if any('test' in name.lower() for name in file_names):", "+                change_patterns.append(\"testing\")", "+            ", "+            patterns_text = ', '.join(change_patterns) if change_patterns else 'code modules'", "+            ", "+            # Build a much more detailed and context-rich prompt", "+            session_prompt = f\"\"\"You are generating a git commit message that accurately reflects what the developer accomplished.", " ", "-SESSION SUMMARY:", "-- Total operations: {total_ops}", "-- Files changed: {file_count}", "-- Activity: {tool_history.get('session_summary', 'code changes')}", "+WHAT THE DEVELOPER DID:", "+- Session Activity: {tool_history.get('session_summary', 'code changes')}", "+- Changed {file_count} files with {total_ops} operations", "+- Areas modified: {patterns_text}", " ", "-FILES CHANGED:", "-{chr(10).join([f\"- {op.get('file', 'unknown')}\" for op in file_operations[:5]])}", "+SPECIFIC FILES AND OPERATIONS:", "+{chr(10).join([f\"- {op.get('operation', 'edit').title()}: {op.get('file', 'unknown')}\" for op in file_operations[:5]])}", " {'- ...' if len(file_operations) > 5 else ''}", " ", "-FORMAT: type(scope): description", "-EXAMPLES: fix(auth): handle login errors, feat(ui): add search, refactor: improve code structure", "+CONTEXT CLUES:", "+- If hooks were modified: likely \"feat(hooks)\" or \"refactor(hooks)\"", "+- If utilities enhanced: likely \"refactor(utils)\" or \"feat(utils)\" ", "+- If configuration updated: likely \"chore(config)\" or \"feat(config)\"", "+- If new features added: likely \"feat:\" ", "+- If bugs fixed: likely \"fix:\"", "+- If code improved/cleaned: likely \"refactor:\"", " ", "+YOUR TASK:", "+Generate ONE conventional commit message that captures the main accomplishment.", "+Format: type(scope): description", "+Keep under 50 characters and use present tense.", "+", "+Examples of GOOD commit messages:", "+- feat(hooks): add automated task chaining", "+- refactor(utils): enhance voice notifications  ", "+- feat(voice): implement dynamic LLM responses", "+- refactor(git): improve context-aware commits", "+", " COMMIT MESSAGE:\"\"\"", " ", "             # Since we're in Stop hook, we can take time for LLM"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T01:55:22.578447", "event": "PostToolUse", "session_id": "2e286492-3935-428e-90eb-f6828206dfdf", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create intelligent fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        files = git_context.get(\"files\", [])\n        \n        # Single file - be specific about what was changed\n        if file_count == 1 and files:\n            file_name = files[0].get(\"file\", \"file\")\n            base_name = file_name.replace('.py', '').replace('.js', '').replace('.ts', '')\n            \n            # Infer purpose from filename\n            if \"hook\" in file_name.lower():\n                return f\"feat(hooks): enhance {base_name}\"\n            elif \"util\" in file_name.lower():\n                return f\"refactor(utils): improve {base_name}\"\n            elif \"config\" in file_name.lower() or \"setting\" in file_name.lower():\n                return f\"chore(config): update {base_name}\"\n            elif \"test\" in file_name.lower():\n                return f\"test: update {base_name}\"\n            else:\n                return f\"refactor: enhance {base_name}\"\n        \n        # Multiple files - analyze patterns\n        elif files:\n            file_names = [f.get(\"file\", \"\") for f in files]\n            \n            if any(\"hook\" in name.lower() for name in file_names):\n                return f\"feat(hooks): enhance automation ({file_count} files)\"\n            elif any(\"util\" in name.lower() for name in file_names):\n                return f\"refactor(utils): improve utilities ({file_count} files)\"\n            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):\n                return f\"chore(config): update configuration ({file_count} files)\"\n            elif any(\"test\" in name.lower() for name in file_names):\n                return f\"test: update test suite ({file_count} files)\"\n            else:\n                # Count by file type\n                py_count = sum(1 for name in file_names if name.endswith('.py'))\n                js_count = sum(1 for name in file_names if name.endswith(('.js', '.ts', '.jsx', '.tsx')))\n                \n                if py_count > 0 and js_count == 0:\n                    return f\"refactor: enhance Python modules ({py_count} files)\"\n                elif js_count > 0 and py_count == 0:\n                    return f\"refactor: enhance JavaScript modules ({js_count} files)\"\n                else:\n                    return f\"refactor: enhance codebase ({file_count} files)\"\n        \n        # Ultimate fallback\n        return f\"chore: development session ({total_ops} operations)\"", "old_string": "    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"", "newString": "    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create intelligent fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        files = git_context.get(\"files\", [])\n        \n        # Single file - be specific about what was changed\n        if file_count == 1 and files:\n            file_name = files[0].get(\"file\", \"file\")\n            base_name = file_name.replace('.py', '').replace('.js', '').replace('.ts', '')\n            \n            # Infer purpose from filename\n            if \"hook\" in file_name.lower():\n                return f\"feat(hooks): enhance {base_name}\"\n            elif \"util\" in file_name.lower():\n                return f\"refactor(utils): improve {base_name}\"\n            elif \"config\" in file_name.lower() or \"setting\" in file_name.lower():\n                return f\"chore(config): update {base_name}\"\n            elif \"test\" in file_name.lower():\n                return f\"test: update {base_name}\"\n            else:\n                return f\"refactor: enhance {base_name}\"\n        \n        # Multiple files - analyze patterns\n        elif files:\n            file_names = [f.get(\"file\", \"\") for f in files]\n            \n            if any(\"hook\" in name.lower() for name in file_names):\n                return f\"feat(hooks): enhance automation ({file_count} files)\"\n            elif any(\"util\" in name.lower() for name in file_names):\n                return f\"refactor(utils): improve utilities ({file_count} files)\"\n            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):\n                return f\"chore(config): update configuration ({file_count} files)\"\n            elif any(\"test\" in name.lower() for name in file_names):\n                return f\"test: update test suite ({file_count} files)\"\n            else:\n                # Count by file type\n                py_count = sum(1 for name in file_names if name.endswith('.py'))\n                js_count = sum(1 for name in file_names if name.endswith(('.js', '.ts', '.jsx', '.tsx')))\n                \n                if py_count > 0 and js_count == 0:\n                    return f\"refactor: enhance Python modules ({py_count} files)\"\n                elif js_count > 0 and py_count == 0:\n                    return f\"refactor: enhance JavaScript modules ({js_count} files)\"\n                else:\n                    return f\"refactor: enhance codebase ({file_count} files)\"\n        \n        # Ultimate fallback\n        return f\"chore: development session ({total_ops} operations)\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_session_checkpoint(self, session_id: str, stop_payload: Dict[str, Any]) -> None:\n        \"\"\"\n        Process git checkpoint for entire session - runs in Stop hook with no timing constraints.\n        \n        Args:\n            session_id: Session identifier\n            stop_payload: Stop hook payload with session information\n        \"\"\"\n        try:\n            self._log_debug(f\"\u00f0\u0178\u201d\u201e Processing session checkpoint for {session_id}\")\n            \n            # Load all tool usage from the entire session\n            tool_history = self._load_tool_usage_history(session_id)\n            \n            # Check if there were any meaningful file operations\n            file_operations = tool_history.get(\"file_operations\", [])\n            if not file_operations:\n                self._log_debug(\"No file operations found, skipping checkpoint\")\n                return\n                \n            # Analyze git repository state\n            git_context = self._analyze_git_changes()\n            if not git_context.get(\"files\"):\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return\n                \n            # Build session context\n            session_context = {\n                \"session_id\": session_id,\n                \"total_operations\": len(file_operations),\n                \"file_count\": len(git_context.get(\"files\", [])),\n                \"session_summary\": tool_history.get(\"session_summary\", \"session activity\")\n            }\n            \n            # Generate commit for entire session (with unlimited time!)\n            commit_message = self._generate_session_commit(session_context, git_context, tool_history)\n            \n            # Create the commit\n            if self._create_commit(commit_message):\n                self._log_debug(f\"\u00e2\u0153\u2026 Session commit created: {commit_message}\")\n            else:\n                self._log_debug(\"\u00e2\udc9d\u0152 Failed to create session commit\")\n                \n        except Exception as e:\n            self._log_debug(f\"Session checkpoint error: {e}\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the actual prompt being sent\n        self._log_debug(f\"Generated prompt for LLM (first 300 chars): {prompt[:300]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt, tool_context, git_context)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _generate_session_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"\n        Generate commit message for entire session - much simpler and more reliable.\n        Since this runs in Stop hook, we have unlimited time for LLM calls.\n        \"\"\"\n        try:\n            # Build session-level prompt\n            file_operations = tool_history.get(\"file_operations\", [])\n            total_ops = session_context.get(\"total_operations\", 0)\n            file_count = session_context.get(\"file_count\", 0)\n            \n            # Extract more context about what actually happened\n            file_names = [op.get('file', 'unknown') for op in file_operations[:5]]\n            operation_types = [op.get('operation', 'edit') for op in file_operations[:5]]\n            \n            # Analyze the specific changes made\n            change_patterns = []\n            if any('hook' in name.lower() for name in file_names):\n                change_patterns.append(\"automation/hooks\")\n            if any('util' in name.lower() for name in file_names):\n                change_patterns.append(\"utilities\")\n            if any('config' in name.lower() or 'setting' in name.lower() for name in file_names):\n                change_patterns.append(\"configuration\")\n            if any('test' in name.lower() for name in file_names):\n                change_patterns.append(\"testing\")\n            \n            patterns_text = ', '.join(change_patterns) if change_patterns else 'code modules'\n            \n            # Build a much more detailed and context-rich prompt\n            session_prompt = f\"\"\"You are generating a git commit message that accurately reflects what the developer accomplished.\n\nWHAT THE DEVELOPER DID:\n- Session Activity: {tool_history.get('session_summary', 'code changes')}\n- Changed {file_count} files with {total_ops} operations\n- Areas modified: {patterns_text}\n\nSPECIFIC FILES AND OPERATIONS:\n{chr(10).join([f\"- {op.get('operation', 'edit').title()}: {op.get('file', 'unknown')}\" for op in file_operations[:5]])}\n{'- ...' if len(file_operations) > 5 else ''}\n\nCONTEXT CLUES:\n- If hooks were modified: likely \"feat(hooks)\" or \"refactor(hooks)\"\n- If utilities enhanced: likely \"refactor(utils)\" or \"feat(utils)\" \n- If configuration updated: likely \"chore(config)\" or \"feat(config)\"\n- If new features added: likely \"feat:\" \n- If bugs fixed: likely \"fix:\"\n- If code improved/cleaned: likely \"refactor:\"\n\nYOUR TASK:\nGenerate ONE conventional commit message that captures the main accomplishment.\nFormat: type(scope): description\nKeep under 50 characters and use present tense.\n\nExamples of GOOD commit messages:\n- feat(hooks): add automated task chaining\n- refactor(utils): enhance voice notifications  \n- feat(voice): implement dynamic LLM responses\n- refactor(git): improve context-aware commits\n\nCOMMIT MESSAGE:\"\"\"\n\n            # Since we're in Stop hook, we can take time for LLM\n            self._log_debug(\"\u00f0\u0178\u0161\u20ac Session commit generation (unlimited time)\")\n            \n            # Try simple pattern matching first (instant)\n            pattern_commit = self._generate_pattern_commit(session_context, git_context, tool_history)\n            if pattern_commit and pattern_commit != \"chore: update files\":\n                self._log_debug(f\"\u00e2\u0153\u2026 Using pattern-based commit: {pattern_commit}\")\n                return pattern_commit\n            \n            # If pattern matching fails, use LLM (with time to complete)\n            self._log_debug(\"\u00f0\u0178\u201c\udc9d Trying LLM generation for session commit\")\n            llm_commit = self._call_claude_task(session_prompt)\n            if llm_commit and \":\" in llm_commit and len(llm_commit) > 10:\n                cleaned = self._clean_commit_message(llm_commit)\n                self._log_debug(f\"\u00e2\u0153\u2026 LLM generated session commit: {cleaned}\")\n                return cleaned\n            \n            # Final fallback\n            return self._create_session_fallback_commit(session_context, git_context)\n            \n        except Exception as e:\n            self._log_debug(f\"Session commit generation error: {e}\")\n            return self._create_session_fallback_commit(session_context, git_context)\n    \n    def _generate_pattern_commit(self, session_context: Dict[str, Any], \n                               git_context: Dict[str, Any],\n                               tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate commit using intelligent pattern matching - analyze content and context.\"\"\"\n        file_operations = tool_history.get(\"file_operations\", [])\n        files_changed = git_context.get(\"files\", [])\n        session_summary = tool_history.get(\"session_summary\", \"\")\n        \n        if not file_operations:\n            return \"\"  # Let LLM handle this case\n            \n        # Analyze the session summary for clues about what was done\n        summary_lower = session_summary.lower()\n        \n        # Look for specific development patterns\n        if \"creating files\" in summary_lower or \"write\" in summary_lower:\n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"feat: add {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            else:\n                return f\"feat: add {len(files_changed)} new files\"\n        \n        elif \"editing files\" in summary_lower or \"multi-file editing\" in summary_lower:\n            # Try to infer the purpose from file names and operations\n            file_names = [f.get(\"file\", \"\") for f in files_changed]\n            \n            # Check for specific patterns in file names\n            if any(\"hook\" in name.lower() for name in file_names):\n                return \"feat(hooks): enhance automation system\"\n            elif any(\"test\" in name.lower() for name in file_names):\n                return \"test: update test suite\"\n            elif any(\"util\" in name.lower() for name in file_names):\n                return \"refactor(utils): improve utilities\"\n            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):\n                return \"chore(config): update configuration\"\n            elif any(\"api\" in name.lower() for name in file_names):\n                return \"feat(api): enhance API functionality\"\n            elif any(\"ui\" in name.lower() or \"component\" in name.lower() for name in file_names):\n                return \"feat(ui): improve user interface\"\n            \n            # Analyze by file extension and count\n            py_files = [f for f in files_changed if f.get(\"file\", \"\").endswith(\".py\")]\n            js_files = [f for f in files_changed if f.get(\"file\", \"\").endswith((\".js\", \".ts\", \".jsx\", \".tsx\"))]\n            \n            if len(files_changed) == 1:\n                file_name = files_changed[0].get(\"file\", \"\")\n                return f\"refactor: enhance {file_name.replace('.py', '').replace('.js', '').replace('.ts', '')}\"\n            elif len(py_files) > 0 and len(js_files) == 0:\n                return \"refactor: enhance Python modules\"\n            elif len(js_files) > 0 and len(py_files) == 0:\n                return \"refactor: enhance JavaScript components\"\n            else:\n                return f\"refactor: enhance {len(files_changed)} modules\"\n        \n        elif \"executing commands\" in summary_lower:\n            return \"chore: run maintenance tasks\"\n        \n        elif \"reading/analyzing code\" in summary_lower:\n            return \"\"  # Let LLM handle analysis sessions\n        \n        # If we can't determine intent from summary, return empty to use LLM\n        return \"\"\n    \n    def _create_session_fallback_commit(self, session_context: Dict[str, Any], \n                                      git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit for session-level processing.\"\"\"\n        file_count = session_context.get(\"file_count\", 0)\n        total_ops = session_context.get(\"total_operations\", 0)\n        \n        if file_count == 1:\n            files = git_context.get(\"files\", [])\n            if files:\n                file_name = files[0].get(\"file\", \"file\")\n                return f\"chore: update {file_name}\"\n        \n        return f\"chore: session with {total_ops} operations on {file_count} files\"\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:250] # Increased length slightly\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        change_description = self._classify_file_operation(tool_input)\n            \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        \n        # Build a more robust prompt that emphasizes user intent\n        prompt = f\"\"\"Generate a git commit message in the conventional commit format.\nYour primary goal is to reflect the user's original request.\n\n**User's Goal:**\n{user_intent}\n\n**Session Context:**\n- **File(s) Changed:** {', '.join(files_changed)}\n- **Primary Change Type:** {change_description} on {primary_file.get('file', 'unknown')}\n- **Recent Activity:** {session_activity}\n\n**Instructions:**\n1.  **Prioritize the User's Goal.** The commit message must align with their request.\n2.  **Format:** `type(scope): description`\n3.  **Be Concise:** Under 50 characters.\n4.  **Use Present Tense.**\n5.  **Types:** feat, fix, refactor, docs, style, test, chore.\n\nBased on the user's goal, generate ONLY the single-line commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str, tool_context: Dict[str, Any] = None, git_context: Dict[str, Any] = None) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"TASK: Generate a git commit message.\n\nCONTEXT:\n{prompt[:300]}\n\nREQUIREMENTS:\n- Use conventional commit format: type(scope): description  \n- Maximum 50 characters\n- Use present tense verbs\n- Do NOT provide explanations or conversation\n- Output ONLY the commit message\n\nEXAMPLES:\nfeat(auth): add login validation\nfix(parser): handle null values  \nrefactor(ui): extract components\nchore(deps): update packages\n\nCOMMIT MESSAGE:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import LLMClient\n                    \n                    # Create LLM client with more specific system prompt\n                    llm = LLMClient()\n                    commit_system_prompt = (\n                        \"You are a commit message generator. Output only the commit message in this exact format: \"\n                        \"type(scope): description. No conversation, no explanations, no questions. \"\n                        \"Examples: 'fix(auth): handle login errors', 'feat(ui): add search bar', 'chore: update deps'. \"\n                        \"Output ONLY the commit message.\"\n                    )\n                    \n                    # Debug: Log what we're sending to LLM utility\n                    self._log_debug(f\"Sending to LLM utility (first 200 chars): {task_prompt[:200]}...\")\n                    \n                    # Set very short timeout to avoid Stop hook interruption (5 seconds max)\n                    import time\n                    start_time = time.time()\n                    \n                    # Override LLM client timeout for this call (20s for ample completion time)\n                    original_timeout = llm.config.default_timeout\n                    llm.config.default_timeout = 20\n                    \n                    try:\n                        response = llm.ask(task_prompt, model=\"claude-3-5-haiku-20241022\", max_tokens=30, system_prompt=commit_system_prompt)\n                        elapsed = time.time() - start_time\n                        self._log_debug(f\"\u00e2\u0161\u00a1 Fast LLM call completed in {elapsed:.2f}s\")\n                    finally:\n                        # Restore original timeout\n                        llm.config.default_timeout = original_timeout\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Check if this is the hardcoded fallback or conversational response\n                    if response == \"chore: update files\":\n                        self._log_debug(\"LLM returned hardcoded fallback, trying direct claude command\")\n                    elif \"apologize\" in response.lower() or \"incomplete\" in response.lower() or \"question\" in response.lower():\n                        self._log_debug(\"\u00f0\u0178\u0161\u00a8 LLM got interrupted/incomplete prompt, falling back to simple commit\")\n                        # Use fallback immediately since the prompt was interrupted\n                        if tool_context and git_context:\n                            return self._create_fallback_commit(tool_context, git_context)\n                        else:\n                            return \"chore: interrupted LLM operation\"\n                    elif response and response != \"AI response unavailable\" and len(response) > 10 and \":\" in response:\n                        self._log_debug(f\"\u00e2\u0153\u2026 LLM gave meaningful commit message: {response}\")\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                # Try different claude command variations for Windows (most reliable first)\n                claude_commands = [\n                    # Use the exact path that worked before\n                    [\"C:\\\\Users\\\\NATH\\\\AppData\\\\Local\\\\pnpm\\\\claude.CMD\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", \"--append-system-prompt\", \"Generate ONLY a conventional commit message. Format: type(scope): description. No explanations.\", f\"@{temp_file_path}\"],\n                    # Fallback to generic commands\n                    [\"claude.cmd\", \"--model\", \"claude-3-5-haiku-20241022\", \"--output-format\", \"text\", f\"@{temp_file_path}\"],\n                    [\"claude\", \"--model\", \"claude-3-5-haiku-20241022\", f\"@{temp_file_path}\"]\n                ]\n                \n                result = None\n                for cmd in claude_commands:\n                    try:\n                        self._log_debug(f\"Trying claude command: {cmd[0]}\")\n                        # Use cmd.exe explicitly to avoid bash issues on Windows\n                        cmd_command = \" \".join(f'\"{arg}\"' if \" \" in str(arg) else str(arg) for arg in cmd)\n                        \n                        result = subprocess.run(\n                            [\"cmd.exe\", \"/c\", cmd_command],\n                            capture_output=True, \n                            text=True, \n                            timeout=15,  # Give fallback commands reasonable time\n                            cwd=pathlib.Path.cwd()\n                        )\n                        if result.returncode == 0:\n                            self._log_debug(f\"Claude command succeeded with: {cmd[0]}\")\n                            break\n                        else:\n                            self._log_debug(f\"Claude command {cmd[0]} failed with code {result.returncode}: {result.stderr}\")\n                    except Exception as e:\n                        self._log_debug(f\"Claude command {cmd[0]} exception: {e}\")\n                        continue\n                \n                if not result or result.returncode != 0:\n                    self._log_debug(\"All claude commands failed\")\n                    raise Exception(\"All claude command variations failed\")\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 637, "oldLines": 17, "newStart": 637, "newLines": 54, "lines": ["     ", "     def _create_session_fallback_commit(self, session_context: Dict[str, Any], ", "                                       git_context: Dict[str, Any]) -> str:", "-        \"\"\"Create fallback commit for session-level processing.\"\"\"", "+        \"\"\"Create intelligent fallback commit for session-level processing.\"\"\"", "         file_count = session_context.get(\"file_count\", 0)", "         total_ops = session_context.get(\"total_operations\", 0)", "+        files = git_context.get(\"files\", [])", "         ", "-        if file_count == 1:", "-            files = git_context.get(\"files\", [])", "-            if files:", "-                file_name = files[0].get(\"file\", \"file\")", "-                return f\"chore: update {file_name}\"", "+        # Single file - be specific about what was changed", "+        if file_count == 1 and files:", "+            file_name = files[0].get(\"file\", \"file\")", "+            base_name = file_name.replace('.py', '').replace('.js', '').replace('.ts', '')", "+            ", "+            # Infer purpose from filename", "+            if \"hook\" in file_name.lower():", "+                return f\"feat(hooks): enhance {base_name}\"", "+            elif \"util\" in file_name.lower():", "+                return f\"refactor(utils): improve {base_name}\"", "+            elif \"config\" in file_name.lower() or \"setting\" in file_name.lower():", "+                return f\"chore(config): update {base_name}\"", "+            elif \"test\" in file_name.lower():", "+                return f\"test: update {base_name}\"", "+            else:", "+                return f\"refactor: enhance {base_name}\"", "         ", "-        return f\"chore: session with {total_ops} operations on {file_count} files\"", "+        # Multiple files - analyze patterns", "+        elif files:", "+            file_names = [f.get(\"file\", \"\") for f in files]", "+            ", "+            if any(\"hook\" in name.lower() for name in file_names):", "+                return f\"feat(hooks): enhance automation ({file_count} files)\"", "+            elif any(\"util\" in name.lower() for name in file_names):", "+                return f\"refactor(utils): improve utilities ({file_count} files)\"", "+            elif any(\"config\" in name.lower() or \"setting\" in name.lower() for name in file_names):", "+                return f\"chore(config): update configuration ({file_count} files)\"", "+            elif any(\"test\" in name.lower() for name in file_names):", "+                return f\"test: update test suite ({file_count} files)\"", "+            else:", "+                # Count by file type", "+                py_count = sum(1 for name in file_names if name.endswith('.py'))", "+                js_count = sum(1 for name in file_names if name.endswith(('.js', '.ts', '.jsx', '.tsx')))", "+                ", "+                if py_count > 0 and js_count == 0:", "+                    return f\"refactor: enhance Python modules ({py_count} files)\"", "+                elif js_count > 0 and py_count == 0:", "+                    return f\"refactor: enhance JavaScript modules ({js_count} files)\"", "+                else:", "+                    return f\"refactor: enhance codebase ({file_count} files)\"", "+        ", "+        # Ultimate fallback", "+        return f\"chore: development session ({total_ops} operations)\"", "     ", "     def _build_ai_prompt(self, tool_context: Dict[str, Any], ", "                         session_context: Dict[str, Any], "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\2e286492-3935-428e-90eb-f6828206dfdf.jsonl", "hook_event_name": "PostToolUse"}
