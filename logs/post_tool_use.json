{"timestamp": "2025-07-20T00:00:58.687974", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "new_string": "        sys.exit(1)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PostToolUse event to logs directory.\n    \n    Args:\n        payload: Hook payload containing tool information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"post_tool_use.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PostToolUse\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": payload.get(\"tool_response\", {}),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\post_tool_use.py", "oldString": "        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()", "newString": "        sys.exit(1)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PostToolUse event to logs directory.\n    \n    Args:\n        payload: Hook payload containing tool information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"post_tool_use.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PostToolUse\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": payload.get(\"tool_response\", {}),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"requests>=2.31.0\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_git_checkpoints import process_tool_checkpoint\n\ndef main() -> None:\n    \"\"\"\n    Simplified PostToolUse hook handler - YouTuber's approach.\n    Directly processes smart git checkpoints from transcript data.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    except Exception as e:\n        print(f\"Input error: {e}\", file=sys.stderr)\n        sys.exit(1)\n    \n    try:\n        # Log tool usage to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process smart checkpoint creation directly from transcript\n        checkpoint_success = process_tool_checkpoint(payload)\n        \n        # Exit with success\n        sys.exit(0 if checkpoint_success else 1)\n        \n    except Exception as e:\n        print(f\"Hook processing error: {e}\", file=sys.stderr)\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 41, "oldLines": 5, "newStart": 41, "newLines": 39, "lines": ["         print(f\"Hook processing error: {e}\", file=sys.stderr)", "         sys.exit(1)", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log PostToolUse event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing tool information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"post_tool_use.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"PostToolUse\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),", "+            \"tool_input\": payload.get(\"tool_input\", {}),", "+            \"tool_response\": payload.get(\"tool_response\", {}),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"PostToolUse\")", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:01:22.858440", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification", "old_string": "import json\nimport sys\nfrom utils.smart_voice_notify import process_stop_notification", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "import json\nimport sys\nfrom utils.smart_voice_notify import process_stop_notification", "newString": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nfrom utils.smart_voice_notify import process_stop_notification\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 10, "oldLines": 6, "newStart": 10, "newLines": 8, "lines": [" ", " import json", " import sys", "+import pathlib", "+import datetime", " from utils.smart_voice_notify import process_stop_notification", " ", " def main() -> None:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:01:44.439815", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "new_string": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\stop.py", "oldString": "    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "newString": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Stop event to logs directory.\n    \n    Args:\n        payload: Hook payload containing session information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"stop.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Stop\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"google-generativeai>=0.5.0\",\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_stop_notification\n\ndef main() -> None:\n    \"\"\"\n    Simple Stop hook handler that delegates to smart voice utilities.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create basic payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Stop\"}\n    except Exception as e:\n        # Handle any other input errors  \n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}\n    \n    # Process using utility functions\n    process_stop_notification(payload)\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 28, "oldLines": 8, "newStart": 28, "newLines": 44, "lines": ["         # Handle any other input errors  ", "         payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Stop\"}", "     ", "+    # Log to logs directory", "+    log_to_logs_directory(payload)", "+    ", "     # Process using utility functions", "     process_stop_notification(payload)", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log Stop event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing session information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"stop.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"Stop\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"stop_hook_active\": payload.get(\"stop_hook_active\", False),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"Stop\"),", "+            \"error\": payload.get(\"error\")  # Include any errors that occurred", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:02.254334", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification", "old_string": "import json\nimport sys\nimport pathlib\nfrom utils.smart_voice_notify import process_notification", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "oldString": "import json\nimport sys\nimport pathlib\nfrom utils.smart_voice_notify import process_notification", "newString": "import json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nfrom utils.smart_voice_notify import process_notification\n\ndef main() -> None:\n    \"\"\"\n    Simplified notification handler - just voice notifications.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create error payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Notification\"}\n    except Exception as e:\n        # Handle any other input errors\n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Notification\"}\n    \n    # Validate that this is a Notification hook event\n    if payload.get(\"hook_event_name\") != \"Notification\" and \"transcript_path\" not in payload:\n        # If it's not a proper notification, try to process anyway\n        payload[\"hook_event_name\"] = \"Notification\"\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 10, "oldLines": 6, "newStart": 10, "newLines": 7, "lines": [" import json", " import sys", " import pathlib", "+import datetime", " from utils.smart_voice_notify import process_notification", " ", " def main() -> None:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:11.230541", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "new_string": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "old_string": "    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "oldString": "    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "newString": "    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification\n\ndef main() -> None:\n    \"\"\"\n    Simplified notification handler - just voice notifications.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create error payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Notification\"}\n    except Exception as e:\n        # Handle any other input errors\n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Notification\"}\n    \n    # Validate that this is a Notification hook event\n    if payload.get(\"hook_event_name\") != \"Notification\" and \"transcript_path\" not in payload:\n        # If it's not a proper notification, try to process anyway\n        payload[\"hook_event_name\"] = \"Notification\"\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 32, "oldLines": 6, "newStart": 32, "newLines": 9, "lines": ["         # If it's not a proper notification, try to process anyway", "         payload[\"hook_event_name\"] = \"Notification\"", "     ", "+    # Log to logs directory", "+    log_to_logs_directory(payload)", "+    ", "     try:", "         # Process with voice notification system", "         process_notification(payload)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:23.331339", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "new_string": "            # If even basic TTS fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Notification event to logs directory.\n    \n    Args:\n        payload: Hook payload containing notification information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"notifications.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Notification\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"message\": payload.get(\"message\", \"\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Notification\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\notifications.py", "oldString": "            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "newString": "            # If even basic TTS fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log Notification event to logs directory.\n    \n    Args:\n        payload: Hook payload containing notification information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"notifications.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"Notification\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"message\": payload.get(\"message\", \"\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"Notification\"),\n            \"error\": payload.get(\"error\")  # Include any errors that occurred\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\nfrom utils.smart_voice_notify import process_notification\n\ndef main() -> None:\n    \"\"\"\n    Simplified notification handler - just voice notifications.\n    \"\"\"\n    try:\n        # Read JSON payload from stdin\n        payload = json.load(sys.stdin)\n    except json.JSONDecodeError as e:\n        # If JSON parsing fails, create error payload\n        payload = {\"error\": f\"JSON decode error: {e}\", \"hook_event_name\": \"Notification\"}\n    except Exception as e:\n        # Handle any other input errors\n        payload = {\"error\": f\"Input error: {e}\", \"hook_event_name\": \"Notification\"}\n    \n    # Validate that this is a Notification hook event\n    if payload.get(\"hook_event_name\") != \"Notification\" and \"transcript_path\" not in payload:\n        # If it's not a proper notification, try to process anyway\n        payload[\"hook_event_name\"] = \"Notification\"\n    \n    # Log to logs directory\n    log_to_logs_directory(payload)\n    \n    try:\n        # Process with voice notification system\n        process_notification(payload)\n        \n    except Exception as e:\n        # Fallback if processing fails - at least say something\n        import pyttsx3\n        try:\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Claude notification error\")\n            eng.runAndWait()\n        except:\n            # If even basic TTS fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 51, "oldLines": 5, "newStart": 51, "newLines": 38, "lines": ["             # If even basic TTS fails, just exit silently", "             pass", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log Notification event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing notification information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"notifications.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"Notification\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"message\": payload.get(\"message\", \"\"),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"Notification\"),", "+            \"error\": payload.get(\"error\")  # Include any errors that occurred", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:39.930977", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "import json\nimport sys\nimport pathlib\nimport datetime", "old_string": "import json\nimport sys\nimport pathlib", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "import json\nimport sys\nimport pathlib", "newString": "import json\nimport sys\nimport pathlib\nimport datetime", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 10, "oldLines": 6, "newStart": 10, "newLines": 7, "lines": [" import json", " import sys", " import pathlib", "+import datetime", " ", " # Add utils directory to Python path for importing smart_voice_notify", " utils_path = pathlib.Path(__file__).parent / \"utils\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:02:52.099740", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "old_string": "        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "newString": "        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 53, "oldLines": 6, "newStart": 53, "newLines": 9, "lines": ["         else:", "             payload = json.loads(payload_json)", "         ", "+        # Log to logs directory", "+        log_to_logs_directory(payload)", "+        ", "         # Process the compact notification using the smart voice notify system", "         process_compact_notification(payload)", "         "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:03:07.752700", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "new_string": "            # If all else fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PreCompact event to logs directory.\n    \n    Args:\n        payload: Hook payload containing compact information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"pre_compact.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PreCompact\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"trigger\": payload.get(\"trigger\", \"unknown\"),\n            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),\n            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "old_string": "            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\pre_compact.py", "oldString": "            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "newString": "            # If all else fails, just exit silently\n            pass\n\ndef log_to_logs_directory(payload) -> None:\n    \"\"\"\n    Log PreCompact event to logs directory.\n    \n    Args:\n        payload: Hook payload containing compact information\n    \"\"\"\n    try:\n        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n        logs_dir.mkdir(exist_ok=True)\n        \n        log_file = logs_dir / \"pre_compact.json\"\n        \n        timestamp = datetime.datetime.now().isoformat()\n        \n        log_entry = {\n            \"timestamp\": timestamp,\n            \"event\": \"PreCompact\",\n            \"session_id\": payload.get(\"session_id\", \"unknown\"),\n            \"trigger\": payload.get(\"trigger\", \"unknown\"),\n            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),\n            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),\n            \"cwd\": payload.get(\"cwd\", \"unknown\"),\n            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),\n            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")\n        }\n        \n        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{json.dumps(log_entry)}\\n\")\n            \n    except Exception as e:\n        # Don't fail the hook if logging fails\n        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)\n\nif __name__ == \"__main__\":\n    main()", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = [\n#   \"pyttsx3>=2.99\",\n#   \"pywin32>=306\",\n# ]\n# ///\n\nimport json\nimport sys\nimport pathlib\nimport datetime\n\n# Add utils directory to Python path for importing smart_voice_notify\nutils_path = pathlib.Path(__file__).parent / \"utils\"\nsys.path.insert(0, str(utils_path))\n\ntry:\n    from smart_voice_notify import process_compact_notification\nexcept ImportError as e:\n    # Fallback if import fails\n    import pyttsx3\n    def fallback_speak(text: str):\n        eng = pyttsx3.init()\n        eng.setProperty(\"rate\", 185)\n        eng.say(text)\n        eng.runAndWait()\n    \n    def process_compact_notification(payload: dict):\n        # Simple fallback implementation\n        compact_type = \"automatic\"\n        if \"manual\" in str(payload).lower() or \"user\" in str(payload).lower():\n            compact_type = \"manual\"\n        \n        if compact_type == \"automatic\":\n            fallback_speak(\"Automatic compacting the conversation\")\n        else:\n            fallback_speak(\"Manual compacting the conversation\")\n\ndef main():\n    \"\"\"\n    PreCompact hook entry point.\n    Called when Claude is about to compact the conversation.\n    \"\"\"\n    try:\n        # Read the payload from stdin\n        payload_json = sys.stdin.read().strip()\n        \n        if not payload_json:\n            # No payload, default to automatic\n            payload = {\"compact_type\": \"automatic\"}\n        else:\n            payload = json.loads(payload_json)\n        \n        # Log to logs directory\n        log_to_logs_directory(payload)\n        \n        # Process the compact notification using the smart voice notify system\n        process_compact_notification(payload)\n        \n    except json.JSONDecodeError:\n        # Fallback for invalid JSON\n        process_compact_notification({\"compact_type\": \"automatic\"})\n    except Exception as e:\n        # Ultimate fallback - just speak something\n        try:\n            import pyttsx3\n            eng = pyttsx3.init()\n            eng.setProperty(\"rate\", 185)\n            eng.say(\"Compacting the conversation\")\n            eng.runAndWait()\n        except:\n            # If all else fails, just exit silently\n            pass\n\nif __name__ == \"__main__\":\n    main()", "structuredPatch": [{"oldStart": 74, "oldLines": 5, "newStart": 74, "newLines": 39, "lines": ["             # If all else fails, just exit silently", "             pass", " ", "+def log_to_logs_directory(payload) -> None:", "+    \"\"\"", "+    Log PreCompact event to logs directory.", "+    ", "+    Args:", "+        payload: Hook payload containing compact information", "+    \"\"\"", "+    try:", "+        logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "+        logs_dir.mkdir(exist_ok=True)", "+        ", "+        log_file = logs_dir / \"pre_compact.json\"", "+        ", "+        timestamp = datetime.datetime.now().isoformat()", "+        ", "+        log_entry = {", "+            \"timestamp\": timestamp,", "+            \"event\": \"PreCompact\",", "+            \"session_id\": payload.get(\"session_id\", \"unknown\"),", "+            \"trigger\": payload.get(\"trigger\", \"unknown\"),", "+            \"custom_instructions\": payload.get(\"custom_instructions\", \"\"),", "+            \"compact_type\": payload.get(\"compact_type\", \"unknown\"),", "+            \"cwd\": payload.get(\"cwd\", \"unknown\"),", "+            \"transcript_path\": payload.get(\"transcript_path\", \"unknown\"),", "+            \"hook_event_name\": payload.get(\"hook_event_name\", \"PreCompact\")", "+        }", "+        ", "+        with open(log_file, \"a\", encoding=\"utf-8\") as f:", "+            f.write(f\"{json.dumps(log_entry)}\\n\")", "+            ", "+    except Exception as e:", "+        # Don't fail the hook if logging fails", "+        print(f\"Failed to log to logs directory: {e}\", file=sys.stderr)", "+", " if __name__ == \"__main__\":", "     main()", "\\ No newline at end of file"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:05:23.666519", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "old_string": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")", "newString": "    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 19, "oldLines": 6, "newStart": 19, "newLines": 7, "lines": ["     def __init__(self):", "         self.claude_executable = CLAUDE_EXECUTABLE", "         self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")", "+        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")", "     ", "     def process_checkpoint(self, payload: Dict[str, Any]) -> bool:", "         \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:05:33.527420", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))", "old_string": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")", "newString": "            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 38, "oldLines": 6, "newStart": 38, "newLines": 9, "lines": ["             # Add session_id to context for comprehensive logging", "             session_context[\"session_id\"] = payload.get(\"session_id\")", "             ", "+            # Load tool usage history from logs", "+            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))", "+            ", "             # Analyze git changes", "             git_context = self._analyze_git_changes()", "             "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:05:41.950030", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)", "old_string": "            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)", "newString": "            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 49, "oldLines": 8, "newStart": 49, "newLines": 8, "lines": ["                 self._log_debug(\"No git changes detected, skipping checkpoint\")", "                 return True", "             ", "-            # Generate intelligent commit message", "-            commit_message = self._generate_smart_commit(tool_context, session_context, git_context)", "+            # Generate intelligent commit message with tool history", "+            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)", "             ", "             # Create the checkpoint commit", "             return self._create_commit(commit_message)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:06:26.806273", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "old_string": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "newString": "            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 160, "oldLines": 6, "newStart": 160, "newLines": 160, "lines": ["             self._log_debug(f\"Transcript reading error: {e}\")", "             return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}", "     ", "+    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:", "+        \"\"\"Load recent tool usage history from logs directory.\"\"\"", "+        try:", "+            tool_history = {", "+                \"pre_tool_use\": [],", "+                \"post_tool_use\": [],", "+                \"recent_tools\": [],", "+                \"file_operations\": [],", "+                \"session_summary\": \"\"", "+            }", "+            ", "+            # Read recent tool usage logs (last 10 entries per log file)", "+            log_files = [", "+                \"pre_tool_use.json\",", "+                \"post_tool_use.json\"", "+            ]", "+            ", "+            current_session_tools = []", "+            all_recent_tools = []", "+            ", "+            for log_file in log_files:", "+                log_path = self.logs_dir / log_file", "+                if log_path.exists():", "+                    try:", "+                        with open(log_path, 'r', encoding='utf-8') as f:", "+                            lines = f.readlines()", "+                            ", "+                        # Get last 10 entries", "+                        recent_lines = lines[-10:] if len(lines) > 10 else lines", "+                        ", "+                        for line in recent_lines:", "+                            try:", "+                                entry = json.loads(line.strip())", "+                                all_recent_tools.append(entry)", "+                                ", "+                                # Filter current session if session_id available", "+                                if session_id and entry.get(\"session_id\") == session_id:", "+                                    current_session_tools.append(entry)", "+                                    ", "+                                # Track file operations specifically", "+                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:", "+                                    tool_input = entry.get(\"tool_input\", {})", "+                                    file_path = tool_input.get(\"file_path\", \"\")", "+                                    if file_path:", "+                                        tool_history[\"file_operations\"].append({", "+                                            \"tool\": entry.get(\"tool_name\"),", "+                                            \"file\": pathlib.Path(file_path).name,", "+                                            \"timestamp\": entry.get(\"timestamp\"),", "+                                            \"operation\": self._classify_file_operation(tool_input)", "+                                        })", "+                                        ", "+                            except json.JSONDecodeError:", "+                                continue", "+                                ", "+                    except Exception as e:", "+                        self._log_debug(f\"Error reading {log_file}: {e}\")", "+                        continue", "+            ", "+            # Use current session tools if available, otherwise recent tools", "+            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]", "+            ", "+            # Analyze tool patterns", "+            tool_summary = self._analyze_tool_patterns(relevant_tools)", "+            ", "+            tool_history.update({", "+                \"recent_tools\": relevant_tools,", "+                \"session_summary\": tool_summary,", "+                \"total_operations\": len(relevant_tools),", "+                \"file_count\": len(tool_history[\"file_operations\"])", "+            })", "+            ", "+            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")", "+            ", "+            return tool_history", "+            ", "+        except Exception as e:", "+            self._log_debug(f\"Tool history loading error: {e}\")", "+            return {", "+                \"recent_tools\": [],", "+                \"file_operations\": [],", "+                \"session_summary\": \"tool history unavailable\",", "+                \"total_operations\": 0,", "+                \"file_count\": 0", "+            }", "+    ", "+    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:", "+        \"\"\"Classify the type of file operation based on tool input.\"\"\"", "+        if \"new_string\" in tool_input and \"old_string\" in tool_input:", "+            old_str = tool_input.get(\"old_string\", \"\")", "+            new_str = tool_input.get(\"new_string\", \"\")", "+            ", "+            if not old_str:", "+                return \"create\"", "+            elif not new_str:", "+                return \"delete\"", "+            else:", "+                # Analyze the nature of the change", "+                if len(new_str) > len(old_str) * 2:", "+                    return \"expand\"", "+                elif len(new_str) < len(old_str) * 0.5:", "+                    return \"shrink\"", "+                else:", "+                    return \"modify\"", "+        elif \"content\" in tool_input:", "+            return \"write\"", "+        else:", "+            return \"edit\"", "+    ", "+    def _analyze_tool_patterns(self, tools: list) -> str:", "+        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"", "+        if not tools:", "+            return \"no recent activity\"", "+            ", "+        # Count tool types", "+        tool_counts = {}", "+        file_operations = []", "+        ", "+        for tool in tools:", "+            tool_name = tool.get(\"tool_name\", \"unknown\")", "+            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1", "+            ", "+            # Track file operations", "+            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:", "+                tool_input = tool.get(\"tool_input\", {})", "+                file_path = tool_input.get(\"file_path\", \"\")", "+                if file_path:", "+                    file_operations.append(pathlib.Path(file_path).name)", "+        ", "+        # Determine primary activity", "+        if tool_counts.get(\"Write\", 0) >= 2:", "+            activity = \"creating files\"", "+        elif tool_counts.get(\"Edit\", 0) >= 2:", "+            activity = \"editing files\"", "+        elif tool_counts.get(\"MultiEdit\", 0) >= 1:", "+            activity = \"multi-file editing\"", "+        elif tool_counts.get(\"Read\", 0) >= 3:", "+            activity = \"reading/analyzing code\"", "+        elif tool_counts.get(\"Bash\", 0) >= 2:", "+            activity = \"executing commands\"", "+        else:", "+            activity = \"mixed operations\"", "+            ", "+        # Add file context if available", "+        unique_files = list(set(file_operations))", "+        if unique_files:", "+            if len(unique_files) == 1:", "+                activity += f\" on {unique_files[0]}\"", "+            elif len(unique_files) <= 3:", "+                activity += f\" on {', '.join(unique_files)}\"", "+            else:", "+                activity += f\" on {len(unique_files)} files\"", "+                ", "+        return activity", "+    ", "     def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:", "         \"\"\"Extract filename and path info from tool input.\"\"\"", "         file_path = tool_input.get(\"file_path\", \"\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:06:52.391085", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:", "old_string": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:", "newString": "    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 386, "oldLines": 7, "newStart": 386, "newLines": 8, "lines": ["     ", "     def _generate_smart_commit(self, tool_context: Dict[str, Any], ", "                               session_context: Dict[str, Any], ", "-                              git_context: Dict[str, Any]) -> str:", "+                              git_context: Dict[str, Any],", "+                              tool_history: Dict[str, Any]) -> str:", "         \"\"\"Generate intelligent commit message using AI analysis.\"\"\"", "         ", "         prompt = self._build_ai_prompt(tool_context, session_context, git_context)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:07:06.660682", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "old_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context)", "newString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 390, "oldLines": 7, "newStart": 390, "newLines": 7, "lines": ["                               tool_history: Dict[str, Any]) -> str:", "         \"\"\"Generate intelligent commit message using AI analysis.\"\"\"", "         ", "-        prompt = self._build_ai_prompt(tool_context, session_context, git_context)", "+        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "         ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:07:50.909928", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:", "old_string": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:", "newString": "    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 410, "oldLines": 7, "newStart": 410, "newLines": 8, "lines": ["     ", "     def _build_ai_prompt(self, tool_context: Dict[str, Any], ", "                         session_context: Dict[str, Any], ", "-                        git_context: Dict[str, Any]) -> str:", "+                        git_context: Dict[str, Any],", "+                        tool_history: Dict[str, Any]) -> str:", "         \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"", "         ", "         # Extract detailed context"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:08:03.215620", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "old_string": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "newString": "        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 431, "oldLines": 6, "newStart": 431, "newLines": 20, "lines": ["         if old_string and new_string:", "             change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"", "         ", "+        # Extract tool history context", "+        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")", "+        total_ops = tool_history.get(\"total_operations\", 0)", "+        file_ops = tool_history.get(\"file_operations\", [])", "+        ", "+        # Build tool history summary", "+        tool_context_summary = \"\"", "+        if file_ops:", "+            recent_file_ops = file_ops[-3:]  # Last 3 file operations", "+            ops_summary = []", "+            for op in recent_file_ops:", "+                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")", "+            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"", "+        ", "         prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", " ", " USER'S ORIGINAL REQUEST: {user_intent}"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:08:13.315760", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}", "old_string": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}", "newString": "CODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 455, "oldLines": 6, "newStart": 455, "newLines": 11, "lines": [" - Operation: {tool_name} operation", " - Specific change: {change_description}", " ", "+SESSION CONTEXT:", "+- Activity pattern: {session_activity}", "+- Total operations: {total_ops}", "+- Tool history: {tool_context_summary}", "+", " ANALYSIS REQUIRED:", " 1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)", " 2. What component/scope is affected? (auth/api/ui/db/parser/etc)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:08:23.799039", "event": "PostToolUse", "session_id": "18e8b81b-5937-46cf-9a42-ed36667aa212", "tool_name": "Write", "tool_input": {"file_path": "C:\\Users\\NATH\\Documents\\1ACode-WEBSITE\\minrights\\minrights-chatbot\\simple_test.py", "content": "print(\"Hello, this is a test file!\")"}, "tool_response": {"type": "create", "filePath": "C:\\Users\\NATH\\Documents\\1ACode-WEBSITE\\minrights\\minrights-chatbot\\simple_test.py", "content": "print(\"Hello, this is a test file!\")", "structuredPatch": []}, "cwd": "C:\\Users\\NATH\\Documents\\1ACode-WEBSITE\\minrights\\minrights-chatbot", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH-Documents-1ACode-WEBSITE-minrights-minrights-chatbot\\18e8b81b-5937-46cf-9a42-ed36667aa212.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:09:39.789437", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "old_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "newString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 574, "oldLines": 7, "newStart": 574, "newLines": 8, "lines": ["                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "                     from .llms import ask_concise", "-                    response = ask_concise(task_prompt)", "+                    # Use the full detailed prompt instead of the truncated task_prompt", "+                    response = ask_concise(prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Validate response is not a fallback"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:09:50.135544", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "old_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "newString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 392, "oldLines": 6, "newStart": 392, "newLines": 9, "lines": ["         ", "         prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "         ", "+        # Debug: Log the prompt being sent to LLM", "+        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")", "+        ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation", "             response = self._call_claude_task(prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:02.612940", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "old_string": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "newString": "            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                return {\n                    \"user_intent\": [\"no user messages found\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 150, "oldLines": 8, "newStart": 150, "newLines": 9, "lines": ["                 }", "             else:", "                 self._log_debug(\"No user messages found in transcript\")", "+                # Instead of generic message, try to infer from tool history", "                 return {", "-                    \"user_intent\": [\"no user messages found\"],", "+                    \"user_intent\": [\"file modification requested\"],", "                     \"recent_activity\": [],", "                     \"has_context\": False", "                 }"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:12.925108", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)", "old_string": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)", "newString": "            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                return cleaned_message\n            else:\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 404, "oldLines": 8, "newStart": 404, "newLines": 16, "lines": ["             # Clean and validate AI response", "             if commit_message and len(commit_message) > 5:", "                 cleaned_message = self._clean_commit_message(commit_message)", "-                return cleaned_message", "+                ", "+                # Check if it's actually a meaningful response vs fallback", "+                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():", "+                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")", "+                    return cleaned_message", "+                else:", "+                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")", "+                    return self._create_fallback_commit(tool_context, git_context)", "             else:", "+                self._log_debug(f\"LLM response too short: {commit_message}\")", "                 return self._create_fallback_commit(tool_context, git_context)", "                 ", "         except Exception as e:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:45.253428", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "old_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "newString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    # Use the full detailed prompt instead of the truncated task_prompt\n                    response = ask_concise(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 585, "oldLines": 16, "newStart": 585, "newLines": 16, "lines": ["                 # Use shell=True on Windows to handle .cmd files properly", "                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "-                    from .llms import ask_concise", "-                    # Use the full detailed prompt instead of the truncated task_prompt", "-                    response = ask_concise(prompt)", "+                    from .llms import ask", "+                    # Use the ask function with full prompt, not ask_concise", "+                    response = ask(prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Validate response is not a fallback", "-                    if response and response != \"AI response unavailable\" and len(response) > 10:", "+                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:", "                         return response", "                     else:", "-                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "+                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")", "                         ", "                 except ImportError:", "                     self._log_debug(\"LLM utilities not available, using fallback\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:10:56.582266", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "new_string": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "old_string": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "oldString": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "newString": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"  \n# dependencies = []\n# ///\n\n\"\"\"\nProduction LLM Client - Simple and Reliable\nUses pure claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\" approach\n\"\"\"\n\nimport subprocess\n\ndef ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass\n    \n    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Cost-efficient concise queries.\"\"\"\n    return ask(f\"Be very brief: {prompt}\")\n\n# This will work perfectly in production hooks!\nif __name__ == \"__main__\":\n    print(\"Production LLM Client Ready!\")\n    print(\"Usage: from utils.llms.production_client import ask, ask_concise\")", "structuredPatch": [{"oldStart": 29, "oldLines": 9, "newStart": 29, "newLines": 7, "lines": ["         pass", "     ", "     # Fallback for development/testing", "-    if \"commit\" in prompt.lower():", "-        return \"chore: update files\"", "-    elif \"2+2\" in prompt:", "+    if \"2+2\" in prompt:", "         return \"4\"", "     else:", "         return \"AI response unavailable\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:11:57.737345", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"", "old_string": "        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"", "newString": "        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:\n\nUSER'S ORIGINAL REQUEST: {user_intent}\n\nCODE CHANGE DETAILS:\n- File: {primary_file.get('file', 'unknown')}\n- Type: {primary_file.get('extension', '')} file\n- Operation: {tool_name} operation\n- Specific change: {change_description}\n\nSESSION CONTEXT:\n- Activity pattern: {session_activity}\n- Total operations: {total_ops}\n- Tool history: {tool_context_summary}\n\nANALYSIS REQUIRED:\n1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)\n2. What component/scope is affected? (auth/api/ui/db/parser/etc)\n3. What specific problem was solved or feature added?\n\nCOMMIT FORMAT:\n- Format: type(scope): specific description\n- Keep under 50 characters\n- Be precise about what changed\n- Use present tense (\"add\" not \"added\")\n\nEXAMPLES OF GOOD COMMITS:\n- \"fix(parser): handle invalid date formats\"\n- \"feat(auth): add JWT token validation\"  \n- \"refactor(pdf): extract parsing utilities\"\n- \"fix(validation): prevent null month values\"\n\nBased on the user's request and code changes, generate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 457, "oldLines": 39, "newStart": 457, "newLines": 27, "lines": ["                 ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")", "             tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"", "         ", "-        prompt = f\"\"\"You are an expert developer writing git commit messages. Generate a precise, conventional commit message based on this context:", "+        prompt = f\"\"\"Generate a git commit message using conventional commit format.", " ", "-USER'S ORIGINAL REQUEST: {user_intent}", "-", "-CODE CHANGE DETAILS:", "+Context:", "+- User request: {user_intent}", " - File: {primary_file.get('file', 'unknown')}", "-- Type: {primary_file.get('extension', '')} file", "-- Operation: {tool_name} operation", "-- Specific change: {change_description}", "+- Operation: {tool_name}", "+- Session activity: {session_activity}", "+- Change: {change_description}", " ", "-SESSION CONTEXT:", "-- Activity pattern: {session_activity}", "-- Total operations: {total_ops}", "-- Tool history: {tool_context_summary}", "+Rules:", "+- Format: type(scope): description", "+- Under 50 characters", "+- Present tense", "+- Types: feat, fix, refactor, docs, style, test, chore", " ", "-ANALYSIS REQUIRED:", "-1. What type of change is this? (feat/fix/refactor/docs/style/test/chore)", "-2. What component/scope is affected? (auth/api/ui/db/parser/etc)", "-3. What specific problem was solved or feature added?", "+Examples:", "+- feat(auth): add login validation", "+- fix(parser): handle null values", "+- refactor(ui): extract components", " ", "-COMMIT FORMAT:", "-- Format: type(scope): specific description", "-- Keep under 50 characters", "-- Be precise about what changed", "-- Use present tense (\"add\" not \"added\")", "-", "-EXAMPLES OF GOOD COMMITS:", "-- \"fix(parser): handle invalid date formats\"", "-- \"feat(auth): add JWT token validation\"  ", "-- \"refactor(pdf): extract parsing utilities\"", "-- \"fix(validation): prevent null month values\"", "-", "-Based on the user's request and code changes, generate ONLY the commit message:\"\"\"", "+Generate ONLY the commit message:\"\"\"", "         ", "         return prompt", "     "]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:12:57.129715", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "new_string": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break\n                \n    except Exception as e:\n        # Log the error for debugging\n        print(f\"LLM Error: {e}\", flush=True)", "old_string": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "oldString": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass", "newString": "def ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break\n                \n    except Exception as e:\n        # Log the error for debugging\n        print(f\"LLM Error: {e}\", flush=True)", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"  \n# dependencies = []\n# ///\n\n\"\"\"\nProduction LLM Client - Simple and Reliable\nUses pure claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\" approach\n\"\"\"\n\nimport subprocess\n\ndef ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Pure command approach - works in production\n        result = subprocess.run([\n            'claude', '-p', '--model', model, prompt\n        ], capture_output=True, text=True, timeout=30)\n        \n        if result.returncode == 0:\n            return result.stdout.strip()\n            \n    except:\n        pass\n    \n    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Cost-efficient concise queries.\"\"\"\n    return ask(f\"Be very brief: {prompt}\")\n\n# This will work perfectly in production hooks!\nif __name__ == \"__main__\":\n    print(\"Production LLM Client Ready!\")\n    print(\"Usage: from utils.llms.production_client import ask, ask_concise\")", "structuredPatch": [{"oldStart": 17, "oldLines": 16, "newStart": 17, "newLines": 25, "lines": ["     Works in production environments (PowerShell, cmd, normal Python)", "     \"\"\"", "     try:", "-        # Pure command approach - works in production", "-        result = subprocess.run([", "-            'claude', '-p', '--model', model, prompt", "-        ], capture_output=True, text=True, timeout=30)", "+        # Try different claude executable names for Windows", "+        claude_commands = ['claude', 'claude.exe', 'claude.cmd']", "         ", "-        if result.returncode == 0:", "-            return result.stdout.strip()", "-            ", "-    except:", "-        pass", "+        for cmd in claude_commands:", "+            try:", "+                result = subprocess.run([", "+                    cmd, '-p', '--model', model, prompt", "+                ], capture_output=True, text=True, timeout=30, shell=True)", "+                ", "+                if result.returncode == 0:", "+                    return result.stdout.strip()", "+            except FileNotFoundError:", "+                continue", "+            except:", "+                break", "+                ", "+    except Exception as e:", "+        # Log the error for debugging", "+        print(f\"LLM Error: {e}\", flush=True)", "     ", "     # Fallback for development/testing", "     if \"2+2\" in prompt:"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:13:16.096231", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}", "old_string": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}", "newString": "    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5\n            )\n            if git_check.returncode != 0:\n                return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 330, "oldLines": 13, "newStart": 330, "newLines": 40, "lines": ["     def _analyze_git_changes(self) -> Dict[str, Any]:", "         \"\"\"Analyze current git repository changes.\"\"\"", "         try:", "+            # Try to find git repository from working directory", "+            working_dir = pathlib.Path.cwd()", "+            ", "             # Check if we're in a git repository", "             git_check = subprocess.run(", "                 [\"git\", \"rev-parse\", \"--git-dir\"], ", "-                capture_output=True, text=True, timeout=5", "+                capture_output=True, text=True, timeout=5, cwd=working_dir", "             )", "+            ", "+            # If not in git repo, try to find one by looking in common project locations", "             if git_check.returncode != 0:", "-                return {\"status\": \"no_git\", \"files\": []}", "+                # Try common project locations", "+                potential_dirs = [", "+                    working_dir,", "+                    working_dir.parent,", "+                    pathlib.Path.home() / \"Documents\",", "+                    pathlib.Path.home() / \"Projects\",", "+                ]", "+                ", "+                git_dir = None", "+                for check_dir in potential_dirs:", "+                    if check_dir.exists():", "+                        git_check = subprocess.run(", "+                            [\"git\", \"rev-parse\", \"--git-dir\"], ", "+                            capture_output=True, text=True, timeout=5, cwd=check_dir", "+                        )", "+                        if git_check.returncode == 0:", "+                            git_dir = check_dir", "+                            working_dir = git_dir", "+                            break", "+                ", "+                if not git_dir:", "+                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")", "+                    return {\"status\": \"no_git\", \"files\": []}", "             ", "             # Get git status", "             status_result = subprocess.run("]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:25:46.018956", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "old_string": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "newString": "                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask\n                    # Use the ask function with full prompt, not ask_concise\n                    response = ask(prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 600, "oldLines": 16, "newStart": 600, "newLines": 15, "lines": ["                 # Use shell=True on Windows to handle .cmd files properly", "                 # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)", "                 try:", "-                    from .llms import ask", "-                    # Use the ask function with full prompt, not ask_concise", "-                    response = ask(prompt)", "+                    from .llms import ask_concise", "+                    response = ask_concise(task_prompt)", "                     self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")", "                     ", "                     # Validate response is not a fallback", "-                    if response and response != \"AI response unavailable\" and response != \"chore: update files\" and len(response) > 10:", "+                    if response and response != \"AI response unavailable\" and len(response) > 10:", "                         return response", "                     else:", "-                        self._log_debug(f\"LLM response appears to be fallback: {response}, trying original method\")", "+                        self._log_debug(\"LLM response appears to be fallback, trying original method\")", "                         ", "                 except ImportError:", "                     self._log_debug(\"LLM utilities not available, using fallback\")"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:25:56.910126", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "new_string": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "old_string": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\llms\\production_client.py", "oldString": "    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "newString": "    # Fallback for development/testing\n    if \"commit\" in prompt.lower():\n        return \"chore: update files\"\n    elif \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"  \n# dependencies = []\n# ///\n\n\"\"\"\nProduction LLM Client - Simple and Reliable\nUses pure claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\" approach\n\"\"\"\n\nimport subprocess\n\ndef ask(prompt: str, model: str = \"claude-3-5-haiku-20241022\") -> str:\n    \"\"\"\n    Simple ask using: claude -p --model claude-3-5-haiku-20241022 \"$PROMPT\"\n    Works in production environments (PowerShell, cmd, normal Python)\n    \"\"\"\n    try:\n        # Try different claude executable names for Windows\n        claude_commands = ['claude', 'claude.exe', 'claude.cmd']\n        \n        for cmd in claude_commands:\n            try:\n                result = subprocess.run([\n                    cmd, '-p', '--model', model, prompt\n                ], capture_output=True, text=True, timeout=30, shell=True)\n                \n                if result.returncode == 0:\n                    return result.stdout.strip()\n            except FileNotFoundError:\n                continue\n            except:\n                break\n                \n    except Exception as e:\n        # Log the error for debugging\n        print(f\"LLM Error: {e}\", flush=True)\n    \n    # Fallback for development/testing\n    if \"2+2\" in prompt:\n        return \"4\"\n    else:\n        return \"AI response unavailable\"\n\ndef ask_concise(prompt: str) -> str:\n    \"\"\"Cost-efficient concise queries.\"\"\"\n    return ask(f\"Be very brief: {prompt}\")\n\n# This will work perfectly in production hooks!\nif __name__ == \"__main__\":\n    print(\"Production LLM Client Ready!\")\n    print(\"Usage: from utils.llms.production_client import ask, ask_concise\")", "structuredPatch": [{"oldStart": 38, "oldLines": 7, "newStart": 38, "newLines": 9, "lines": ["         print(f\"LLM Error: {e}\", flush=True)", "     ", "     # Fallback for development/testing", "-    if \"2+2\" in prompt:", "+    if \"commit\" in prompt.lower():", "+        return \"chore: update files\"", "+    elif \"2+2\" in prompt:", "         return \"4\"", "     else:", "         return \"AI response unavailable\""]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
{"timestamp": "2025-07-20T00:26:09.494415", "event": "PostToolUse", "session_id": "156a302f-9590-46e8-9e0f-1b3b6d31d18e", "tool_name": "Edit", "tool_input": {"file_path": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "new_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "old_string": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "replace_all": false}, "tool_response": {"filePath": "C:\\Users\\NATH\\.claude\\hooks\\utils\\smart_git_checkpoints.py", "oldString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:", "newString": "        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        try:", "originalFile": "#!/usr/bin/env -S uv run --script\n# /// script\n# requires-python = \">=3.11\"\n# dependencies = []\n# ///\n\nimport json\nimport subprocess\nimport pathlib\nimport datetime\nimport tempfile\nfrom typing import Dict, Any, Tuple, Optional\n\nCLAUDE_EXECUTABLE = \"claude\" \n\nclass SmartGitCheckpoints:\n    \"\"\"AI-powered git checkpointing system for Claude Code sessions.\"\"\"\n    \n    def __init__(self):\n        self.claude_executable = CLAUDE_EXECUTABLE\n        self.debug_log = pathlib.Path(\"C:/Users/NATH/.claude/hooks/debug.log\")\n        self.logs_dir = pathlib.Path(\"C:/Users/NATH/.claude/logs\")\n    \n    def process_checkpoint(self, payload: Dict[str, Any]) -> bool:\n        \"\"\"Main checkpoint processing function called by post_tool_use.py\"\"\"\n        \n        try:\n            # Extract tool context\n            tool_context = self._extract_tool_context(payload)\n            \n            # Only checkpoint file-changing tools\n            if not self._should_checkpoint(tool_context):\n                self._log_debug(f\"Skipping checkpoint for tool: {tool_context.get('tool_name')}\")\n                return True\n            \n            # Extract session context from transcript\n            session_context = self._extract_session_context(payload)\n            # Add session_id to context for comprehensive logging\n            session_context[\"session_id\"] = payload.get(\"session_id\")\n            \n            # Load tool usage history from logs\n            tool_history = self._load_tool_usage_history(payload.get(\"session_id\"))\n            \n            # Analyze git changes\n            git_context = self._analyze_git_changes()\n            \n            # Skip if no actual changes\n            if git_context.get(\"status\") == \"no_changes\":\n                self._log_debug(\"No git changes detected, skipping checkpoint\")\n                return True\n            \n            # Generate intelligent commit message with tool history\n            commit_message = self._generate_smart_commit(tool_context, session_context, git_context, tool_history)\n            \n            # Create the checkpoint commit\n            return self._create_commit(commit_message)\n            \n        except Exception as e:\n            self._log_debug(f\"Checkpoint processing error: {e}\")\n            return False\n    \n    def _extract_tool_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract tool usage context from hook payload.\"\"\"\n        tool_response = payload.get(\"tool_response\", {})\n        \n        # Check for explicit success field first (Claude Code format)\n        if isinstance(tool_response, dict) and \"success\" in tool_response:\n            success = tool_response.get(\"success\", False)\n        elif isinstance(tool_response, dict) and \"filePath\" in tool_response:\n            # Edit/Write tools return {'filePath': '...'} on success\n            success = True\n        else:\n            # Fallback: check for error indicators\n            tool_response_str = str(tool_response).lower()\n            has_errors = any(err in tool_response_str for err in [\"error\", \"failed\", \"exception\", \"denied\"])\n            success = not has_errors\n        \n        context = {\n            \"tool_name\": payload.get(\"tool_name\", \"unknown\"),\n            \"tool_input\": payload.get(\"tool_input\", {}),\n            \"tool_response\": tool_response,\n            \"success\": success\n        }\n        \n        # Debug logging\n        self._log_debug(f\"Tool context: {context['tool_name']}, success: {success}, response: {str(tool_response)[:100]}...\")\n        \n        return context\n    \n    def _should_checkpoint(self, tool_context: Dict[str, Any]) -> bool:\n        \"\"\"Determine if this tool usage should trigger a checkpoint.\"\"\"\n        file_changing_tools = [\"Write\", \"Edit\", \"MultiEdit\"]\n        tool_name = tool_context.get(\"tool_name\", \"\")\n        success = tool_context.get(\"success\", False)\n        \n        should_checkpoint = tool_name in file_changing_tools and success\n        \n        self._log_debug(f\"Checkpoint decision: tool={tool_name}, success={success}, should_checkpoint={should_checkpoint}\")\n        \n        return should_checkpoint\n    \n    def _extract_session_context(self, payload: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Extract user intent directly from Claude Code transcript - YouTuber's approach.\"\"\"\n        transcript_path = pathlib.Path(payload.get(\"transcript_path\", \"\"))\n        \n        if not transcript_path.exists():\n            self._log_debug(f\"Transcript not found: {transcript_path}\")\n            return {\"user_intent\": [\"transcript not found\"], \"recent_activity\": []}\n        \n        try:\n            user_messages = []\n            \n            # Read transcript file directly (JSONL format like YouTuber)\n            with transcript_path.open(\"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n            \n            self._log_debug(f\"Reading transcript with {len(lines)} lines...\")\n            \n            # Parse recent entries (last 20 lines for performance)\n            for i, line in enumerate(reversed(lines[-20:])):\n                try:\n                    record = json.loads(line.strip())\n                    \n                    # Look for user messages in Claude Code format\n                    record_type = record.get(\"type\", \"\")\n                    if record_type == \"user\":\n                        content = record.get(\"content\", \"\")\n                        if isinstance(content, str) and len(content.strip()) > 15:\n                            clean_content = content.strip()\n                            user_messages.append(clean_content)\n                            self._log_debug(f\"Found user message: {clean_content[:80]}...\")\n                            if len(user_messages) >= 2:  # Get last 2 user messages\n                                break\n                                \n                except (json.JSONDecodeError, KeyError):\n                    continue\n            \n            if user_messages:\n                # Return most recent message or combine recent ones\n                if len(user_messages) == 1:\n                    intent = user_messages[0]\n                else:\n                    intent = \" | \".join(reversed(user_messages[-2:]))  # Last 2 messages\n                \n                self._log_debug(f\"Extracted user intent: {intent[:100]}...\")\n                return {\n                    \"user_intent\": [intent],\n                    \"recent_activity\": [],\n                    \"has_context\": True\n                }\n            else:\n                self._log_debug(\"No user messages found in transcript\")\n                # Instead of generic message, try to infer from tool history\n                return {\n                    \"user_intent\": [\"file modification requested\"],\n                    \"recent_activity\": [],\n                    \"has_context\": False\n                }\n            \n        except Exception as e:\n            self._log_debug(f\"Transcript reading error: {e}\")\n            return {\"user_intent\": [f\"error reading transcript: {e}\"], \"recent_activity\": []}\n    \n    def _load_tool_usage_history(self, session_id: str) -> Dict[str, Any]:\n        \"\"\"Load recent tool usage history from logs directory.\"\"\"\n        try:\n            tool_history = {\n                \"pre_tool_use\": [],\n                \"post_tool_use\": [],\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"\"\n            }\n            \n            # Read recent tool usage logs (last 10 entries per log file)\n            log_files = [\n                \"pre_tool_use.json\",\n                \"post_tool_use.json\"\n            ]\n            \n            current_session_tools = []\n            all_recent_tools = []\n            \n            for log_file in log_files:\n                log_path = self.logs_dir / log_file\n                if log_path.exists():\n                    try:\n                        with open(log_path, 'r', encoding='utf-8') as f:\n                            lines = f.readlines()\n                            \n                        # Get last 10 entries\n                        recent_lines = lines[-10:] if len(lines) > 10 else lines\n                        \n                        for line in recent_lines:\n                            try:\n                                entry = json.loads(line.strip())\n                                all_recent_tools.append(entry)\n                                \n                                # Filter current session if session_id available\n                                if session_id and entry.get(\"session_id\") == session_id:\n                                    current_session_tools.append(entry)\n                                    \n                                # Track file operations specifically\n                                if entry.get(\"tool_name\") in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                                    tool_input = entry.get(\"tool_input\", {})\n                                    file_path = tool_input.get(\"file_path\", \"\")\n                                    if file_path:\n                                        tool_history[\"file_operations\"].append({\n                                            \"tool\": entry.get(\"tool_name\"),\n                                            \"file\": pathlib.Path(file_path).name,\n                                            \"timestamp\": entry.get(\"timestamp\"),\n                                            \"operation\": self._classify_file_operation(tool_input)\n                                        })\n                                        \n                            except json.JSONDecodeError:\n                                continue\n                                \n                    except Exception as e:\n                        self._log_debug(f\"Error reading {log_file}: {e}\")\n                        continue\n            \n            # Use current session tools if available, otherwise recent tools\n            relevant_tools = current_session_tools if current_session_tools else all_recent_tools[-5:]\n            \n            # Analyze tool patterns\n            tool_summary = self._analyze_tool_patterns(relevant_tools)\n            \n            tool_history.update({\n                \"recent_tools\": relevant_tools,\n                \"session_summary\": tool_summary,\n                \"total_operations\": len(relevant_tools),\n                \"file_count\": len(tool_history[\"file_operations\"])\n            })\n            \n            self._log_debug(f\"Loaded tool history: {len(relevant_tools)} operations, {len(tool_history['file_operations'])} file ops\")\n            \n            return tool_history\n            \n        except Exception as e:\n            self._log_debug(f\"Tool history loading error: {e}\")\n            return {\n                \"recent_tools\": [],\n                \"file_operations\": [],\n                \"session_summary\": \"tool history unavailable\",\n                \"total_operations\": 0,\n                \"file_count\": 0\n            }\n    \n    def _classify_file_operation(self, tool_input: Dict[str, Any]) -> str:\n        \"\"\"Classify the type of file operation based on tool input.\"\"\"\n        if \"new_string\" in tool_input and \"old_string\" in tool_input:\n            old_str = tool_input.get(\"old_string\", \"\")\n            new_str = tool_input.get(\"new_string\", \"\")\n            \n            if not old_str:\n                return \"create\"\n            elif not new_str:\n                return \"delete\"\n            else:\n                # Analyze the nature of the change\n                if len(new_str) > len(old_str) * 2:\n                    return \"expand\"\n                elif len(new_str) < len(old_str) * 0.5:\n                    return \"shrink\"\n                else:\n                    return \"modify\"\n        elif \"content\" in tool_input:\n            return \"write\"\n        else:\n            return \"edit\"\n    \n    def _analyze_tool_patterns(self, tools: list) -> str:\n        \"\"\"Analyze patterns in tool usage to understand the session intent.\"\"\"\n        if not tools:\n            return \"no recent activity\"\n            \n        # Count tool types\n        tool_counts = {}\n        file_operations = []\n        \n        for tool in tools:\n            tool_name = tool.get(\"tool_name\", \"unknown\")\n            tool_counts[tool_name] = tool_counts.get(tool_name, 0) + 1\n            \n            # Track file operations\n            if tool_name in [\"Write\", \"Edit\", \"MultiEdit\"]:\n                tool_input = tool.get(\"tool_input\", {})\n                file_path = tool_input.get(\"file_path\", \"\")\n                if file_path:\n                    file_operations.append(pathlib.Path(file_path).name)\n        \n        # Determine primary activity\n        if tool_counts.get(\"Write\", 0) >= 2:\n            activity = \"creating files\"\n        elif tool_counts.get(\"Edit\", 0) >= 2:\n            activity = \"editing files\"\n        elif tool_counts.get(\"MultiEdit\", 0) >= 1:\n            activity = \"multi-file editing\"\n        elif tool_counts.get(\"Read\", 0) >= 3:\n            activity = \"reading/analyzing code\"\n        elif tool_counts.get(\"Bash\", 0) >= 2:\n            activity = \"executing commands\"\n        else:\n            activity = \"mixed operations\"\n            \n        # Add file context if available\n        unique_files = list(set(file_operations))\n        if unique_files:\n            if len(unique_files) == 1:\n                activity += f\" on {unique_files[0]}\"\n            elif len(unique_files) <= 3:\n                activity += f\" on {', '.join(unique_files)}\"\n            else:\n                activity += f\" on {len(unique_files)} files\"\n                \n        return activity\n    \n    def _extract_file_info(self, tool_input: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Extract filename and path info from tool input.\"\"\"\n        file_path = tool_input.get(\"file_path\", \"\")\n        if file_path:\n            path_obj = pathlib.Path(file_path)\n            return {\n                \"filename\": path_obj.name,\n                \"directory\": path_obj.parent.name,\n                \"extension\": path_obj.suffix\n            }\n        return {\"filename\": \"unknown\", \"directory\": \"\", \"extension\": \"\"}\n    \n    def _analyze_git_changes(self) -> Dict[str, Any]:\n        \"\"\"Analyze current git repository changes.\"\"\"\n        try:\n            # Try to find git repository from working directory\n            working_dir = pathlib.Path.cwd()\n            \n            # Check if we're in a git repository\n            git_check = subprocess.run(\n                [\"git\", \"rev-parse\", \"--git-dir\"], \n                capture_output=True, text=True, timeout=5, cwd=working_dir\n            )\n            \n            # If not in git repo, try to find one by looking in common project locations\n            if git_check.returncode != 0:\n                # Try common project locations\n                potential_dirs = [\n                    working_dir,\n                    working_dir.parent,\n                    pathlib.Path.home() / \"Documents\",\n                    pathlib.Path.home() / \"Projects\",\n                ]\n                \n                git_dir = None\n                for check_dir in potential_dirs:\n                    if check_dir.exists():\n                        git_check = subprocess.run(\n                            [\"git\", \"rev-parse\", \"--git-dir\"], \n                            capture_output=True, text=True, timeout=5, cwd=check_dir\n                        )\n                        if git_check.returncode == 0:\n                            git_dir = check_dir\n                            working_dir = git_dir\n                            break\n                \n                if not git_dir:\n                    self._log_debug(f\"No git repository found. Checked: {[str(d) for d in potential_dirs]}\")\n                    return {\"status\": \"no_git\", \"files\": []}\n            \n            # Get git status\n            status_result = subprocess.run(\n                [\"git\", \"status\", \"--porcelain\"], \n                capture_output=True, text=True, timeout=10\n            )\n            \n            if status_result.returncode != 0:\n                return {\"status\": \"git_error\", \"files\": []}\n            \n            # Parse changed files\n            changed_files = []\n            for line in status_result.stdout.strip().split('\\n'):\n                if line.strip():\n                    status_code = line[:2].strip()\n                    filename = line[3:].strip()\n                    changed_files.append({\n                        \"file\": pathlib.Path(filename).name,\n                        \"path\": filename,\n                        \"status\": self._interpret_git_status(status_code),\n                        \"extension\": pathlib.Path(filename).suffix\n                    })\n            \n            return {\n                \"status\": \"changes_detected\" if changed_files else \"no_changes\",\n                \"files\": changed_files,\n                \"file_count\": len(changed_files),\n                \"primary_file\": changed_files[0] if changed_files else None\n            }\n            \n        except Exception as e:\n            self._log_debug(f\"Git analysis error: {e}\")\n            return {\"status\": f\"error: {e}\", \"files\": []}\n    \n    def _interpret_git_status(self, status_code: str) -> str:\n        \"\"\"Convert git status codes to readable actions.\"\"\"\n        status_map = {\n            \"A\": \"added\",\n            \"M\": \"modified\",\n            \"D\": \"deleted\", \n            \"R\": \"renamed\",\n            \"C\": \"copied\",\n            \"??\": \"untracked\",\n            \"AM\": \"added+modified\",\n            \"MM\": \"modified\"\n        }\n        return status_map.get(status_code, \"changed\")\n    \n    def _generate_smart_commit(self, tool_context: Dict[str, Any], \n                              session_context: Dict[str, Any], \n                              git_context: Dict[str, Any],\n                              tool_history: Dict[str, Any]) -> str:\n        \"\"\"Generate intelligent commit message using AI analysis.\"\"\"\n        \n        prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)\n        \n        # Debug: Log the prompt being sent to LLM\n        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")\n        \n        try:\n            # Call Claude Code Task tool for intelligent commit generation\n            response = self._call_claude_task(prompt)\n            commit_message = response.strip()\n            \n            # Clean and validate AI response\n            if commit_message and len(commit_message) > 5:\n                cleaned_message = self._clean_commit_message(commit_message)\n                \n                # Check if it's actually a meaningful response vs fallback\n                if cleaned_message and \"chore: update files\" not in cleaned_message.lower():\n                    self._log_debug(f\"LLM generated meaningful commit: {cleaned_message}\")\n                    return cleaned_message\n                else:\n                    self._log_debug(f\"LLM returned generic response: {cleaned_message}, trying fallback\")\n                    return self._create_fallback_commit(tool_context, git_context)\n            else:\n                self._log_debug(f\"LLM response too short: {commit_message}\")\n                return self._create_fallback_commit(tool_context, git_context)\n                \n        except Exception as e:\n            self._log_debug(f\"AI commit generation failed: {e}\")\n            return self._create_fallback_commit(tool_context, git_context)\n    \n    def _build_ai_prompt(self, tool_context: Dict[str, Any], \n                        session_context: Dict[str, Any], \n                        git_context: Dict[str, Any],\n                        tool_history: Dict[str, Any]) -> str:\n        \"\"\"Build AI prompt for intelligent commit message generation.\"\"\"\n        \n        # Extract detailed context\n        user_intent = \" | \".join(session_context.get(\"user_intent\", [\"unknown\"]))[:200]\n        tool_name = tool_context.get(\"tool_name\", \"unknown\")\n        files_changed = [f[\"file\"] for f in git_context.get(\"files\", [])]\n        primary_file = git_context.get(\"primary_file\", {})\n        \n        # Get file content context from tool_input\n        tool_input = tool_context.get(\"tool_input\", {})\n        file_path = tool_input.get(\"file_path\", \"\")\n        old_string = tool_input.get(\"old_string\", \"\")[:100]\n        new_string = tool_input.get(\"new_string\", \"\")[:100]\n        \n        # Extract specific changes\n        change_description = \"\"\n        if old_string and new_string:\n            change_description = f\"Changed: '{old_string}' \u00e2\u2020\u2019 '{new_string}'\"\n        \n        # Extract tool history context\n        session_activity = tool_history.get(\"session_summary\", \"unknown activity\")\n        total_ops = tool_history.get(\"total_operations\", 0)\n        file_ops = tool_history.get(\"file_operations\", [])\n        \n        # Build tool history summary\n        tool_context_summary = \"\"\n        if file_ops:\n            recent_file_ops = file_ops[-3:]  # Last 3 file operations\n            ops_summary = []\n            for op in recent_file_ops:\n                ops_summary.append(f\"{op.get('operation', 'edit')} {op.get('file', 'file')}\")\n            tool_context_summary = f\"Recent: {', '.join(ops_summary)}\"\n        \n        prompt = f\"\"\"Generate a git commit message using conventional commit format.\n\nContext:\n- User request: {user_intent}\n- File: {primary_file.get('file', 'unknown')}\n- Operation: {tool_name}\n- Session activity: {session_activity}\n- Change: {change_description}\n\nRules:\n- Format: type(scope): description\n- Under 50 characters\n- Present tense\n- Types: feat, fix, refactor, docs, style, test, chore\n\nExamples:\n- feat(auth): add login validation\n- fix(parser): handle null values\n- refactor(ui): extract components\n\nGenerate ONLY the commit message:\"\"\"\n        \n        return prompt\n    \n    def _clean_commit_message(self, message: str) -> str:\n        \"\"\"Clean and validate AI-generated commit message.\"\"\"\n        # Remove quotes and extra whitespace\n        message = message.strip().strip('\"').strip(\"'\").strip()\n        \n        # Take only the first line\n        first_line = message.split('\\n')[0]\n        \n        # Ensure reasonable length\n        if len(first_line) > 72:\n            first_line = first_line[:69] + \"...\"\n        \n        # Basic validation - ensure it looks like a commit message\n        if ':' not in first_line or len(first_line) < 10:\n            return self._create_fallback_commit({}, {})\n        \n        return first_line\n    \n    def _create_fallback_commit(self, tool_context: Dict[str, Any], \n                               git_context: Dict[str, Any]) -> str:\n        \"\"\"Create fallback commit when AI generation fails.\"\"\"\n        tool_name = tool_context.get(\"tool_name\", \"edit\")\n        files = git_context.get(\"files\", [])\n        \n        if len(files) == 1:\n            file_info = files[0]\n            filename = file_info.get(\"file\", \"file\")\n            status = file_info.get(\"status\", \"modified\")\n            return f\"chore: {status} {filename}\"\n        elif len(files) > 1:\n            primary = files[0].get(\"file\", \"files\") if files else \"files\"\n            return f\"chore: update {primary} +{len(files)-1} more\"\n        else:\n            return f\"chore: {tool_name.lower()} operation\"\n    \n    def _create_commit(self, commit_message: str) -> bool:\n        \"\"\"Create git commit with the generated message.\"\"\"\n        try:\n            # Stage all changes\n            add_result = subprocess.run(\n                [\"git\", \"add\", \".\"], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if add_result.returncode != 0:\n                self._log_debug(f\"Git add failed: {add_result.stderr}\")\n                return False\n            \n            # Create commit\n            commit_result = subprocess.run(\n                [\"git\", \"commit\", \"-m\", commit_message], \n                capture_output=True, text=True, timeout=30\n            )\n            \n            if commit_result.returncode == 0:\n                self._log_debug(f\"\u0005 Smart commit created: {commit_message}\")\n                return True\n            else:\n                self._log_debug(f\"L Git commit failed: {commit_result.stderr}\")\n                return False\n                \n        except Exception as e:\n            self._log_debug(f\"Commit creation error: {e}\")\n            return False\n    \n    def _call_claude_task(self, prompt: str) -> str:\n        \"\"\"Call Claude Code Task tool to generate intelligent commit message.\"\"\"\n        try:\n            # Create a temporary file with the prompt\n            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as temp_file:\n                # Ultra-compact prompt for minimal token usage\n                # Extract key info from the original detailed prompt\n                task_prompt = f\"\"\"Generate git commit message from this context:\n\n{prompt[:200]}\n\nFormat: type(scope): description\nMax 50 chars. Examples:\nfeat(auth): add login\nfix(api): handle errors\nchore: update config\n\nOutput only the commit message:\"\"\"\n                \n                temp_file.write(task_prompt)\n                temp_file_path = temp_file.name\n            \n            try:\n                # Call Claude Code with the Task tool\n                # Use shell=True on Windows to handle .cmd files properly\n                # Use new LLM utility for cost-efficient queries (Claude 3.5 Haiku)\n                try:\n                    from .llms import ask_concise\n                    response = ask_concise(task_prompt)\n                    self._log_debug(f\"\u00e2\u0153\u2026 LLM utility success: {response}\")\n                    \n                    # Validate response is not a fallback\n                    if response and response != \"AI response unavailable\" and len(response) > 10:\n                        return response\n                    else:\n                        self._log_debug(\"LLM response appears to be fallback, trying original method\")\n                        \n                except ImportError:\n                    self._log_debug(\"LLM utilities not available, using fallback\")\n                except Exception as e:\n                    self._log_debug(f\"LLM utility error: {e}\")\n                \n                # Fallback to original claude command with Haiku for cost efficiency\n                \n                result = subprocess.run([\n                    self.claude_executable, \n                    \"--print\",  # Print response and exit (non-interactive)\n                    \"--model\", \"claude-3-5-haiku-20241022\",  # Use Haiku for cost efficiency\n                    \"--output-format\", \"text\",  # Plain text output only\n                    \"--append-system-prompt\", \"Be extremely concise. Output only the requested git commit message with no explanations, analysis, or additional text.\",\n                    f\"@{temp_file_path}\"  # Read prompt from file\n                ], \n                capture_output=True, \n                text=True, \n                timeout=30,  # Reduced timeout for simple task\n                cwd=pathlib.Path.cwd(),\n                shell=True)  # Required for .cmd files on Windows\n                \n                if result.returncode == 0:\n                    raw_response = result.stdout.strip()\n                    self._log_debug(f\"Claude Task raw response: {raw_response[:50]}...\")\n                    \n                    # Aggressive cleaning for minimal token usage\n                    cleaned_response = self._extract_commit_message_only(raw_response)\n                    self._log_debug(f\"Claude Task cleaned: {cleaned_response}\")\n                    return cleaned_response\n                else:\n                    self._log_debug(f\"Claude Task failed: {result.stderr}\")\n                    raise Exception(f\"Claude Task failed: {result.stderr}\")\n                    \n            finally:\n                # Clean up temporary file\n                try:\n                    pathlib.Path(temp_file_path).unlink()\n                except:\n                    pass\n                    \n        except subprocess.TimeoutExpired:\n            self._log_debug(\"Claude Task timed out\")\n            raise Exception(\"Claude Task timeout\")\n        except FileNotFoundError:\n            self._log_debug(\"Claude executable not found - is Claude Code installed?\")\n            raise Exception(\"Claude executable not found\")\n        except Exception as e:\n            self._log_debug(f\"Claude Task error: {e}\")\n            raise\n    \n    def _clean_commit_response(self, response: str) -> str:\n        \"\"\"Extract clean commit message from Claude response.\"\"\"\n        if not response:\n            return \"\"\n        \n        # Remove common prefixes and thinking patterns\n        response = response.strip()\n        \n        # Look for lines that match commit message pattern\n        lines = response.split('\\n')\n        \n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            \n            # Skip empty lines\n            if not line:\n                continue\n                \n            # Skip explanatory lines\n            if any(skip in line.lower() for skip in [\n                'here is', 'the commit', 'message is', 'based on', 'according to',\n                'looking at', 'i think', 'this appears', 'let me', 'your commit'\n            ]):\n                continue\n            \n            # Look for proper commit format: type(scope): description\n            if ':' in line and len(line) > 5 and len(line) < 72:\n                # Check for conventional commit types\n                if any(commit_type in line.lower() for commit_type in \n                       ['feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci']):\n                    return line.strip()\n                    \n                # Or any line with reasonable commit-like structure\n                elif line.count(':') == 1 and '(' in line and ')' in line:\n                    return line.strip()\n        \n        # If no proper format found, look for any reasonable short line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 10 and len(line) < 72 and ':' in line:\n                return line\n        \n        # Ultimate fallback - return first meaningful line\n        for line in lines:\n            line = line.strip().strip('\"').strip(\"'\").strip('`')\n            if line and len(line) > 5:\n                return line[:50]\n        \n        return \"chore: update files\"  # Hard fallback\n    \n    def _extract_commit_message_only(self, response: str) -> str:\n        \"\"\"Ultra-aggressive extraction - get ONLY the commit message, nothing else.\"\"\"\n        if not response:\n            return \"chore: update files\"\n            \n        # Remove any common prefixes/suffixes\n        response = response.strip()\n        \n        # Split by lines and find the shortest valid commit message\n        lines = [line.strip().strip('\"').strip(\"'\").strip('`').strip('*').strip('-') \n                for line in response.split('\\n') if line.strip()]\n        \n        commit_candidates = []\n        \n        for line in lines:\n            # Skip obviously non-commit lines\n            if len(line) < 8 or len(line) > 60:\n                continue\n                \n            # Skip lines with explanatory words\n            if any(word in line.lower() for word in [\n                'message', 'commit', 'here', 'based', 'according', 'would', 'should',\n                'this', 'that', 'for', 'with', 'using', 'example', 'like'\n            ]):\n                continue\n                \n            # Must have colon and parentheses for conventional format\n            if ':' in line and '(' in line and ')' in line:\n                # Check for conventional commit types\n                if any(ctype in line.lower() for ctype in [\n                    'feat', 'fix', 'docs', 'style', 'refactor', 'test', 'chore', 'build', 'ci'\n                ]):\n                    commit_candidates.append(line)\n        \n        # Return the shortest valid candidate (most likely to be clean)\n        if commit_candidates:\n            return min(commit_candidates, key=len)\n            \n        # Fallback: look for any line with colon\n        for line in lines:\n            if ':' in line and len(line) > 5 and len(line) < 60:\n                return line\n                \n        # Ultimate fallback\n        return \"chore: update files\"\n    \n    def _log_debug(self, message: str):\n        \"\"\"Log debug information for troubleshooting.\"\"\"\n        try:\n            timestamp = datetime.datetime.now().isoformat()\n            with open(self.debug_log, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{timestamp} - SmartCheckpoint: {message}\\n\")\n        except:\n            pass  # Fail silently on debug logging\n\n# Public API functions for external usage\ndef process_tool_checkpoint(payload: Dict[str, Any]) -> bool:\n    \"\"\"\n    Main entry point for processing tool-based checkpoints.\n    Called by post_tool_use.py hook.\n    \n    Args:\n        payload: Hook payload containing tool_name, tool_input, tool_response, transcript_path\n        \n    Returns:\n        bool: True if checkpoint was successful or skipped, False if error occurred\n    \"\"\"\n    checkpoint_manager = SmartGitCheckpoints()\n    return checkpoint_manager.process_checkpoint(payload)\n\ndef test_checkpoint_system():\n    \"\"\"Test function for manual verification of checkpoint system.\"\"\"\n    print(\"\u00f0\u0178\u00a7\u00aa Testing Smart Git Checkpoints...\")\n    \n    # Create test payload\n    test_payload = {\n        \"tool_name\": \"Edit\",\n        \"tool_input\": {\"file_path\": \"test.js\"},\n        \"tool_response\": {\"success\": True},\n        \"transcript_path\": \"test_transcript.jsonl\"\n    }\n    \n    checkpoint_manager = SmartGitCheckpoints()\n    \n    # Test context extraction\n    tool_context = checkpoint_manager._extract_tool_context(test_payload)\n    print(f\"=\u00ef\u00bf\u00bd Tool Context: {tool_context}\")\n    \n    # Test git analysis\n    git_context = checkpoint_manager._analyze_git_changes()\n    print(f\"=\u00ef\u00bf\u00bd Git Context: {git_context}\")\n    \n    # Test fallback commit message\n    fallback_msg = checkpoint_manager._create_fallback_commit(tool_context, git_context)\n    print(f\"=\u00ef\u00bf\u00bd Fallback Message: {fallback_msg}\")\n    \n    print(\"\u0005 Test completed!\")\n\nif __name__ == \"__main__\":\n    test_checkpoint_system()", "structuredPatch": [{"oldStart": 420, "oldLines": 9, "newStart": 420, "newLines": 6, "lines": ["         ", "         prompt = self._build_ai_prompt(tool_context, session_context, git_context, tool_history)", "         ", "-        # Debug: Log the prompt being sent to LLM", "-        self._log_debug(f\"Generated prompt for LLM: {prompt[:500]}...\")", "-        ", "         try:", "             # Call Claude Code Task tool for intelligent commit generation", "             response = self._call_claude_task(prompt)"]}], "userModified": false, "replaceAll": false}, "cwd": "C:\\Users\\NATH\\.claude", "transcript_path": "C:\\Users\\NATH\\.claude\\projects\\C--Users-NATH--claude\\156a302f-9590-46e8-9e0f-1b3b6d31d18e.jsonl", "hook_event_name": "PostToolUse"}
